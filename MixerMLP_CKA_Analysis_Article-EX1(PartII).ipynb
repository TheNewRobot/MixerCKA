{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zSzgroG_Suq"
   },
   "source": [
    "# Study of Image classification with modern MLP Mixer model and CKA\n",
    "\n",
    "**Author:** [Arturo Flores](https://www.linkedin.com/in/afloresalv/)<br>\n",
    "**Based on (MLP-MIXER):**  https://keras.io/examples/vision/mlp_image_classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U087DdDw_Suy"
   },
   "source": [
    "# Setup for the MLP-Mixer Architecture\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AnTyoluw_Suz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alach\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:53: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import datetime\n",
    "import pickle\n",
    "# Files imported from the sleected GitHub https://cka-similarity.github.io/\n",
    "from CKA_Google import *\n",
    "import seaborn as sns \n",
    "import random\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 : Understand Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DAOrIHu_Su2"
   },
   "source": [
    "## Configure the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1iMiVS7o_Su3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 224 X 224 = 50176\n",
      "Patch size: 32 X 32 = 1024 \n",
      "Patches per image: 49\n",
      "Elements per patch (3 channels): 3072\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 0.0001\n",
    "batch_size = 512 \n",
    "num_epochs = 50\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.005\n",
    "\n",
    "## Selected Architecture: B/32\n",
    "\n",
    "image_size = 224  # We'll resize input images to this size. Square\n",
    "patch_size = 32  # Size of the patches to be extracted from the input images. Square\n",
    "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
    "embedding_dim = [384]  # Fixed Embedding Dimension\n",
    "num_blocks = [8,12,24,32]\n",
    "\n",
    "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
    "print(f\"Patches per image: {num_patches}\")\n",
    "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d_%H-%M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUuu2OAS_Su0"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Dataset for training \n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "#plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08mpnEZH_Su5"
   },
   "source": [
    "## Build a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ra-bXojQ_Su6"
   },
   "outputs": [],
   "source": [
    "def build_classifier(blocks, embedding_dim, positional_encoding=False):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data. \n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches. \n",
    "    patches = Patches(patch_size, num_patches)(augmented)\n",
    "    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n",
    "    x = layers.Dense(units=embedding_dim)(patches)\n",
    "    if positional_encoding:\n",
    "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "        position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=embedding_dim\n",
    "        )(positions)\n",
    "        x = x + position_embedding\n",
    "    # Process x using the module blocks. ## (sequential_82)\n",
    "    x = blocks(x)\n",
    "    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor. \n",
    "    representation = layers.GlobalAveragePooling1D()(x)\n",
    "    # Apply dropout.\n",
    "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
    "    # Compute logits outputs.\n",
    "    logits = layers.Dense(num_classes)(representation) \n",
    "    # Create the Keras model.\n",
    "    return keras.Model(inputs=inputs, outputs=logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpQFU8H__Su8"
   },
   "source": [
    "## Define an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9E1zD2BY_Su8"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    # Create Adam optimizer with weight decay. Regularization that penalizes the increase of weight - with a facto alpha - to correct the overfitting\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay,\n",
    "    )\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        #Negative Log Likelihood = Categorical Cross Entropy\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
    "        ],\n",
    "    )\n",
    "    # Create a learning rate scheduler callback.\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=5\n",
    "    )\n",
    "    # Create an early stopping regularization callback. \n",
    "    # It ends at a point that corresponds to a minimum of the L2-regularized objective\n",
    "    #early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    #    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "    #)\n",
    "    # Fit the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[reduce_lr],\n",
    "    )\n",
    "\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    # Return history to plot learning curves.\n",
    "    return history, accuracy, top_5_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxeE0cmM_Su9"
   },
   "source": [
    "## Use data augmentation\n",
    "Their state is not set during training; it must be set before training, either by initializing them from a precomputed constant, or by \"adapting\" them on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zh6hFPWX_Su-"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G77cUgiu_Su-"
   },
   "source": [
    "## Implement patch extraction as a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RYKNktXe_Su_"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, num_patches):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "    def call(self, images):\n",
    "        #Extract the shape dimension in the position 0 = columns\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            #Without overlapping, stride horizontally and vertically\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            #Rate: Dilation factor [1 1* 1* 1] controls the spacing between the kernel points.\n",
    "            rates=[1, 1, 1, 1],\n",
    "            #Patches contained in the images are considered, no zero padding\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        #shape[-1], number of colummns, as well as shape[0]\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Patches, self).get_config().copy()\n",
    "        config.update ({\n",
    "            'patch_size' : self.patch_size ,\n",
    "            'num_patches' : self.num_patches\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7yehcSS_Su_"
   },
   "source": [
    "## The MLP-Mixer model\n",
    "\n",
    "The MLP-Mixer is an architecture based exclusively on\n",
    "multi-layer perceptrons (MLPs), that contains two types of MLP layers:\n",
    "\n",
    "1. One applied independently to image patches, which mixes the per-location features.\n",
    "2. The other applied across patches (along channels), which mixes spatial information.\n",
    "\n",
    "This is similar to a [depthwise separable convolution based model](https://arxiv.org/pdf/1610.02357.pdf)\n",
    "such as the Xception model, but with two chained dense transforms, no max pooling, and layer normalization\n",
    "instead of batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvwg4e2n_SvA"
   },
   "source": [
    "### Implement the MLP-Mixer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dT6wVEki_SvA"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLPMixerLayer(layers.Layer):\n",
    "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
    "        super(MLPMixerLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.mlp1 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dense(units=num_patches),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.mlp2 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dense(units=embedding_dim),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply layer normalization.\n",
    "        x = self.normalize(inputs)\n",
    "        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n",
    "        x_channels = tf.linalg.matrix_transpose(x)\n",
    "        # Apply mlp1 on each channel independently.\n",
    "        mlp1_outputs = self.mlp1(x_channels)\n",
    "        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n",
    "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
    "        # Add skip connection.\n",
    "        x = mlp1_outputs + inputs\n",
    "        # Apply layer normalization.\n",
    "        x_patches = self.normalize(x)\n",
    "        # Apply mlp2 on each patch independtenly.\n",
    "        mlp2_outputs = self.mlp2(x_patches)\n",
    "        # Add skip connection.\n",
    "        x = x + mlp2_outputs\n",
    "        return x\n",
    "\n",
    "    def get_config(self): \n",
    "        config = super(MLPMixerLayer, self).get_config().copy()\n",
    "        config.update ({\n",
    "            'num_patches' : num_patches,\n",
    "            'embedding_dim' : embedding_dim,\n",
    "            'dropout_rate' : dropout_rate,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUiufq92_SvA"
   },
   "source": [
    "## Build, train, and evaluate the MLP-Mixer model\n",
    "\n",
    "Note that training the model with the current settings on a V100 GPUs\n",
    "takes around 8 seconds per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report: Learning Curve\n",
    "def curves(history):\n",
    "    ymax1 = min(history[\"loss\"])\n",
    "    xmax1 = history[\"loss\"].index(ymax1)\n",
    "    ymax2 = min(history[\"val_loss\"])\n",
    "    xmax2 = history[\"val_loss\"].index(ymax2)\n",
    "    plt.title(\"Cross Entropy Loss\")\n",
    "    plt.plot(history[\"loss\"], color = 'blue', label = 'Training')\n",
    "    plt.plot(history[\"val_loss\"], color = 'orange', label = 'Testing')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.annotate('Max:' + str(round(ymax1,2)) , xy = (xmax1, ymax1), xytext = (xmax1*0.93, 1.07*ymax1), \n",
    "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
    "    plt.annotate('Max:' + str(round(ymax2,2)) , xy = (xmax2, ymax2), xytext = (xmax2*0.93, 1.07*ymax2), \n",
    "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Graph accuracy\n",
    "    ymax3 = max(history[\"acc\"])\n",
    "    xmax3 = history[\"acc\"].index(ymax3)\n",
    "    ymax4 = max(history[\"val_acc\"])\n",
    "    xmax4 = history[\"val_acc\"].index(ymax4)\n",
    "    ymax5 = max(history[\"top5-acc\"])\n",
    "    xmax5 = history[\"top5-acc\"].index(ymax5)\n",
    "    ymax6 = max(history[\"val_top5-acc\"])\n",
    "    xmax6 = history[\"val_top5-acc\"].index(ymax6)\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('Classification accuracy')\n",
    "    plt.plot(history['acc'], color = 'blue', label = 'Training')\n",
    "    plt.plot(history['val_acc'], color = 'orange', label = 'Testing')\n",
    "    plt.annotate('Max:' + str(round(ymax3,2)) , xy = (xmax3, ymax3), xytext = (xmax3*0.93, 1.2*ymax3), \n",
    "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
    "    plt.annotate('Max:' + str(round(ymax4,2)) , xy = (xmax4, ymax4), xytext = (xmax4*0.93, 0.7*ymax4), \n",
    "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.title('Classification top5-acc')\n",
    "    plt.plot(history['top5-acc'], color = 'blue', label = 'Training')\n",
    "    plt.plot(history['val_top5-acc'], color = 'orange', label = 'Testing')\n",
    "    plt.annotate('Max:' + str(round(ymax5,2)) , xy = (xmax5, ymax5), xytext = (xmax5*0.93, 1.2*ymax5), \n",
    "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
    "    plt.annotate('Max:' + str(round(ymax6,2)) , xy = (xmax6, ymax6), xytext = (xmax6*0.87, 1.2*ymax6), \n",
    "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.suptitle(\"Learning Curves\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain activations + Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Layers + Patches + One dense layer\n",
    "def Preprocessing(num_example):\n",
    "    augmented = data_augmentation(x_train[num_example])\n",
    "    b = Patches(patch_size, num_patches)(augmented)\n",
    "    a = layers.Dense(units=embedding_dim)(b)\n",
    "    inp = tf.reshape(a,[1,embedding_dim,num_patches])\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a random vector with indexes of a random batch selection and also regularizes the selected batch\n",
    "def Batch_Preprocessing(batch_size):\n",
    "    #Vector with the number of Sample of the Xtrain\n",
    "    a  = list(range(0,x_train.shape[0]))\n",
    "    b = random.sample(a,batch_size)\n",
    "    batch_regularization = list()\n",
    "    for i in range(0,batch_size):\n",
    "        inter_result = Preprocessing(b[i])\n",
    "        batch_regularization.append(inter_result)\n",
    "    return batch_regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_out(result,layer_number,example):\n",
    "    fig, (ax1, ax2)= plt.subplots(1,2)\n",
    "    ax1.imshow(x_train[example])\n",
    "    ax1.set_title('Original_Figure, Class: #' + str(y_train[example][0]))\n",
    "    ax2.imshow(result[layer_number])\n",
    "    ax2.set_title('Activations of MLP block of the Mixer #: '+ '\"' + str(layer_number) + '\"')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mixer_Layer_Outputs(model_input, model_output,example):\n",
    "    #The input is fixed to the beginning of the mlp blocks\n",
    "    intermediate_model=tf.keras.models.Model(inputs=model_input.input,outputs=model_output.output)\n",
    "    #This reshape is necessary for the input of the model\n",
    "    example = tf.reshape(example,[1,num_patches,embedding_dim])\n",
    "    #Inference\n",
    "    intermediate_prediction =intermediate_model.predict(example)\n",
    "    #This reshape is standardize the output\n",
    "    layactivation = intermediate_prediction.reshape((embedding_dim,num_patches))\n",
    "    return layactivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computes the outputs of each MLP-mixer Layer\n",
    "def Mixer_Activations(model, example):\n",
    "    total_activations = list()\n",
    "    for i in range(num_blocks):\n",
    "        model_input = model.layers[4].layers[0]\n",
    "        model_output = model.layers[4].layers[i]\n",
    "        int_total_activations = Mixer_Layer_Outputs(model_input, model_output, example)\n",
    "        total_activations.append(int_total_activations)\n",
    "    return  total_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average of layer's activation\n",
    "def Prom_Mixer_Activations_Blocks(model,batch_regularization):\n",
    "    sum = list()\n",
    "    for i in range(0,num_blocks):\n",
    "        sum_raw = np.zeros((embedding_dim,num_patches))\n",
    "        sum.append(sum_raw)\n",
    "    for i in range(0,batch_size):\n",
    "        mixer_raw = Mixer_Activations(model,batch_regularization[i])\n",
    "        for i in range(0,num_blocks):\n",
    "            sum[i] = np.add(mixer_raw[i],sum[i])\n",
    "    prom_mixer_activations = [ (number / batch_size)  for number in sum]\n",
    "    return prom_mixer_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates a heatmap according to the selection of a CKA_Kernel (preferred) or CKA_Linear\n",
    "def Heatmap(result,type,sigma):\n",
    "    dim = len(result)\n",
    "    k = (dim - 1)\n",
    "    heatmap_CKA = np.zeros((dim,dim))\n",
    "    for i in range(0,dim):\n",
    "        tr = (dim - 1)\n",
    "        for j in range(0,dim):\n",
    "            if type == 'kernel':\n",
    "                heatmap_CKA[k][tr] = cka(gram_rbf(result[i],sigma),gram_rbf(result[j],sigma))\n",
    "            elif type == 'linear':\n",
    "                heatmap_CKA[k][tr] = cka(gram_linear(result[i]),gram_linear(result[j])) \n",
    "            else:\n",
    "                print('There is no such category, try again')\n",
    "                break\n",
    "\n",
    "            tr -= 1\n",
    "        k -= 1\n",
    "    #print('CKA' + type + 'calculated')\n",
    "    return heatmap_CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average of heatmaps (obsolet)\n",
    "def Prom_Mixer_Heatmaps(batch_result,type):\n",
    "    mat_heatmaps = list()\n",
    "    prom_mixer_heatmap_raw = np.zeros((num_blocks,num_blocks))\n",
    "    for i in range(0,batch_size):\n",
    "        mixer_activations_raw = Mixer_Activations(batch_result[i])\n",
    "        heatmap_raw = Heatmap(mixer_activations_raw, type)\n",
    "        mat_heatmaps.append(heatmap_raw)\n",
    "        prom_mixer_heatmap_raw = np.add(heatmap_raw,prom_mixer_heatmap_raw)\n",
    "    prom_mixer_heatmap =  prom_mixer_heatmap_raw/batch_size  \n",
    "    return prom_mixer_heatmap,mat_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_Heatmap(heatmap,type,bl):\n",
    "    #Number of thats that you want to appear in the plot\n",
    "    tri = 4\n",
    "    if type == 'kernel' or type == 'linear':\n",
    "        dim = len(heatmap)\n",
    "        axis_labels = list()\n",
    "        for i in range(0,dim):\n",
    "            axis_labels_inter = str('%i'%(i+1))\n",
    "            axis_labels.append(axis_labels_inter)\n",
    "        _, ax = plt.subplots(figsize=(3,3))\n",
    "        ax = sns.heatmap(heatmap, xticklabels=axis_labels[::-1], yticklabels=axis_labels[::-1], ax = ax, annot=bl)\n",
    "        #sns.heatmap(heatmap, xticklabels=2, yticklabels=2, ax = ax, annot=bl, cbar=True)   \n",
    "        ax.invert_xaxis()\n",
    "        ax.axhline(y = 0, color='k',linewidth = 4)\n",
    "        ax.axhline(y = heatmap.shape[1], color = 'k', linewidth = 4)\n",
    "        ax.axvline(x = 0, color ='k',linewidth = 4)\n",
    "        ax.axvline(x = heatmap.shape[0], color = 'k', linewidth = 4)\n",
    "\n",
    "        ax.set_title(\"CKA-\"+ type)   \n",
    "        ax.set_xlabel(\"Layer\")\n",
    "        ax.set_ylabel(\"Layer\")\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.locator_params(axis='x',nbins=tri)\n",
    "        plt.locator_params(axis='y',nbins=tri)\n",
    "        plt.savefig('CKA_'+ type +'.png', dpi=300)\n",
    "        \n",
    "    else:\n",
    "        print('There is no such category, try again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 : Understand Network Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1A: Different Depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create different mlpmixers according to an array of widths or depths\n",
    "def mlpmixer_iterations(num_patches,experiment,embedding_dim,num_blocks):\n",
    "    it_widths = len(embedding_dim)\n",
    "    it_blocks = len(num_blocks)\n",
    "    for j in range(it_widths):\n",
    "        for i in range(it_blocks):\n",
    "            mlpmixer_blocks = keras.Sequential(\n",
    "            [MLPMixerLayer(num_patches, embedding_dim[j], dropout_rate) for _ in range(num_blocks[i])] # creates the number of block without a \n",
    "            )\n",
    "            mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim[j]) # Returns the model\n",
    "            history,accuracy, top_5_accuracy = run_experiment(mlpmixer_classifier)\n",
    "            #Saving Results\n",
    "            pwd = 'Results_Article/'+ str(experiment) +'/mlpmixer_'+ str(num_blocks[i]) + 'ly_' + str(embedding_dim[j]) + 'Dc'\n",
    "            mlpmixer_classifier.save(pwd)\n",
    "            np.save( pwd + '/history.npy',history.history)\n",
    "            with open(pwd + '/accuracy.pkl','wb') as file:\n",
    "                pickle.dump(accuracy,file)\n",
    "            with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
    "                pickle.dump(top_5_accuracy,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of Average of layer's activation\n",
    "sigma = 1\n",
    "type = 'kernel'\n",
    "embedding_dim = 384\n",
    "blocks_total = num_blocks\n",
    "######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run separtely once to avoid randomness \n",
    "batch_prepro = Batch_Preprocessing(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the only parameter that have to be initialized since, all the parameters are shared with Experiment 1A\n",
    "embedding_d = embedding_dim  # Fixed Embedding Dimension from experiment 1A\n",
    "path_1B = 'Results_Article/1B'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evol_accuracy(all_models,num_blocks):\n",
    "    total_plots=list()\n",
    "    for f in range(len(all_models)) :\n",
    "        testing_model = all_models[f]\n",
    "        partial_plots = list()\n",
    "        for j in range(num_blocks[f]):\n",
    "            #Define the Mixer Block that are going to participate (Cumulative Approach)\n",
    "            inter_input = testing_model.layers[4].layers[0].input\n",
    "            inter_output = testing_model.layers[4].layers[j].output\n",
    "            partial_models=tf.keras.models.Model(inputs=inter_input,outputs=inter_output, name = 'Mixer_Blocks')\n",
    "            #Create the structure of the model\n",
    "            inputs = layers.Input(shape=input_shape)\n",
    "            augmented = data_augmentation(inputs)\n",
    "            patches = Patches(patch_size, num_patches)(augmented)\n",
    "            x = testing_model.layers[3](patches)\n",
    "            intermediate_output  =  partial_models(x)\n",
    "            representation = layers.GlobalAveragePooling1D()(intermediate_output)\n",
    "            output =  layers.Dense(units=num_classes, activation='softmax')(representation) # Linear regression that is going to be trained\n",
    "            final_modelx =   keras.Model(inputs=inputs, outputs=output)\n",
    "            #Set the condition to not trainable\n",
    "            final_modelx.layers[3].trainable = False\n",
    "            final_modelx.layers[4].trainable = False\n",
    "            __,accuracy,__= run_experiment(final_modelx)\n",
    "            with open(path_1B + '/accuracy_Blocks_'+ str(num_blocks[f]) + '_L' + str(j+1)+ '.pkl','wb') as file:\n",
    "                        pickle.dump(accuracy,file)\n",
    "            partial_plots.append(accuracy)\n",
    "        total_plots.append(partial_plots)\n",
    "    return total_plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the path in this cell (loading results from the experiment 1A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_blocks = [8, 12, 24]\n",
    "listnumblocks = num_blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = list()\n",
    "for layer in listnumblocks:\n",
    "    #Call the folder\n",
    "    pwd1 = 'Results_Article/1A/mlpmixer_'+ str(layer) + 'ly_' + str(embedding_d) + 'Dc' \n",
    "    layers_models = tf.keras.models.load_model(pwd1, compile=False)\n",
    "    all_models.append(layers_models)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alach\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.4764 - acc: 0.2906 - top5-acc: 0.8110WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 3s 27ms/step - loss: 2.4764 - acc: 0.2906 - top5-acc: 0.8110 - val_loss: 1.8434 - val_acc: 0.3594 - val_top5-acc: 0.8614 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.9435 - acc: 0.3278 - top5-acc: 0.8459 - val_loss: 1.8080 - val_acc: 0.3710 - val_top5-acc: 0.8678 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8426 - acc: 0.3548 - top5-acc: 0.8581 - val_loss: 1.7068 - val_acc: 0.3912 - val_top5-acc: 0.8874 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8235 - acc: 0.3582 - top5-acc: 0.8627 - val_loss: 1.6956 - val_acc: 0.3966 - val_top5-acc: 0.8788 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8417 - acc: 0.3596 - top5-acc: 0.8629 - val_loss: 1.7472 - val_acc: 0.3702 - val_top5-acc: 0.8848 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.8047 - acc: 0.3699 - top5-acc: 0.8674 - val_loss: 1.7001 - val_acc: 0.3934 - val_top5-acc: 0.8838 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7897 - acc: 0.3766 - top5-acc: 0.8695 - val_loss: 1.7152 - val_acc: 0.3924 - val_top5-acc: 0.8724 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7674 - acc: 0.3788 - top5-acc: 0.8714 - val_loss: 1.6376 - val_acc: 0.4178 - val_top5-acc: 0.8928 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7726 - acc: 0.3801 - top5-acc: 0.8726 - val_loss: 1.6520 - val_acc: 0.4222 - val_top5-acc: 0.8958 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7869 - acc: 0.3771 - top5-acc: 0.8712 - val_loss: 1.6821 - val_acc: 0.4046 - val_top5-acc: 0.8870 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7743 - acc: 0.3832 - top5-acc: 0.8715 - val_loss: 1.6811 - val_acc: 0.3948 - val_top5-acc: 0.8960 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7451 - acc: 0.3866 - top5-acc: 0.8760 - val_loss: 1.6784 - val_acc: 0.4022 - val_top5-acc: 0.8892 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.7748 - acc: 0.3827 - top5-acc: 0.8717 - val_loss: 1.7253 - val_acc: 0.3974 - val_top5-acc: 0.8878 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6773 - acc: 0.4059 - top5-acc: 0.8845 - val_loss: 1.5952 - val_acc: 0.4288 - val_top5-acc: 0.8992 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6531 - acc: 0.4111 - top5-acc: 0.8875 - val_loss: 1.5593 - val_acc: 0.4442 - val_top5-acc: 0.9072 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6633 - acc: 0.4052 - top5-acc: 0.8853 - val_loss: 1.5886 - val_acc: 0.4314 - val_top5-acc: 0.9030 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6691 - acc: 0.4071 - top5-acc: 0.8876 - val_loss: 1.5592 - val_acc: 0.4400 - val_top5-acc: 0.9074 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6519 - acc: 0.4094 - top5-acc: 0.8881 - val_loss: 1.5626 - val_acc: 0.4324 - val_top5-acc: 0.9110 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6622 - acc: 0.4071 - top5-acc: 0.8873 - val_loss: 1.5963 - val_acc: 0.4180 - val_top5-acc: 0.9022 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6709 - acc: 0.4053 - top5-acc: 0.8858 - val_loss: 1.6028 - val_acc: 0.4180 - val_top5-acc: 0.8984 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6570 - acc: 0.4106 - top5-acc: 0.8894 - val_loss: 1.5933 - val_acc: 0.4196 - val_top5-acc: 0.9006 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6676 - acc: 0.4086 - top5-acc: 0.8860 - val_loss: 1.5735 - val_acc: 0.4284 - val_top5-acc: 0.9074 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6247 - acc: 0.4227 - top5-acc: 0.8914 - val_loss: 1.5356 - val_acc: 0.4496 - val_top5-acc: 0.9106 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6202 - acc: 0.4217 - top5-acc: 0.8924 - val_loss: 1.5501 - val_acc: 0.4360 - val_top5-acc: 0.9062 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6159 - acc: 0.4217 - top5-acc: 0.8925 - val_loss: 1.5459 - val_acc: 0.4478 - val_top5-acc: 0.9072 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6189 - acc: 0.4204 - top5-acc: 0.8912 - val_loss: 1.5729 - val_acc: 0.4344 - val_top5-acc: 0.9012 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6115 - acc: 0.4259 - top5-acc: 0.8915 - val_loss: 1.5642 - val_acc: 0.4298 - val_top5-acc: 0.9056 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6159 - acc: 0.4234 - top5-acc: 0.8920 - val_loss: 1.5723 - val_acc: 0.4276 - val_top5-acc: 0.9056 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6015 - acc: 0.4293 - top5-acc: 0.8958 - val_loss: 1.5281 - val_acc: 0.4484 - val_top5-acc: 0.9114 - lr: 6.2500e-04\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5981 - acc: 0.4295 - top5-acc: 0.8950 - val_loss: 1.5299 - val_acc: 0.4526 - val_top5-acc: 0.9104 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5989 - acc: 0.4290 - top5-acc: 0.8943 - val_loss: 1.5318 - val_acc: 0.4466 - val_top5-acc: 0.9066 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5903 - acc: 0.4320 - top5-acc: 0.8961 - val_loss: 1.5204 - val_acc: 0.4560 - val_top5-acc: 0.9090 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5966 - acc: 0.4299 - top5-acc: 0.8952 - val_loss: 1.5369 - val_acc: 0.4438 - val_top5-acc: 0.9078 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5944 - acc: 0.4295 - top5-acc: 0.8963 - val_loss: 1.5278 - val_acc: 0.4480 - val_top5-acc: 0.9084 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6014 - acc: 0.4271 - top5-acc: 0.8929 - val_loss: 1.5326 - val_acc: 0.4422 - val_top5-acc: 0.9078 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5943 - acc: 0.4299 - top5-acc: 0.8954 - val_loss: 1.5289 - val_acc: 0.4462 - val_top5-acc: 0.9072 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5964 - acc: 0.4312 - top5-acc: 0.8953 - val_loss: 1.5278 - val_acc: 0.4480 - val_top5-acc: 0.9108 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5865 - acc: 0.4327 - top5-acc: 0.8964 - val_loss: 1.5272 - val_acc: 0.4576 - val_top5-acc: 0.9094 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5865 - acc: 0.4337 - top5-acc: 0.8961 - val_loss: 1.5274 - val_acc: 0.4504 - val_top5-acc: 0.9088 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5863 - acc: 0.4337 - top5-acc: 0.8978 - val_loss: 1.5283 - val_acc: 0.4532 - val_top5-acc: 0.9098 - lr: 3.1250e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5910 - acc: 0.4334 - top5-acc: 0.8967 - val_loss: 1.5201 - val_acc: 0.4488 - val_top5-acc: 0.9104 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5845 - acc: 0.4346 - top5-acc: 0.8966 - val_loss: 1.5203 - val_acc: 0.4598 - val_top5-acc: 0.9076 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5902 - acc: 0.4327 - top5-acc: 0.8971 - val_loss: 1.5339 - val_acc: 0.4426 - val_top5-acc: 0.9092 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5898 - acc: 0.4327 - top5-acc: 0.8944 - val_loss: 1.5217 - val_acc: 0.4556 - val_top5-acc: 0.9110 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5832 - acc: 0.4362 - top5-acc: 0.8968 - val_loss: 1.5298 - val_acc: 0.4422 - val_top5-acc: 0.9092 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5907 - acc: 0.4296 - top5-acc: 0.8952 - val_loss: 1.5291 - val_acc: 0.4408 - val_top5-acc: 0.9054 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5822 - acc: 0.4351 - top5-acc: 0.8972 - val_loss: 1.5242 - val_acc: 0.4546 - val_top5-acc: 0.9068 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5819 - acc: 0.4367 - top5-acc: 0.8983 - val_loss: 1.5303 - val_acc: 0.4428 - val_top5-acc: 0.9080 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5830 - acc: 0.4368 - top5-acc: 0.8961 - val_loss: 1.5251 - val_acc: 0.4528 - val_top5-acc: 0.9064 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5827 - acc: 0.4375 - top5-acc: 0.8967 - val_loss: 1.5208 - val_acc: 0.4614 - val_top5-acc: 0.9088 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.5441 - acc: 0.4502 - top5-acc: 0.9109\n",
      "Test accuracy: 45.02%\n",
      "Test top 5 accuracy: 91.09%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.1961 - acc: 0.3253 - top5-acc: 0.8444WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 4s 37ms/step - loss: 2.1910 - acc: 0.3259 - top5-acc: 0.8449 - val_loss: 1.6135 - val_acc: 0.4244 - val_top5-acc: 0.9042 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.7152 - acc: 0.3963 - top5-acc: 0.8896 - val_loss: 1.5617 - val_acc: 0.4410 - val_top5-acc: 0.9144 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6525 - acc: 0.4176 - top5-acc: 0.9006 - val_loss: 1.4711 - val_acc: 0.4666 - val_top5-acc: 0.9258 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6100 - acc: 0.4308 - top5-acc: 0.9063 - val_loss: 1.4680 - val_acc: 0.4666 - val_top5-acc: 0.9252 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6035 - acc: 0.4352 - top5-acc: 0.9071 - val_loss: 1.4221 - val_acc: 0.4910 - val_top5-acc: 0.9270 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5837 - acc: 0.4429 - top5-acc: 0.9090 - val_loss: 1.5153 - val_acc: 0.4596 - val_top5-acc: 0.9216 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5579 - acc: 0.4480 - top5-acc: 0.9123 - val_loss: 1.4873 - val_acc: 0.4720 - val_top5-acc: 0.9256 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5375 - acc: 0.4545 - top5-acc: 0.9146 - val_loss: 1.4505 - val_acc: 0.4752 - val_top5-acc: 0.9274 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5595 - acc: 0.4505 - top5-acc: 0.9142 - val_loss: 1.4699 - val_acc: 0.4860 - val_top5-acc: 0.9236 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5468 - acc: 0.4523 - top5-acc: 0.9150 - val_loss: 1.4197 - val_acc: 0.4980 - val_top5-acc: 0.9284 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5378 - acc: 0.4569 - top5-acc: 0.9150 - val_loss: 1.4589 - val_acc: 0.4830 - val_top5-acc: 0.9256 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5455 - acc: 0.4558 - top5-acc: 0.9152 - val_loss: 1.4428 - val_acc: 0.4906 - val_top5-acc: 0.9254 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5325 - acc: 0.4596 - top5-acc: 0.9156 - val_loss: 1.4946 - val_acc: 0.4740 - val_top5-acc: 0.9272 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5339 - acc: 0.4593 - top5-acc: 0.9165 - val_loss: 1.4219 - val_acc: 0.4890 - val_top5-acc: 0.9330 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5433 - acc: 0.4572 - top5-acc: 0.9155 - val_loss: 1.4737 - val_acc: 0.4784 - val_top5-acc: 0.9276 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4649 - acc: 0.4778 - top5-acc: 0.9217 - val_loss: 1.3556 - val_acc: 0.5066 - val_top5-acc: 0.9370 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4585 - acc: 0.4795 - top5-acc: 0.9246 - val_loss: 1.3469 - val_acc: 0.5216 - val_top5-acc: 0.9332 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4552 - acc: 0.4792 - top5-acc: 0.9230 - val_loss: 1.3423 - val_acc: 0.5112 - val_top5-acc: 0.9418 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4592 - acc: 0.4812 - top5-acc: 0.9221 - val_loss: 1.3437 - val_acc: 0.5082 - val_top5-acc: 0.9410 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4603 - acc: 0.4773 - top5-acc: 0.9227 - val_loss: 1.3498 - val_acc: 0.5164 - val_top5-acc: 0.9398 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4639 - acc: 0.4770 - top5-acc: 0.9223 - val_loss: 1.3756 - val_acc: 0.5028 - val_top5-acc: 0.9342 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4609 - acc: 0.4771 - top5-acc: 0.9228 - val_loss: 1.3344 - val_acc: 0.5202 - val_top5-acc: 0.9412 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4417 - acc: 0.4837 - top5-acc: 0.9268 - val_loss: 1.3446 - val_acc: 0.5128 - val_top5-acc: 0.9356 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4578 - acc: 0.4767 - top5-acc: 0.9234 - val_loss: 1.3579 - val_acc: 0.5120 - val_top5-acc: 0.9340 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4562 - acc: 0.4774 - top5-acc: 0.9235 - val_loss: 1.3363 - val_acc: 0.5220 - val_top5-acc: 0.9348 - lr: 0.0025\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4488 - acc: 0.4829 - top5-acc: 0.9224 - val_loss: 1.3411 - val_acc: 0.5126 - val_top5-acc: 0.9410 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4614 - acc: 0.4782 - top5-acc: 0.9226 - val_loss: 1.3766 - val_acc: 0.5064 - val_top5-acc: 0.9330 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4229 - acc: 0.4902 - top5-acc: 0.9270 - val_loss: 1.3080 - val_acc: 0.5300 - val_top5-acc: 0.9412 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4151 - acc: 0.4905 - top5-acc: 0.9277 - val_loss: 1.3386 - val_acc: 0.5150 - val_top5-acc: 0.9380 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4285 - acc: 0.4892 - top5-acc: 0.9261 - val_loss: 1.3069 - val_acc: 0.5312 - val_top5-acc: 0.9436 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4266 - acc: 0.4880 - top5-acc: 0.9269 - val_loss: 1.3350 - val_acc: 0.5262 - val_top5-acc: 0.9344 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4231 - acc: 0.4915 - top5-acc: 0.9257 - val_loss: 1.3359 - val_acc: 0.5194 - val_top5-acc: 0.9366 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4244 - acc: 0.4892 - top5-acc: 0.9280 - val_loss: 1.3402 - val_acc: 0.5232 - val_top5-acc: 0.9394 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4268 - acc: 0.4873 - top5-acc: 0.9262 - val_loss: 1.3203 - val_acc: 0.5238 - val_top5-acc: 0.9386 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4200 - acc: 0.4906 - top5-acc: 0.9268 - val_loss: 1.3208 - val_acc: 0.5238 - val_top5-acc: 0.9410 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4090 - acc: 0.4947 - top5-acc: 0.9268 - val_loss: 1.3050 - val_acc: 0.5288 - val_top5-acc: 0.9436 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4096 - acc: 0.4926 - top5-acc: 0.9292 - val_loss: 1.3291 - val_acc: 0.5206 - val_top5-acc: 0.9406 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4102 - acc: 0.4941 - top5-acc: 0.9282 - val_loss: 1.3167 - val_acc: 0.5188 - val_top5-acc: 0.9428 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4114 - acc: 0.4954 - top5-acc: 0.9268 - val_loss: 1.3287 - val_acc: 0.5226 - val_top5-acc: 0.9398 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4096 - acc: 0.4950 - top5-acc: 0.9276 - val_loss: 1.3244 - val_acc: 0.5240 - val_top5-acc: 0.9422 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4099 - acc: 0.4959 - top5-acc: 0.9284 - val_loss: 1.3077 - val_acc: 0.5300 - val_top5-acc: 0.9422 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4027 - acc: 0.4988 - top5-acc: 0.9278 - val_loss: 1.3138 - val_acc: 0.5324 - val_top5-acc: 0.9416 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4004 - acc: 0.4972 - top5-acc: 0.9298 - val_loss: 1.3157 - val_acc: 0.5300 - val_top5-acc: 0.9404 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4035 - acc: 0.4999 - top5-acc: 0.9284 - val_loss: 1.3082 - val_acc: 0.5314 - val_top5-acc: 0.9412 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4019 - acc: 0.4975 - top5-acc: 0.9304 - val_loss: 1.3026 - val_acc: 0.5358 - val_top5-acc: 0.9426 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4039 - acc: 0.4996 - top5-acc: 0.9292 - val_loss: 1.3218 - val_acc: 0.5278 - val_top5-acc: 0.9424 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4037 - acc: 0.4985 - top5-acc: 0.9259 - val_loss: 1.3107 - val_acc: 0.5334 - val_top5-acc: 0.9442 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4027 - acc: 0.4964 - top5-acc: 0.9301 - val_loss: 1.3198 - val_acc: 0.5288 - val_top5-acc: 0.9370 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4022 - acc: 0.4988 - top5-acc: 0.9286 - val_loss: 1.3231 - val_acc: 0.5256 - val_top5-acc: 0.9414 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4012 - acc: 0.4989 - top5-acc: 0.9267 - val_loss: 1.3117 - val_acc: 0.5332 - val_top5-acc: 0.9412 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 1.3494 - acc: 0.5224 - top5-acc: 0.9361\n",
      "Test accuracy: 52.24%\n",
      "Test top 5 accuracy: 93.61%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 1.9500 - acc: 0.3727 - top5-acc: 0.8700WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 5s 45ms/step - loss: 1.9460 - acc: 0.3735 - top5-acc: 0.8704 - val_loss: 1.5003 - val_acc: 0.4628 - val_top5-acc: 0.9248 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5348 - acc: 0.4601 - top5-acc: 0.9168 - val_loss: 1.4176 - val_acc: 0.4942 - val_top5-acc: 0.9348 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4535 - acc: 0.4843 - top5-acc: 0.9267 - val_loss: 1.3267 - val_acc: 0.5246 - val_top5-acc: 0.9412 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4395 - acc: 0.4920 - top5-acc: 0.9298 - val_loss: 1.3247 - val_acc: 0.5240 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4210 - acc: 0.4972 - top5-acc: 0.9334 - val_loss: 1.3285 - val_acc: 0.5214 - val_top5-acc: 0.9444 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4024 - acc: 0.5027 - top5-acc: 0.9334 - val_loss: 1.3492 - val_acc: 0.5262 - val_top5-acc: 0.9426 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3844 - acc: 0.5113 - top5-acc: 0.9342 - val_loss: 1.2650 - val_acc: 0.5492 - val_top5-acc: 0.9476 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3873 - acc: 0.5136 - top5-acc: 0.9341 - val_loss: 1.3479 - val_acc: 0.5240 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3897 - acc: 0.5127 - top5-acc: 0.9343 - val_loss: 1.3167 - val_acc: 0.5300 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3860 - acc: 0.5125 - top5-acc: 0.9338 - val_loss: 1.3130 - val_acc: 0.5322 - val_top5-acc: 0.9414 - lr: 0.0050\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3734 - acc: 0.5145 - top5-acc: 0.9358 - val_loss: 1.3329 - val_acc: 0.5256 - val_top5-acc: 0.9442 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3827 - acc: 0.5132 - top5-acc: 0.9365 - val_loss: 1.3871 - val_acc: 0.5190 - val_top5-acc: 0.9404 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3274 - acc: 0.5274 - top5-acc: 0.9399 - val_loss: 1.2835 - val_acc: 0.5424 - val_top5-acc: 0.9508 - lr: 0.0025\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3217 - acc: 0.5304 - top5-acc: 0.9391 - val_loss: 1.2566 - val_acc: 0.5542 - val_top5-acc: 0.9478 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3226 - acc: 0.5285 - top5-acc: 0.9419 - val_loss: 1.2329 - val_acc: 0.5558 - val_top5-acc: 0.9510 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3200 - acc: 0.5298 - top5-acc: 0.9396 - val_loss: 1.2523 - val_acc: 0.5518 - val_top5-acc: 0.9502 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3223 - acc: 0.5317 - top5-acc: 0.9404 - val_loss: 1.2441 - val_acc: 0.5576 - val_top5-acc: 0.9508 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3198 - acc: 0.5302 - top5-acc: 0.9410 - val_loss: 1.2691 - val_acc: 0.5500 - val_top5-acc: 0.9482 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3228 - acc: 0.5269 - top5-acc: 0.9402 - val_loss: 1.2507 - val_acc: 0.5538 - val_top5-acc: 0.9514 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3207 - acc: 0.5293 - top5-acc: 0.9395 - val_loss: 1.2512 - val_acc: 0.5504 - val_top5-acc: 0.9510 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2921 - acc: 0.5393 - top5-acc: 0.9433 - val_loss: 1.2269 - val_acc: 0.5622 - val_top5-acc: 0.9528 - lr: 0.0012\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2924 - acc: 0.5404 - top5-acc: 0.9416 - val_loss: 1.2125 - val_acc: 0.5656 - val_top5-acc: 0.9550 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2916 - acc: 0.5394 - top5-acc: 0.9409 - val_loss: 1.2212 - val_acc: 0.5560 - val_top5-acc: 0.9532 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2916 - acc: 0.5411 - top5-acc: 0.9423 - val_loss: 1.2152 - val_acc: 0.5638 - val_top5-acc: 0.9542 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2938 - acc: 0.5400 - top5-acc: 0.9427 - val_loss: 1.2629 - val_acc: 0.5562 - val_top5-acc: 0.9488 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2964 - acc: 0.5387 - top5-acc: 0.9424 - val_loss: 1.2616 - val_acc: 0.5442 - val_top5-acc: 0.9486 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3006 - acc: 0.5381 - top5-acc: 0.9423 - val_loss: 1.2330 - val_acc: 0.5618 - val_top5-acc: 0.9522 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2830 - acc: 0.5406 - top5-acc: 0.9439 - val_loss: 1.2013 - val_acc: 0.5764 - val_top5-acc: 0.9552 - lr: 6.2500e-04\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2868 - acc: 0.5418 - top5-acc: 0.9428 - val_loss: 1.2096 - val_acc: 0.5666 - val_top5-acc: 0.9546 - lr: 6.2500e-04\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2826 - acc: 0.5404 - top5-acc: 0.9442 - val_loss: 1.2274 - val_acc: 0.5598 - val_top5-acc: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2833 - acc: 0.5423 - top5-acc: 0.9426 - val_loss: 1.2142 - val_acc: 0.5710 - val_top5-acc: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2817 - acc: 0.5449 - top5-acc: 0.9437 - val_loss: 1.2189 - val_acc: 0.5640 - val_top5-acc: 0.9538 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2803 - acc: 0.5418 - top5-acc: 0.9427 - val_loss: 1.2180 - val_acc: 0.5654 - val_top5-acc: 0.9520 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2769 - acc: 0.5468 - top5-acc: 0.9442 - val_loss: 1.2132 - val_acc: 0.5636 - val_top5-acc: 0.9538 - lr: 3.1250e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2765 - acc: 0.5479 - top5-acc: 0.9432 - val_loss: 1.2144 - val_acc: 0.5678 - val_top5-acc: 0.9534 - lr: 3.1250e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2763 - acc: 0.5488 - top5-acc: 0.9444 - val_loss: 1.2211 - val_acc: 0.5656 - val_top5-acc: 0.9530 - lr: 3.1250e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2793 - acc: 0.5440 - top5-acc: 0.9437 - val_loss: 1.2019 - val_acc: 0.5724 - val_top5-acc: 0.9570 - lr: 3.1250e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2732 - acc: 0.5468 - top5-acc: 0.9448 - val_loss: 1.2143 - val_acc: 0.5716 - val_top5-acc: 0.9518 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2760 - acc: 0.5461 - top5-acc: 0.9435 - val_loss: 1.2144 - val_acc: 0.5692 - val_top5-acc: 0.9524 - lr: 1.5625e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2712 - acc: 0.5503 - top5-acc: 0.9440 - val_loss: 1.2085 - val_acc: 0.5710 - val_top5-acc: 0.9542 - lr: 1.5625e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2743 - acc: 0.5472 - top5-acc: 0.9447 - val_loss: 1.2107 - val_acc: 0.5690 - val_top5-acc: 0.9556 - lr: 1.5625e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2754 - acc: 0.5507 - top5-acc: 0.9438 - val_loss: 1.2024 - val_acc: 0.5724 - val_top5-acc: 0.9568 - lr: 1.5625e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2764 - acc: 0.5493 - top5-acc: 0.9438 - val_loss: 1.2090 - val_acc: 0.5690 - val_top5-acc: 0.9542 - lr: 1.5625e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2726 - acc: 0.5482 - top5-acc: 0.9440 - val_loss: 1.2160 - val_acc: 0.5674 - val_top5-acc: 0.9530 - lr: 7.8125e-05\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2749 - acc: 0.5482 - top5-acc: 0.9440 - val_loss: 1.2131 - val_acc: 0.5704 - val_top5-acc: 0.9546 - lr: 7.8125e-05\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2748 - acc: 0.5470 - top5-acc: 0.9442 - val_loss: 1.2156 - val_acc: 0.5674 - val_top5-acc: 0.9550 - lr: 7.8125e-05\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2731 - acc: 0.5474 - top5-acc: 0.9444 - val_loss: 1.2117 - val_acc: 0.5720 - val_top5-acc: 0.9540 - lr: 7.8125e-05\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2750 - acc: 0.5461 - top5-acc: 0.9442 - val_loss: 1.2130 - val_acc: 0.5716 - val_top5-acc: 0.9536 - lr: 7.8125e-05\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2757 - acc: 0.5480 - top5-acc: 0.9453 - val_loss: 1.2137 - val_acc: 0.5674 - val_top5-acc: 0.9538 - lr: 3.9062e-05\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.2757 - acc: 0.5496 - top5-acc: 0.9439 - val_loss: 1.2149 - val_acc: 0.5666 - val_top5-acc: 0.9546 - lr: 3.9062e-05\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 1.2350 - acc: 0.5595 - top5-acc: 0.9463\n",
      "Test accuracy: 55.95%\n",
      "Test top 5 accuracy: 94.63%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 1.9112 - acc: 0.3669 - top5-acc: 0.8629WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 6s 54ms/step - loss: 1.9082 - acc: 0.3673 - top5-acc: 0.8635 - val_loss: 1.4451 - val_acc: 0.4866 - val_top5-acc: 0.9274 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5106 - acc: 0.4620 - top5-acc: 0.9166 - val_loss: 1.4187 - val_acc: 0.4972 - val_top5-acc: 0.9318 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4491 - acc: 0.4836 - top5-acc: 0.9258 - val_loss: 1.3548 - val_acc: 0.5148 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4414 - acc: 0.4915 - top5-acc: 0.9251 - val_loss: 1.3380 - val_acc: 0.5266 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4014 - acc: 0.5020 - top5-acc: 0.9304 - val_loss: 1.3319 - val_acc: 0.5274 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4051 - acc: 0.5035 - top5-acc: 0.9309 - val_loss: 1.3372 - val_acc: 0.5264 - val_top5-acc: 0.9376 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3891 - acc: 0.5101 - top5-acc: 0.9332 - val_loss: 1.3651 - val_acc: 0.5142 - val_top5-acc: 0.9426 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3717 - acc: 0.5126 - top5-acc: 0.9334 - val_loss: 1.3106 - val_acc: 0.5434 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3655 - acc: 0.5153 - top5-acc: 0.9357 - val_loss: 1.3183 - val_acc: 0.5288 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3640 - acc: 0.5174 - top5-acc: 0.9348 - val_loss: 1.3164 - val_acc: 0.5346 - val_top5-acc: 0.9428 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3681 - acc: 0.5151 - top5-acc: 0.9340 - val_loss: 1.2848 - val_acc: 0.5402 - val_top5-acc: 0.9430 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3595 - acc: 0.5196 - top5-acc: 0.9360 - val_loss: 1.3323 - val_acc: 0.5148 - val_top5-acc: 0.9512 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3691 - acc: 0.5148 - top5-acc: 0.9355 - val_loss: 1.2978 - val_acc: 0.5400 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3457 - acc: 0.5230 - top5-acc: 0.9381 - val_loss: 1.2674 - val_acc: 0.5506 - val_top5-acc: 0.9454 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3564 - acc: 0.5180 - top5-acc: 0.9364 - val_loss: 1.3105 - val_acc: 0.5410 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3511 - acc: 0.5196 - top5-acc: 0.9349 - val_loss: 1.3135 - val_acc: 0.5312 - val_top5-acc: 0.9430 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3572 - acc: 0.5172 - top5-acc: 0.9365 - val_loss: 1.3174 - val_acc: 0.5362 - val_top5-acc: 0.9442 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3513 - acc: 0.5224 - top5-acc: 0.9372 - val_loss: 1.2240 - val_acc: 0.5616 - val_top5-acc: 0.9542 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3500 - acc: 0.5241 - top5-acc: 0.9360 - val_loss: 1.2986 - val_acc: 0.5368 - val_top5-acc: 0.9486 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3391 - acc: 0.5256 - top5-acc: 0.9384 - val_loss: 1.2836 - val_acc: 0.5444 - val_top5-acc: 0.9434 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3499 - acc: 0.5233 - top5-acc: 0.9371 - val_loss: 1.3106 - val_acc: 0.5332 - val_top5-acc: 0.9470 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3552 - acc: 0.5194 - top5-acc: 0.9359 - val_loss: 1.2933 - val_acc: 0.5446 - val_top5-acc: 0.9464 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3414 - acc: 0.5267 - top5-acc: 0.9375 - val_loss: 1.3680 - val_acc: 0.5088 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 1.3095 - acc: 0.5352 - top5-acc: 0.9402 - val_loss: 1.2288 - val_acc: 0.5560 - val_top5-acc: 0.9516 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3067 - acc: 0.5336 - top5-acc: 0.9418 - val_loss: 1.2624 - val_acc: 0.5464 - val_top5-acc: 0.9496 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3086 - acc: 0.5353 - top5-acc: 0.9420 - val_loss: 1.2448 - val_acc: 0.5560 - val_top5-acc: 0.9516 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3058 - acc: 0.5365 - top5-acc: 0.9395 - val_loss: 1.2548 - val_acc: 0.5542 - val_top5-acc: 0.9498 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 1.3068 - acc: 0.5338 - top5-acc: 0.9401 - val_loss: 1.2505 - val_acc: 0.5556 - val_top5-acc: 0.9514 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2883 - acc: 0.5433 - top5-acc: 0.9435 - val_loss: 1.2503 - val_acc: 0.5590 - val_top5-acc: 0.9506 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2854 - acc: 0.5420 - top5-acc: 0.9413 - val_loss: 1.2141 - val_acc: 0.5688 - val_top5-acc: 0.9534 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2786 - acc: 0.5452 - top5-acc: 0.9410 - val_loss: 1.2177 - val_acc: 0.5614 - val_top5-acc: 0.9508 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2792 - acc: 0.5459 - top5-acc: 0.9427 - val_loss: 1.2469 - val_acc: 0.5522 - val_top5-acc: 0.9512 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2887 - acc: 0.5403 - top5-acc: 0.9406 - val_loss: 1.2483 - val_acc: 0.5528 - val_top5-acc: 0.9488 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2817 - acc: 0.5415 - top5-acc: 0.9428 - val_loss: 1.2195 - val_acc: 0.5660 - val_top5-acc: 0.9526 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2834 - acc: 0.5441 - top5-acc: 0.9426 - val_loss: 1.2442 - val_acc: 0.5550 - val_top5-acc: 0.9502 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2797 - acc: 0.5457 - top5-acc: 0.9425 - val_loss: 1.2637 - val_acc: 0.5464 - val_top5-acc: 0.9514 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2747 - acc: 0.5493 - top5-acc: 0.9440 - val_loss: 1.2256 - val_acc: 0.5558 - val_top5-acc: 0.9534 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2787 - acc: 0.5440 - top5-acc: 0.9420 - val_loss: 1.2139 - val_acc: 0.5636 - val_top5-acc: 0.9518 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2738 - acc: 0.5466 - top5-acc: 0.9440 - val_loss: 1.2228 - val_acc: 0.5626 - val_top5-acc: 0.9518 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2696 - acc: 0.5468 - top5-acc: 0.9444 - val_loss: 1.2422 - val_acc: 0.5536 - val_top5-acc: 0.9522 - lr: 6.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2764 - acc: 0.5462 - top5-acc: 0.9435 - val_loss: 1.2259 - val_acc: 0.5638 - val_top5-acc: 0.9524 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2763 - acc: 0.5450 - top5-acc: 0.9435 - val_loss: 1.2170 - val_acc: 0.5646 - val_top5-acc: 0.9538 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2764 - acc: 0.5444 - top5-acc: 0.9430 - val_loss: 1.2285 - val_acc: 0.5592 - val_top5-acc: 0.9538 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2683 - acc: 0.5524 - top5-acc: 0.9438 - val_loss: 1.2228 - val_acc: 0.5594 - val_top5-acc: 0.9526 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2673 - acc: 0.5496 - top5-acc: 0.9438 - val_loss: 1.2237 - val_acc: 0.5634 - val_top5-acc: 0.9530 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2714 - acc: 0.5508 - top5-acc: 0.9445 - val_loss: 1.2307 - val_acc: 0.5580 - val_top5-acc: 0.9536 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2678 - acc: 0.5502 - top5-acc: 0.9437 - val_loss: 1.2259 - val_acc: 0.5610 - val_top5-acc: 0.9516 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2720 - acc: 0.5488 - top5-acc: 0.9430 - val_loss: 1.2254 - val_acc: 0.5642 - val_top5-acc: 0.9526 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2728 - acc: 0.5490 - top5-acc: 0.9430 - val_loss: 1.2097 - val_acc: 0.5700 - val_top5-acc: 0.9532 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2707 - acc: 0.5507 - top5-acc: 0.9420 - val_loss: 1.2180 - val_acc: 0.5648 - val_top5-acc: 0.9512 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 1.2293 - acc: 0.5610 - top5-acc: 0.9488\n",
      "Test accuracy: 56.1%\n",
      "Test top 5 accuracy: 94.88%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 1.7994 - acc: 0.3977 - top5-acc: 0.8728WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 7s 62ms/step - loss: 1.7964 - acc: 0.3981 - top5-acc: 0.8733 - val_loss: 1.4372 - val_acc: 0.4886 - val_top5-acc: 0.9336 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4440 - acc: 0.4920 - top5-acc: 0.9236 - val_loss: 1.2918 - val_acc: 0.5398 - val_top5-acc: 0.9434 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3758 - acc: 0.5136 - top5-acc: 0.9314 - val_loss: 1.2744 - val_acc: 0.5372 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3602 - acc: 0.5203 - top5-acc: 0.9353 - val_loss: 1.2341 - val_acc: 0.5558 - val_top5-acc: 0.9486 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3195 - acc: 0.5326 - top5-acc: 0.9389 - val_loss: 1.2019 - val_acc: 0.5742 - val_top5-acc: 0.9526 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3110 - acc: 0.5343 - top5-acc: 0.9413 - val_loss: 1.2081 - val_acc: 0.5694 - val_top5-acc: 0.9516 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3108 - acc: 0.5357 - top5-acc: 0.9402 - val_loss: 1.2165 - val_acc: 0.5656 - val_top5-acc: 0.9520 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2859 - acc: 0.5437 - top5-acc: 0.9426 - val_loss: 1.2341 - val_acc: 0.5622 - val_top5-acc: 0.9484 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2966 - acc: 0.5398 - top5-acc: 0.9399 - val_loss: 1.2023 - val_acc: 0.5770 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2863 - acc: 0.5468 - top5-acc: 0.9428 - val_loss: 1.2183 - val_acc: 0.5700 - val_top5-acc: 0.9532 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2448 - acc: 0.5589 - top5-acc: 0.9472 - val_loss: 1.2211 - val_acc: 0.5626 - val_top5-acc: 0.9490 - lr: 0.0025\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2472 - acc: 0.5556 - top5-acc: 0.9461 - val_loss: 1.1774 - val_acc: 0.5810 - val_top5-acc: 0.9520 - lr: 0.0025\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2466 - acc: 0.5582 - top5-acc: 0.9456 - val_loss: 1.2038 - val_acc: 0.5708 - val_top5-acc: 0.9500 - lr: 0.0025\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2527 - acc: 0.5589 - top5-acc: 0.9442 - val_loss: 1.1774 - val_acc: 0.5726 - val_top5-acc: 0.9542 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2500 - acc: 0.5571 - top5-acc: 0.9452 - val_loss: 1.1593 - val_acc: 0.5866 - val_top5-acc: 0.9568 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2426 - acc: 0.5568 - top5-acc: 0.9464 - val_loss: 1.1608 - val_acc: 0.5912 - val_top5-acc: 0.9560 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2571 - acc: 0.5510 - top5-acc: 0.9455 - val_loss: 1.1772 - val_acc: 0.5780 - val_top5-acc: 0.9570 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2504 - acc: 0.5565 - top5-acc: 0.9455 - val_loss: 1.1749 - val_acc: 0.5776 - val_top5-acc: 0.9538 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2335 - acc: 0.5621 - top5-acc: 0.9474 - val_loss: 1.1757 - val_acc: 0.5780 - val_top5-acc: 0.9524 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2465 - acc: 0.5574 - top5-acc: 0.9482 - val_loss: 1.1941 - val_acc: 0.5712 - val_top5-acc: 0.9560 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2289 - acc: 0.5632 - top5-acc: 0.9485 - val_loss: 1.1624 - val_acc: 0.5882 - val_top5-acc: 0.9548 - lr: 0.0012\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2262 - acc: 0.5643 - top5-acc: 0.9488 - val_loss: 1.1636 - val_acc: 0.5832 - val_top5-acc: 0.9550 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.2268 - acc: 0.5657 - top5-acc: 0.9484 - val_loss: 1.1590 - val_acc: 0.5870 - val_top5-acc: 0.9538 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2290 - acc: 0.5619 - top5-acc: 0.9490 - val_loss: 1.1680 - val_acc: 0.5804 - val_top5-acc: 0.9536 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2251 - acc: 0.5655 - top5-acc: 0.9478 - val_loss: 1.1325 - val_acc: 0.5954 - val_top5-acc: 0.9566 - lr: 0.0012\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2277 - acc: 0.5637 - top5-acc: 0.9476 - val_loss: 1.1729 - val_acc: 0.5796 - val_top5-acc: 0.9518 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2273 - acc: 0.5672 - top5-acc: 0.9473 - val_loss: 1.1544 - val_acc: 0.5848 - val_top5-acc: 0.9554 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2267 - acc: 0.5605 - top5-acc: 0.9484 - val_loss: 1.1532 - val_acc: 0.5930 - val_top5-acc: 0.9558 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2258 - acc: 0.5662 - top5-acc: 0.9486 - val_loss: 1.1530 - val_acc: 0.5892 - val_top5-acc: 0.9564 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2235 - acc: 0.5666 - top5-acc: 0.9491 - val_loss: 1.1638 - val_acc: 0.5820 - val_top5-acc: 0.9536 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2161 - acc: 0.5686 - top5-acc: 0.9498 - val_loss: 1.1413 - val_acc: 0.5952 - val_top5-acc: 0.9580 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2122 - acc: 0.5704 - top5-acc: 0.9496 - val_loss: 1.1514 - val_acc: 0.5854 - val_top5-acc: 0.9554 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2151 - acc: 0.5666 - top5-acc: 0.9483 - val_loss: 1.1621 - val_acc: 0.5818 - val_top5-acc: 0.9540 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2144 - acc: 0.5706 - top5-acc: 0.9484 - val_loss: 1.1490 - val_acc: 0.5952 - val_top5-acc: 0.9554 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2179 - acc: 0.5675 - top5-acc: 0.9499 - val_loss: 1.1562 - val_acc: 0.5906 - val_top5-acc: 0.9538 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.2134 - acc: 0.5678 - top5-acc: 0.9486 - val_loss: 1.1442 - val_acc: 0.5902 - val_top5-acc: 0.9558 - lr: 3.1250e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2117 - acc: 0.5709 - top5-acc: 0.9491 - val_loss: 1.1443 - val_acc: 0.5948 - val_top5-acc: 0.9560 - lr: 3.1250e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2133 - acc: 0.5717 - top5-acc: 0.9485 - val_loss: 1.1515 - val_acc: 0.5904 - val_top5-acc: 0.9562 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.2132 - acc: 0.5699 - top5-acc: 0.9494 - val_loss: 1.1563 - val_acc: 0.5860 - val_top5-acc: 0.9544 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2146 - acc: 0.5710 - top5-acc: 0.9486 - val_loss: 1.1478 - val_acc: 0.5900 - val_top5-acc: 0.9550 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.2123 - acc: 0.5740 - top5-acc: 0.9491 - val_loss: 1.1413 - val_acc: 0.5940 - val_top5-acc: 0.9564 - lr: 1.5625e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2099 - acc: 0.5720 - top5-acc: 0.9486 - val_loss: 1.1436 - val_acc: 0.5938 - val_top5-acc: 0.9570 - lr: 1.5625e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2087 - acc: 0.5722 - top5-acc: 0.9497 - val_loss: 1.1486 - val_acc: 0.5916 - val_top5-acc: 0.9552 - lr: 1.5625e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2115 - acc: 0.5696 - top5-acc: 0.9493 - val_loss: 1.1534 - val_acc: 0.5900 - val_top5-acc: 0.9550 - lr: 1.5625e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2102 - acc: 0.5731 - top5-acc: 0.9495 - val_loss: 1.1501 - val_acc: 0.5904 - val_top5-acc: 0.9548 - lr: 1.5625e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2140 - acc: 0.5720 - top5-acc: 0.9490 - val_loss: 1.1483 - val_acc: 0.5930 - val_top5-acc: 0.9552 - lr: 7.8125e-05\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.2115 - acc: 0.5710 - top5-acc: 0.9489 - val_loss: 1.1485 - val_acc: 0.5902 - val_top5-acc: 0.9552 - lr: 7.8125e-05\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2099 - acc: 0.5752 - top5-acc: 0.9491 - val_loss: 1.1499 - val_acc: 0.5890 - val_top5-acc: 0.9562 - lr: 7.8125e-05\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2127 - acc: 0.5719 - top5-acc: 0.9481 - val_loss: 1.1473 - val_acc: 0.5952 - val_top5-acc: 0.9560 - lr: 7.8125e-05\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2141 - acc: 0.5720 - top5-acc: 0.9489 - val_loss: 1.1521 - val_acc: 0.5914 - val_top5-acc: 0.9550 - lr: 7.8125e-05\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.1755 - acc: 0.5860 - top5-acc: 0.9543\n",
      "Test accuracy: 58.6%\n",
      "Test top 5 accuracy: 95.43%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8749 - acc: 0.4005 - top5-acc: 0.8599WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 7s 69ms/step - loss: 1.8749 - acc: 0.4005 - top5-acc: 0.8599 - val_loss: 1.2984 - val_acc: 0.5338 - val_top5-acc: 0.9412 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3835 - acc: 0.5148 - top5-acc: 0.9274 - val_loss: 1.2422 - val_acc: 0.5480 - val_top5-acc: 0.9510 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3251 - acc: 0.5342 - top5-acc: 0.9356 - val_loss: 1.1765 - val_acc: 0.5860 - val_top5-acc: 0.9522 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2841 - acc: 0.5469 - top5-acc: 0.9418 - val_loss: 1.2027 - val_acc: 0.5720 - val_top5-acc: 0.9482 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2731 - acc: 0.5526 - top5-acc: 0.9431 - val_loss: 1.1598 - val_acc: 0.5820 - val_top5-acc: 0.9566 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.2649 - acc: 0.5556 - top5-acc: 0.9439 - val_loss: 1.1756 - val_acc: 0.5790 - val_top5-acc: 0.9602 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.2568 - acc: 0.5589 - top5-acc: 0.9450 - val_loss: 1.1174 - val_acc: 0.6014 - val_top5-acc: 0.9592 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2443 - acc: 0.5633 - top5-acc: 0.9453 - val_loss: 1.1086 - val_acc: 0.6050 - val_top5-acc: 0.9636 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2479 - acc: 0.5623 - top5-acc: 0.9430 - val_loss: 1.1732 - val_acc: 0.5894 - val_top5-acc: 0.9572 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2392 - acc: 0.5643 - top5-acc: 0.9465 - val_loss: 1.1785 - val_acc: 0.5814 - val_top5-acc: 0.9570 - lr: 0.0050\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2400 - acc: 0.5625 - top5-acc: 0.9474 - val_loss: 1.1576 - val_acc: 0.5922 - val_top5-acc: 0.9534 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2344 - acc: 0.5665 - top5-acc: 0.9460 - val_loss: 1.1301 - val_acc: 0.5992 - val_top5-acc: 0.9612 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2331 - acc: 0.5674 - top5-acc: 0.9471 - val_loss: 1.1225 - val_acc: 0.5932 - val_top5-acc: 0.9606 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1949 - acc: 0.5822 - top5-acc: 0.9487 - val_loss: 1.1033 - val_acc: 0.6082 - val_top5-acc: 0.9624 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1922 - acc: 0.5816 - top5-acc: 0.9497 - val_loss: 1.0970 - val_acc: 0.6080 - val_top5-acc: 0.9638 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1955 - acc: 0.5814 - top5-acc: 0.9504 - val_loss: 1.1173 - val_acc: 0.6028 - val_top5-acc: 0.9612 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2000 - acc: 0.5791 - top5-acc: 0.9487 - val_loss: 1.1151 - val_acc: 0.6016 - val_top5-acc: 0.9630 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.1976 - acc: 0.5787 - top5-acc: 0.9502 - val_loss: 1.0950 - val_acc: 0.6096 - val_top5-acc: 0.9644 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1976 - acc: 0.5806 - top5-acc: 0.9491 - val_loss: 1.1151 - val_acc: 0.6074 - val_top5-acc: 0.9614 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1992 - acc: 0.5776 - top5-acc: 0.9495 - val_loss: 1.1135 - val_acc: 0.6088 - val_top5-acc: 0.9592 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1958 - acc: 0.5804 - top5-acc: 0.9494 - val_loss: 1.1231 - val_acc: 0.6028 - val_top5-acc: 0.9642 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2015 - acc: 0.5754 - top5-acc: 0.9493 - val_loss: 1.0978 - val_acc: 0.6098 - val_top5-acc: 0.9612 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1899 - acc: 0.5833 - top5-acc: 0.9502 - val_loss: 1.1078 - val_acc: 0.6072 - val_top5-acc: 0.9636 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1756 - acc: 0.5875 - top5-acc: 0.9520 - val_loss: 1.0827 - val_acc: 0.6146 - val_top5-acc: 0.9676 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1828 - acc: 0.5835 - top5-acc: 0.9509 - val_loss: 1.1038 - val_acc: 0.6116 - val_top5-acc: 0.9606 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1766 - acc: 0.5868 - top5-acc: 0.9522 - val_loss: 1.0926 - val_acc: 0.6068 - val_top5-acc: 0.9658 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1766 - acc: 0.5879 - top5-acc: 0.9516 - val_loss: 1.1382 - val_acc: 0.5894 - val_top5-acc: 0.9640 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1776 - acc: 0.5842 - top5-acc: 0.9510 - val_loss: 1.0900 - val_acc: 0.6140 - val_top5-acc: 0.9632 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1821 - acc: 0.5860 - top5-acc: 0.9503 - val_loss: 1.0964 - val_acc: 0.6096 - val_top5-acc: 0.9630 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1714 - acc: 0.5900 - top5-acc: 0.9520 - val_loss: 1.1004 - val_acc: 0.6070 - val_top5-acc: 0.9638 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1679 - acc: 0.5905 - top5-acc: 0.9522 - val_loss: 1.0998 - val_acc: 0.6080 - val_top5-acc: 0.9622 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1654 - acc: 0.5918 - top5-acc: 0.9517 - val_loss: 1.0874 - val_acc: 0.6138 - val_top5-acc: 0.9640 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1694 - acc: 0.5902 - top5-acc: 0.9520 - val_loss: 1.1048 - val_acc: 0.6070 - val_top5-acc: 0.9636 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1695 - acc: 0.5912 - top5-acc: 0.9505 - val_loss: 1.0970 - val_acc: 0.6070 - val_top5-acc: 0.9654 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1664 - acc: 0.5894 - top5-acc: 0.9519 - val_loss: 1.0880 - val_acc: 0.6134 - val_top5-acc: 0.9662 - lr: 3.1250e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1635 - acc: 0.5944 - top5-acc: 0.9508 - val_loss: 1.0954 - val_acc: 0.6096 - val_top5-acc: 0.9634 - lr: 3.1250e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1662 - acc: 0.5902 - top5-acc: 0.9520 - val_loss: 1.0895 - val_acc: 0.6130 - val_top5-acc: 0.9632 - lr: 3.1250e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1647 - acc: 0.5916 - top5-acc: 0.9524 - val_loss: 1.0812 - val_acc: 0.6168 - val_top5-acc: 0.9648 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1621 - acc: 0.5930 - top5-acc: 0.9527 - val_loss: 1.0849 - val_acc: 0.6142 - val_top5-acc: 0.9648 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1706 - acc: 0.5866 - top5-acc: 0.9518 - val_loss: 1.0894 - val_acc: 0.6134 - val_top5-acc: 0.9648 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1647 - acc: 0.5934 - top5-acc: 0.9511 - val_loss: 1.0947 - val_acc: 0.6102 - val_top5-acc: 0.9648 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1648 - acc: 0.5920 - top5-acc: 0.9509 - val_loss: 1.0960 - val_acc: 0.6096 - val_top5-acc: 0.9638 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1743 - acc: 0.5866 - top5-acc: 0.9513 - val_loss: 1.0924 - val_acc: 0.6134 - val_top5-acc: 0.9652 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1636 - acc: 0.5942 - top5-acc: 0.9518 - val_loss: 1.0930 - val_acc: 0.6100 - val_top5-acc: 0.9646 - lr: 1.5625e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1698 - acc: 0.5925 - top5-acc: 0.9510 - val_loss: 1.0831 - val_acc: 0.6138 - val_top5-acc: 0.9662 - lr: 1.5625e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1655 - acc: 0.5958 - top5-acc: 0.9520 - val_loss: 1.0945 - val_acc: 0.6088 - val_top5-acc: 0.9632 - lr: 1.5625e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1618 - acc: 0.5947 - top5-acc: 0.9529 - val_loss: 1.0863 - val_acc: 0.6160 - val_top5-acc: 0.9658 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1685 - acc: 0.5898 - top5-acc: 0.9520 - val_loss: 1.0906 - val_acc: 0.6126 - val_top5-acc: 0.9650 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1648 - acc: 0.5948 - top5-acc: 0.9538 - val_loss: 1.0906 - val_acc: 0.6120 - val_top5-acc: 0.9662 - lr: 7.8125e-05\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.1639 - acc: 0.5928 - top5-acc: 0.9526 - val_loss: 1.0897 - val_acc: 0.6134 - val_top5-acc: 0.9656 - lr: 7.8125e-05\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 1.1038 - acc: 0.6116 - top5-acc: 0.9593\n",
      "Test accuracy: 61.16%\n",
      "Test top 5 accuracy: 95.93%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.5389 - acc: 0.4926 - top5-acc: 0.9083WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 8s 79ms/step - loss: 1.5389 - acc: 0.4926 - top5-acc: 0.9083 - val_loss: 1.1175 - val_acc: 0.6044 - val_top5-acc: 0.9586 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1693 - acc: 0.5900 - top5-acc: 0.9542 - val_loss: 1.1005 - val_acc: 0.6114 - val_top5-acc: 0.9642 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1160 - acc: 0.6069 - top5-acc: 0.9582 - val_loss: 1.0406 - val_acc: 0.6354 - val_top5-acc: 0.9646 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.0873 - acc: 0.6159 - top5-acc: 0.9616 - val_loss: 1.0489 - val_acc: 0.6346 - val_top5-acc: 0.9680 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0947 - acc: 0.6138 - top5-acc: 0.9600 - val_loss: 1.0372 - val_acc: 0.6356 - val_top5-acc: 0.9676 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.0715 - acc: 0.6210 - top5-acc: 0.9621 - val_loss: 1.0475 - val_acc: 0.6350 - val_top5-acc: 0.9646 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.0710 - acc: 0.6221 - top5-acc: 0.9628 - val_loss: 1.0539 - val_acc: 0.6432 - val_top5-acc: 0.9630 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0663 - acc: 0.6222 - top5-acc: 0.9634 - val_loss: 1.0454 - val_acc: 0.6344 - val_top5-acc: 0.9696 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.0661 - acc: 0.6240 - top5-acc: 0.9629 - val_loss: 1.0504 - val_acc: 0.6332 - val_top5-acc: 0.9668 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0632 - acc: 0.6244 - top5-acc: 0.9631 - val_loss: 1.0343 - val_acc: 0.6372 - val_top5-acc: 0.9680 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0592 - acc: 0.6246 - top5-acc: 0.9648 - val_loss: 1.0248 - val_acc: 0.6476 - val_top5-acc: 0.9686 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0745 - acc: 0.6225 - top5-acc: 0.9635 - val_loss: 1.0163 - val_acc: 0.6448 - val_top5-acc: 0.9700 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0518 - acc: 0.6275 - top5-acc: 0.9640 - val_loss: 1.0505 - val_acc: 0.6380 - val_top5-acc: 0.9652 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0648 - acc: 0.6256 - top5-acc: 0.9628 - val_loss: 0.9943 - val_acc: 0.6462 - val_top5-acc: 0.9690 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0518 - acc: 0.6275 - top5-acc: 0.9651 - val_loss: 1.0545 - val_acc: 0.6396 - val_top5-acc: 0.9672 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0505 - acc: 0.6293 - top5-acc: 0.9647 - val_loss: 1.1098 - val_acc: 0.6252 - val_top5-acc: 0.9638 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0576 - acc: 0.6268 - top5-acc: 0.9641 - val_loss: 1.0645 - val_acc: 0.6300 - val_top5-acc: 0.9660 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0544 - acc: 0.6298 - top5-acc: 0.9652 - val_loss: 1.0237 - val_acc: 0.6454 - val_top5-acc: 0.9676 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0539 - acc: 0.6274 - top5-acc: 0.9646 - val_loss: 0.9998 - val_acc: 0.6604 - val_top5-acc: 0.9702 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0248 - acc: 0.6383 - top5-acc: 0.9665 - val_loss: 1.0118 - val_acc: 0.6480 - val_top5-acc: 0.9682 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0275 - acc: 0.6361 - top5-acc: 0.9671 - val_loss: 0.9829 - val_acc: 0.6546 - val_top5-acc: 0.9704 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0246 - acc: 0.6364 - top5-acc: 0.9664 - val_loss: 0.9761 - val_acc: 0.6590 - val_top5-acc: 0.9708 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0256 - acc: 0.6382 - top5-acc: 0.9667 - val_loss: 0.9956 - val_acc: 0.6564 - val_top5-acc: 0.9700 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0238 - acc: 0.6363 - top5-acc: 0.9664 - val_loss: 1.0013 - val_acc: 0.6548 - val_top5-acc: 0.9682 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0274 - acc: 0.6350 - top5-acc: 0.9668 - val_loss: 0.9963 - val_acc: 0.6540 - val_top5-acc: 0.9670 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0262 - acc: 0.6382 - top5-acc: 0.9661 - val_loss: 0.9776 - val_acc: 0.6590 - val_top5-acc: 0.9694 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0221 - acc: 0.6379 - top5-acc: 0.9667 - val_loss: 0.9874 - val_acc: 0.6566 - val_top5-acc: 0.9708 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.0130 - acc: 0.6420 - top5-acc: 0.9674 - val_loss: 0.9667 - val_acc: 0.6672 - val_top5-acc: 0.9716 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0066 - acc: 0.6444 - top5-acc: 0.9670 - val_loss: 0.9764 - val_acc: 0.6616 - val_top5-acc: 0.9704 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0141 - acc: 0.6415 - top5-acc: 0.9670 - val_loss: 0.9684 - val_acc: 0.6670 - val_top5-acc: 0.9704 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0080 - acc: 0.6462 - top5-acc: 0.9680 - val_loss: 0.9573 - val_acc: 0.6694 - val_top5-acc: 0.9700 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0068 - acc: 0.6455 - top5-acc: 0.9673 - val_loss: 0.9791 - val_acc: 0.6630 - val_top5-acc: 0.9696 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0110 - acc: 0.6441 - top5-acc: 0.9662 - val_loss: 0.9961 - val_acc: 0.6534 - val_top5-acc: 0.9688 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0140 - acc: 0.6434 - top5-acc: 0.9666 - val_loss: 0.9656 - val_acc: 0.6696 - val_top5-acc: 0.9704 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0072 - acc: 0.6452 - top5-acc: 0.9670 - val_loss: 0.9883 - val_acc: 0.6542 - val_top5-acc: 0.9696 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0121 - acc: 0.6443 - top5-acc: 0.9667 - val_loss: 0.9791 - val_acc: 0.6600 - val_top5-acc: 0.9702 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0070 - acc: 0.6473 - top5-acc: 0.9673 - val_loss: 0.9660 - val_acc: 0.6650 - val_top5-acc: 0.9698 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0083 - acc: 0.6462 - top5-acc: 0.9668 - val_loss: 0.9614 - val_acc: 0.6650 - val_top5-acc: 0.9712 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0024 - acc: 0.6480 - top5-acc: 0.9679 - val_loss: 0.9639 - val_acc: 0.6676 - val_top5-acc: 0.9700 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0020 - acc: 0.6458 - top5-acc: 0.9678 - val_loss: 0.9614 - val_acc: 0.6670 - val_top5-acc: 0.9704 - lr: 6.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0014 - acc: 0.6450 - top5-acc: 0.9666 - val_loss: 0.9665 - val_acc: 0.6650 - val_top5-acc: 0.9720 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 0.9971 - acc: 0.6490 - top5-acc: 0.9679 - val_loss: 0.9587 - val_acc: 0.6694 - val_top5-acc: 0.9704 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0028 - acc: 0.6480 - top5-acc: 0.9672 - val_loss: 0.9624 - val_acc: 0.6686 - val_top5-acc: 0.9696 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 0.9974 - acc: 0.6480 - top5-acc: 0.9680 - val_loss: 0.9653 - val_acc: 0.6618 - val_top5-acc: 0.9700 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 0.9992 - acc: 0.6495 - top5-acc: 0.9672 - val_loss: 0.9701 - val_acc: 0.6604 - val_top5-acc: 0.9706 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.0010 - acc: 0.6487 - top5-acc: 0.9680 - val_loss: 0.9674 - val_acc: 0.6646 - val_top5-acc: 0.9696 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.0022 - acc: 0.6486 - top5-acc: 0.9665 - val_loss: 0.9656 - val_acc: 0.6636 - val_top5-acc: 0.9698 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 0.9980 - acc: 0.6478 - top5-acc: 0.9676 - val_loss: 0.9644 - val_acc: 0.6630 - val_top5-acc: 0.9698 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 0.9990 - acc: 0.6498 - top5-acc: 0.9681 - val_loss: 0.9640 - val_acc: 0.6672 - val_top5-acc: 0.9702 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 0.9986 - acc: 0.6477 - top5-acc: 0.9674 - val_loss: 0.9684 - val_acc: 0.6654 - val_top5-acc: 0.9690 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 0.9996 - acc: 0.6456 - top5-acc: 0.9683\n",
      "Test accuracy: 64.56%\n",
      "Test top 5 accuracy: 96.83%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.9549 - acc: 0.6784 - top5-acc: 0.9654WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 9s 87ms/step - loss: 0.9549 - acc: 0.6784 - top5-acc: 0.9654 - val_loss: 0.8562 - val_acc: 0.7202 - val_top5-acc: 0.9840 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7539 - acc: 0.7375 - top5-acc: 0.9837 - val_loss: 0.8299 - val_acc: 0.7282 - val_top5-acc: 0.9840 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7376 - acc: 0.7407 - top5-acc: 0.9853 - val_loss: 0.8124 - val_acc: 0.7318 - val_top5-acc: 0.9822 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7298 - acc: 0.7431 - top5-acc: 0.9846 - val_loss: 0.8125 - val_acc: 0.7328 - val_top5-acc: 0.9822 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7298 - acc: 0.7424 - top5-acc: 0.9857 - val_loss: 0.8241 - val_acc: 0.7318 - val_top5-acc: 0.9828 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7273 - acc: 0.7434 - top5-acc: 0.9850 - val_loss: 0.8151 - val_acc: 0.7314 - val_top5-acc: 0.9820 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7322 - acc: 0.7448 - top5-acc: 0.9849 - val_loss: 0.8117 - val_acc: 0.7330 - val_top5-acc: 0.9824 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7345 - acc: 0.7405 - top5-acc: 0.9852 - val_loss: 0.8091 - val_acc: 0.7316 - val_top5-acc: 0.9830 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7315 - acc: 0.7426 - top5-acc: 0.9850 - val_loss: 0.8183 - val_acc: 0.7296 - val_top5-acc: 0.9842 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7312 - acc: 0.7436 - top5-acc: 0.9849 - val_loss: 0.8219 - val_acc: 0.7268 - val_top5-acc: 0.9834 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7334 - acc: 0.7436 - top5-acc: 0.9850 - val_loss: 0.8127 - val_acc: 0.7314 - val_top5-acc: 0.9820 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7307 - acc: 0.7440 - top5-acc: 0.9845 - val_loss: 0.8243 - val_acc: 0.7284 - val_top5-acc: 0.9818 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.7282 - acc: 0.7425 - top5-acc: 0.9853 - val_loss: 0.8227 - val_acc: 0.7282 - val_top5-acc: 0.9828 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7184 - acc: 0.7459 - top5-acc: 0.9847 - val_loss: 0.7925 - val_acc: 0.7366 - val_top5-acc: 0.9822 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7076 - acc: 0.7510 - top5-acc: 0.9861 - val_loss: 0.7945 - val_acc: 0.7318 - val_top5-acc: 0.9830 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 0.7069 - acc: 0.7496 - top5-acc: 0.9857 - val_loss: 0.7994 - val_acc: 0.7332 - val_top5-acc: 0.9832 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7108 - acc: 0.7493 - top5-acc: 0.9857 - val_loss: 0.7991 - val_acc: 0.7340 - val_top5-acc: 0.9822 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7035 - acc: 0.7496 - top5-acc: 0.9856 - val_loss: 0.7932 - val_acc: 0.7356 - val_top5-acc: 0.9816 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.7078 - acc: 0.7505 - top5-acc: 0.9852 - val_loss: 0.7926 - val_acc: 0.7340 - val_top5-acc: 0.9826 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6977 - acc: 0.7525 - top5-acc: 0.9860 - val_loss: 0.7846 - val_acc: 0.7362 - val_top5-acc: 0.9826 - lr: 0.0012\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6976 - acc: 0.7524 - top5-acc: 0.9856 - val_loss: 0.7894 - val_acc: 0.7344 - val_top5-acc: 0.9820 - lr: 0.0012\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.6971 - acc: 0.7541 - top5-acc: 0.9854 - val_loss: 0.7857 - val_acc: 0.7334 - val_top5-acc: 0.9830 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.6976 - acc: 0.7540 - top5-acc: 0.9862 - val_loss: 0.7799 - val_acc: 0.7370 - val_top5-acc: 0.9828 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6984 - acc: 0.7542 - top5-acc: 0.9854 - val_loss: 0.7801 - val_acc: 0.7346 - val_top5-acc: 0.9834 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6957 - acc: 0.7556 - top5-acc: 0.9858 - val_loss: 0.7873 - val_acc: 0.7324 - val_top5-acc: 0.9824 - lr: 0.0012\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6953 - acc: 0.7545 - top5-acc: 0.9853 - val_loss: 0.7832 - val_acc: 0.7334 - val_top5-acc: 0.9828 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6964 - acc: 0.7547 - top5-acc: 0.9867 - val_loss: 0.7867 - val_acc: 0.7366 - val_top5-acc: 0.9826 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 0.6962 - acc: 0.7543 - top5-acc: 0.9853 - val_loss: 0.7880 - val_acc: 0.7336 - val_top5-acc: 0.9824 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 0.6907 - acc: 0.7560 - top5-acc: 0.9857 - val_loss: 0.7781 - val_acc: 0.7352 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 0.6900 - acc: 0.7569 - top5-acc: 0.9864 - val_loss: 0.7807 - val_acc: 0.7356 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6925 - acc: 0.7545 - top5-acc: 0.9865 - val_loss: 0.7773 - val_acc: 0.7354 - val_top5-acc: 0.9832 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6934 - acc: 0.7548 - top5-acc: 0.9854 - val_loss: 0.7778 - val_acc: 0.7372 - val_top5-acc: 0.9832 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 0.6859 - acc: 0.7592 - top5-acc: 0.9861 - val_loss: 0.7786 - val_acc: 0.7350 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 0.6876 - acc: 0.7585 - top5-acc: 0.9868 - val_loss: 0.7783 - val_acc: 0.7342 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6944 - acc: 0.7545 - top5-acc: 0.9864 - val_loss: 0.7738 - val_acc: 0.7364 - val_top5-acc: 0.9828 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6895 - acc: 0.7582 - top5-acc: 0.9851 - val_loss: 0.7749 - val_acc: 0.7342 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.6904 - acc: 0.7584 - top5-acc: 0.9860 - val_loss: 0.7784 - val_acc: 0.7348 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6896 - acc: 0.7571 - top5-acc: 0.9868 - val_loss: 0.7744 - val_acc: 0.7372 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6907 - acc: 0.7553 - top5-acc: 0.9869 - val_loss: 0.7743 - val_acc: 0.7370 - val_top5-acc: 0.9828 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6947 - acc: 0.7558 - top5-acc: 0.9858 - val_loss: 0.7731 - val_acc: 0.7370 - val_top5-acc: 0.9838 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.6912 - acc: 0.7579 - top5-acc: 0.9864 - val_loss: 0.7725 - val_acc: 0.7350 - val_top5-acc: 0.9834 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6936 - acc: 0.7546 - top5-acc: 0.9865 - val_loss: 0.7733 - val_acc: 0.7342 - val_top5-acc: 0.9828 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.6917 - acc: 0.7570 - top5-acc: 0.9857 - val_loss: 0.7730 - val_acc: 0.7364 - val_top5-acc: 0.9830 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.6896 - acc: 0.7556 - top5-acc: 0.9864 - val_loss: 0.7774 - val_acc: 0.7384 - val_top5-acc: 0.9832 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 0.6873 - acc: 0.7600 - top5-acc: 0.9863 - val_loss: 0.7720 - val_acc: 0.7350 - val_top5-acc: 0.9834 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6882 - acc: 0.7570 - top5-acc: 0.9856 - val_loss: 0.7755 - val_acc: 0.7346 - val_top5-acc: 0.9824 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6898 - acc: 0.7597 - top5-acc: 0.9853 - val_loss: 0.7746 - val_acc: 0.7340 - val_top5-acc: 0.9832 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6874 - acc: 0.7596 - top5-acc: 0.9861 - val_loss: 0.7745 - val_acc: 0.7346 - val_top5-acc: 0.9832 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6905 - acc: 0.7566 - top5-acc: 0.9872 - val_loss: 0.7734 - val_acc: 0.7360 - val_top5-acc: 0.9828 - lr: 6.2500e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 0.6931 - acc: 0.7559 - top5-acc: 0.9853 - val_loss: 0.7769 - val_acc: 0.7342 - val_top5-acc: 0.9834 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 0.8029 - acc: 0.7249 - top5-acc: 0.9822\n",
      "Test accuracy: 72.49%\n",
      "Test top 5 accuracy: 98.22%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.4654 - acc: 0.3134 - top5-acc: 0.8227WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 3s 27ms/step - loss: 2.4592 - acc: 0.3139 - top5-acc: 0.8230 - val_loss: 1.7517 - val_acc: 0.3780 - val_top5-acc: 0.8850 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.7881 - acc: 0.3730 - top5-acc: 0.8708 - val_loss: 1.7009 - val_acc: 0.3948 - val_top5-acc: 0.8828 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.7326 - acc: 0.3878 - top5-acc: 0.8804 - val_loss: 1.6544 - val_acc: 0.4042 - val_top5-acc: 0.8912 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.7305 - acc: 0.3935 - top5-acc: 0.8830 - val_loss: 1.5900 - val_acc: 0.4344 - val_top5-acc: 0.9044 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.7286 - acc: 0.3960 - top5-acc: 0.8834 - val_loss: 1.6425 - val_acc: 0.4204 - val_top5-acc: 0.8916 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6939 - acc: 0.4019 - top5-acc: 0.8874 - val_loss: 1.5604 - val_acc: 0.4402 - val_top5-acc: 0.9126 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6626 - acc: 0.4093 - top5-acc: 0.8912 - val_loss: 1.5941 - val_acc: 0.4302 - val_top5-acc: 0.9046 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6677 - acc: 0.4078 - top5-acc: 0.8918 - val_loss: 1.6292 - val_acc: 0.4146 - val_top5-acc: 0.8994 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6750 - acc: 0.4102 - top5-acc: 0.8926 - val_loss: 1.6297 - val_acc: 0.4246 - val_top5-acc: 0.9000 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6808 - acc: 0.4098 - top5-acc: 0.8914 - val_loss: 1.5869 - val_acc: 0.4276 - val_top5-acc: 0.9062 - lr: 0.0050\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6624 - acc: 0.4124 - top5-acc: 0.8947 - val_loss: 1.6023 - val_acc: 0.4266 - val_top5-acc: 0.9060 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5861 - acc: 0.4329 - top5-acc: 0.9026 - val_loss: 1.5096 - val_acc: 0.4614 - val_top5-acc: 0.9150 - lr: 0.0025\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5764 - acc: 0.4336 - top5-acc: 0.9036 - val_loss: 1.4917 - val_acc: 0.4636 - val_top5-acc: 0.9200 - lr: 0.0025\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5772 - acc: 0.4363 - top5-acc: 0.9043 - val_loss: 1.4927 - val_acc: 0.4684 - val_top5-acc: 0.9106 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5761 - acc: 0.4374 - top5-acc: 0.9022 - val_loss: 1.5236 - val_acc: 0.4472 - val_top5-acc: 0.9190 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5761 - acc: 0.4355 - top5-acc: 0.9043 - val_loss: 1.4992 - val_acc: 0.4574 - val_top5-acc: 0.9148 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5745 - acc: 0.4381 - top5-acc: 0.9025 - val_loss: 1.5078 - val_acc: 0.4558 - val_top5-acc: 0.9124 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5815 - acc: 0.4350 - top5-acc: 0.9003 - val_loss: 1.5337 - val_acc: 0.4426 - val_top5-acc: 0.9090 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5488 - acc: 0.4438 - top5-acc: 0.9074 - val_loss: 1.4757 - val_acc: 0.4620 - val_top5-acc: 0.9196 - lr: 0.0012\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5349 - acc: 0.4504 - top5-acc: 0.9084 - val_loss: 1.4815 - val_acc: 0.4712 - val_top5-acc: 0.9164 - lr: 0.0012\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5380 - acc: 0.4479 - top5-acc: 0.9085 - val_loss: 1.4902 - val_acc: 0.4610 - val_top5-acc: 0.9120 - lr: 0.0012\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5367 - acc: 0.4472 - top5-acc: 0.9084 - val_loss: 1.5006 - val_acc: 0.4582 - val_top5-acc: 0.9142 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5376 - acc: 0.4496 - top5-acc: 0.9080 - val_loss: 1.4762 - val_acc: 0.4712 - val_top5-acc: 0.9156 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5448 - acc: 0.4432 - top5-acc: 0.9069 - val_loss: 1.4821 - val_acc: 0.4708 - val_top5-acc: 0.9174 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5197 - acc: 0.4572 - top5-acc: 0.9092 - val_loss: 1.4742 - val_acc: 0.4660 - val_top5-acc: 0.9226 - lr: 6.2500e-04\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5153 - acc: 0.4590 - top5-acc: 0.9101 - val_loss: 1.4746 - val_acc: 0.4724 - val_top5-acc: 0.9170 - lr: 6.2500e-04\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5207 - acc: 0.4549 - top5-acc: 0.9109 - val_loss: 1.4703 - val_acc: 0.4764 - val_top5-acc: 0.9198 - lr: 6.2500e-04\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5140 - acc: 0.4590 - top5-acc: 0.9110 - val_loss: 1.4665 - val_acc: 0.4740 - val_top5-acc: 0.9188 - lr: 6.2500e-04\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5171 - acc: 0.4592 - top5-acc: 0.9102 - val_loss: 1.4679 - val_acc: 0.4758 - val_top5-acc: 0.9172 - lr: 6.2500e-04\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5166 - acc: 0.4575 - top5-acc: 0.9109 - val_loss: 1.4703 - val_acc: 0.4728 - val_top5-acc: 0.9160 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5222 - acc: 0.4552 - top5-acc: 0.9096 - val_loss: 1.4644 - val_acc: 0.4782 - val_top5-acc: 0.9188 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5206 - acc: 0.4589 - top5-acc: 0.9092 - val_loss: 1.4716 - val_acc: 0.4666 - val_top5-acc: 0.9182 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5198 - acc: 0.4560 - top5-acc: 0.9121 - val_loss: 1.4595 - val_acc: 0.4742 - val_top5-acc: 0.9174 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5179 - acc: 0.4565 - top5-acc: 0.9112 - val_loss: 1.4742 - val_acc: 0.4694 - val_top5-acc: 0.9200 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5210 - acc: 0.4574 - top5-acc: 0.9101 - val_loss: 1.4689 - val_acc: 0.4682 - val_top5-acc: 0.9180 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5193 - acc: 0.4573 - top5-acc: 0.9100 - val_loss: 1.4696 - val_acc: 0.4770 - val_top5-acc: 0.9190 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5231 - acc: 0.4575 - top5-acc: 0.9087 - val_loss: 1.4650 - val_acc: 0.4744 - val_top5-acc: 0.9222 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5181 - acc: 0.4572 - top5-acc: 0.9101 - val_loss: 1.4701 - val_acc: 0.4732 - val_top5-acc: 0.9190 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5124 - acc: 0.4625 - top5-acc: 0.9100 - val_loss: 1.4569 - val_acc: 0.4794 - val_top5-acc: 0.9206 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5109 - acc: 0.4609 - top5-acc: 0.9119 - val_loss: 1.4521 - val_acc: 0.4858 - val_top5-acc: 0.9238 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5059 - acc: 0.4614 - top5-acc: 0.9117 - val_loss: 1.4567 - val_acc: 0.4794 - val_top5-acc: 0.9194 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5088 - acc: 0.4628 - top5-acc: 0.9104 - val_loss: 1.4562 - val_acc: 0.4816 - val_top5-acc: 0.9202 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5109 - acc: 0.4608 - top5-acc: 0.9109 - val_loss: 1.4577 - val_acc: 0.4738 - val_top5-acc: 0.9202 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5100 - acc: 0.4602 - top5-acc: 0.9116 - val_loss: 1.4696 - val_acc: 0.4712 - val_top5-acc: 0.9166 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5123 - acc: 0.4604 - top5-acc: 0.9112 - val_loss: 1.4551 - val_acc: 0.4808 - val_top5-acc: 0.9230 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5043 - acc: 0.4645 - top5-acc: 0.9115 - val_loss: 1.4565 - val_acc: 0.4808 - val_top5-acc: 0.9192 - lr: 1.5625e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.5056 - acc: 0.4638 - top5-acc: 0.9116 - val_loss: 1.4548 - val_acc: 0.4880 - val_top5-acc: 0.9218 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5075 - acc: 0.4638 - top5-acc: 0.9123 - val_loss: 1.4573 - val_acc: 0.4808 - val_top5-acc: 0.9200 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5041 - acc: 0.4638 - top5-acc: 0.9117 - val_loss: 1.4624 - val_acc: 0.4796 - val_top5-acc: 0.9204 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.5055 - acc: 0.4630 - top5-acc: 0.9133 - val_loss: 1.4588 - val_acc: 0.4794 - val_top5-acc: 0.9204 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.4796 - acc: 0.4715 - top5-acc: 0.9173\n",
      "Test accuracy: 47.15%\n",
      "Test top 5 accuracy: 91.73%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.1230 - acc: 0.3438 - top5-acc: 0.8531WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 4s 37ms/step - loss: 2.1190 - acc: 0.3441 - top5-acc: 0.8532 - val_loss: 1.6282 - val_acc: 0.4258 - val_top5-acc: 0.9042 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6567 - acc: 0.4177 - top5-acc: 0.8971 - val_loss: 1.5645 - val_acc: 0.4238 - val_top5-acc: 0.9190 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6393 - acc: 0.4275 - top5-acc: 0.8991 - val_loss: 1.4607 - val_acc: 0.4736 - val_top5-acc: 0.9266 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5639 - acc: 0.4491 - top5-acc: 0.9101 - val_loss: 1.4541 - val_acc: 0.4772 - val_top5-acc: 0.9246 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5534 - acc: 0.4527 - top5-acc: 0.9124 - val_loss: 1.4219 - val_acc: 0.4872 - val_top5-acc: 0.9300 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5469 - acc: 0.4570 - top5-acc: 0.9145 - val_loss: 1.4317 - val_acc: 0.4760 - val_top5-acc: 0.9284 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5337 - acc: 0.4623 - top5-acc: 0.9148 - val_loss: 1.4181 - val_acc: 0.4932 - val_top5-acc: 0.9284 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5284 - acc: 0.4611 - top5-acc: 0.9169 - val_loss: 1.4593 - val_acc: 0.4876 - val_top5-acc: 0.9314 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5353 - acc: 0.4628 - top5-acc: 0.9148 - val_loss: 1.4238 - val_acc: 0.4866 - val_top5-acc: 0.9310 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5182 - acc: 0.4643 - top5-acc: 0.9169 - val_loss: 1.3845 - val_acc: 0.5028 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5008 - acc: 0.4692 - top5-acc: 0.9196 - val_loss: 1.3891 - val_acc: 0.5074 - val_top5-acc: 0.9388 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5020 - acc: 0.4677 - top5-acc: 0.9200 - val_loss: 1.3974 - val_acc: 0.5032 - val_top5-acc: 0.9356 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4862 - acc: 0.4740 - top5-acc: 0.9206 - val_loss: 1.4090 - val_acc: 0.4916 - val_top5-acc: 0.9340 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4814 - acc: 0.4783 - top5-acc: 0.9219 - val_loss: 1.3914 - val_acc: 0.5010 - val_top5-acc: 0.9316 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4925 - acc: 0.4731 - top5-acc: 0.9208 - val_loss: 1.4317 - val_acc: 0.4936 - val_top5-acc: 0.9294 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4248 - acc: 0.4913 - top5-acc: 0.9274 - val_loss: 1.3356 - val_acc: 0.5260 - val_top5-acc: 0.9392 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4245 - acc: 0.4963 - top5-acc: 0.9280 - val_loss: 1.3223 - val_acc: 0.5322 - val_top5-acc: 0.9422 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4227 - acc: 0.4919 - top5-acc: 0.9269 - val_loss: 1.3480 - val_acc: 0.5102 - val_top5-acc: 0.9400 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4159 - acc: 0.4953 - top5-acc: 0.9285 - val_loss: 1.3231 - val_acc: 0.5282 - val_top5-acc: 0.9410 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4139 - acc: 0.4940 - top5-acc: 0.9290 - val_loss: 1.3195 - val_acc: 0.5312 - val_top5-acc: 0.9390 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4274 - acc: 0.4928 - top5-acc: 0.9267 - val_loss: 1.3164 - val_acc: 0.5330 - val_top5-acc: 0.9388 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4195 - acc: 0.4956 - top5-acc: 0.9280 - val_loss: 1.3311 - val_acc: 0.5184 - val_top5-acc: 0.9414 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4252 - acc: 0.4943 - top5-acc: 0.9285 - val_loss: 1.3347 - val_acc: 0.5222 - val_top5-acc: 0.9418 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4273 - acc: 0.4938 - top5-acc: 0.9282 - val_loss: 1.3227 - val_acc: 0.5284 - val_top5-acc: 0.9380 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4264 - acc: 0.4927 - top5-acc: 0.9266 - val_loss: 1.3045 - val_acc: 0.5288 - val_top5-acc: 0.9456 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4139 - acc: 0.4975 - top5-acc: 0.9282 - val_loss: 1.3254 - val_acc: 0.5236 - val_top5-acc: 0.9430 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4271 - acc: 0.4912 - top5-acc: 0.9295 - val_loss: 1.3183 - val_acc: 0.5250 - val_top5-acc: 0.9436 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4189 - acc: 0.4940 - top5-acc: 0.9280 - val_loss: 1.3221 - val_acc: 0.5266 - val_top5-acc: 0.9402 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4163 - acc: 0.4962 - top5-acc: 0.9301 - val_loss: 1.3263 - val_acc: 0.5260 - val_top5-acc: 0.9424 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.4133 - acc: 0.4973 - top5-acc: 0.9288 - val_loss: 1.3083 - val_acc: 0.5290 - val_top5-acc: 0.9414 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3859 - acc: 0.5075 - top5-acc: 0.9318 - val_loss: 1.2813 - val_acc: 0.5468 - val_top5-acc: 0.9458 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3855 - acc: 0.5056 - top5-acc: 0.9310 - val_loss: 1.3033 - val_acc: 0.5306 - val_top5-acc: 0.9428 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3859 - acc: 0.5089 - top5-acc: 0.9300 - val_loss: 1.2913 - val_acc: 0.5388 - val_top5-acc: 0.9430 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3845 - acc: 0.5077 - top5-acc: 0.9311 - val_loss: 1.2983 - val_acc: 0.5326 - val_top5-acc: 0.9458 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3857 - acc: 0.5084 - top5-acc: 0.9309 - val_loss: 1.3048 - val_acc: 0.5316 - val_top5-acc: 0.9452 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3863 - acc: 0.5046 - top5-acc: 0.9316 - val_loss: 1.2850 - val_acc: 0.5430 - val_top5-acc: 0.9452 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3731 - acc: 0.5117 - top5-acc: 0.9317 - val_loss: 1.2899 - val_acc: 0.5434 - val_top5-acc: 0.9462 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3715 - acc: 0.5136 - top5-acc: 0.9339 - val_loss: 1.2708 - val_acc: 0.5480 - val_top5-acc: 0.9466 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3688 - acc: 0.5146 - top5-acc: 0.9325 - val_loss: 1.2771 - val_acc: 0.5450 - val_top5-acc: 0.9442 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3709 - acc: 0.5105 - top5-acc: 0.9328 - val_loss: 1.2855 - val_acc: 0.5380 - val_top5-acc: 0.9490 - lr: 6.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3684 - acc: 0.5126 - top5-acc: 0.9332 - val_loss: 1.2791 - val_acc: 0.5450 - val_top5-acc: 0.9452 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3717 - acc: 0.5134 - top5-acc: 0.9312 - val_loss: 1.2887 - val_acc: 0.5392 - val_top5-acc: 0.9436 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3760 - acc: 0.5109 - top5-acc: 0.9311 - val_loss: 1.2813 - val_acc: 0.5428 - val_top5-acc: 0.9452 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3658 - acc: 0.5173 - top5-acc: 0.9329 - val_loss: 1.2729 - val_acc: 0.5450 - val_top5-acc: 0.9492 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3609 - acc: 0.5158 - top5-acc: 0.9353 - val_loss: 1.2755 - val_acc: 0.5472 - val_top5-acc: 0.9476 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3659 - acc: 0.5136 - top5-acc: 0.9338 - val_loss: 1.2754 - val_acc: 0.5478 - val_top5-acc: 0.9460 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3658 - acc: 0.5166 - top5-acc: 0.9311 - val_loss: 1.2749 - val_acc: 0.5448 - val_top5-acc: 0.9488 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3617 - acc: 0.5162 - top5-acc: 0.9337 - val_loss: 1.2748 - val_acc: 0.5468 - val_top5-acc: 0.9452 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3621 - acc: 0.5164 - top5-acc: 0.9335 - val_loss: 1.2737 - val_acc: 0.5514 - val_top5-acc: 0.9478 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.3586 - acc: 0.5224 - top5-acc: 0.9344 - val_loss: 1.2746 - val_acc: 0.5492 - val_top5-acc: 0.9454 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 1.3103 - acc: 0.5375 - top5-acc: 0.9398\n",
      "Test accuracy: 53.75%\n",
      "Test top 5 accuracy: 93.98%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.0790 - acc: 0.3541 - top5-acc: 0.8527WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 5s 45ms/step - loss: 2.0756 - acc: 0.3545 - top5-acc: 0.8532 - val_loss: 1.5530 - val_acc: 0.4342 - val_top5-acc: 0.9124 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 1.6026 - acc: 0.4337 - top5-acc: 0.9054 - val_loss: 1.4325 - val_acc: 0.5022 - val_top5-acc: 0.9216 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 1.5520 - acc: 0.4560 - top5-acc: 0.9104 - val_loss: 1.3876 - val_acc: 0.5166 - val_top5-acc: 0.9272 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5101 - acc: 0.4684 - top5-acc: 0.9170 - val_loss: 1.3733 - val_acc: 0.5038 - val_top5-acc: 0.9356 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4954 - acc: 0.4778 - top5-acc: 0.9194 - val_loss: 1.4007 - val_acc: 0.4946 - val_top5-acc: 0.9368 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4981 - acc: 0.4764 - top5-acc: 0.9212 - val_loss: 1.3557 - val_acc: 0.5116 - val_top5-acc: 0.9382 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4732 - acc: 0.4851 - top5-acc: 0.9215 - val_loss: 1.3648 - val_acc: 0.5210 - val_top5-acc: 0.9334 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4670 - acc: 0.4849 - top5-acc: 0.9226 - val_loss: 1.3718 - val_acc: 0.5054 - val_top5-acc: 0.9364 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4502 - acc: 0.4910 - top5-acc: 0.9240 - val_loss: 1.3448 - val_acc: 0.5204 - val_top5-acc: 0.9440 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4507 - acc: 0.4889 - top5-acc: 0.9244 - val_loss: 1.3189 - val_acc: 0.5350 - val_top5-acc: 0.9394 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4373 - acc: 0.4956 - top5-acc: 0.9266 - val_loss: 1.3747 - val_acc: 0.5224 - val_top5-acc: 0.9324 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4395 - acc: 0.4940 - top5-acc: 0.9262 - val_loss: 1.3258 - val_acc: 0.5310 - val_top5-acc: 0.9432 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4303 - acc: 0.4990 - top5-acc: 0.9269 - val_loss: 1.3054 - val_acc: 0.5346 - val_top5-acc: 0.9418 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4428 - acc: 0.4938 - top5-acc: 0.9261 - val_loss: 1.3526 - val_acc: 0.5202 - val_top5-acc: 0.9338 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 1.4375 - acc: 0.4946 - top5-acc: 0.9272 - val_loss: 1.3624 - val_acc: 0.5204 - val_top5-acc: 0.9354 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4393 - acc: 0.4929 - top5-acc: 0.9266 - val_loss: 1.3309 - val_acc: 0.5272 - val_top5-acc: 0.9400 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4311 - acc: 0.4977 - top5-acc: 0.9275 - val_loss: 1.2759 - val_acc: 0.5396 - val_top5-acc: 0.9456 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4151 - acc: 0.5012 - top5-acc: 0.9290 - val_loss: 1.3152 - val_acc: 0.5360 - val_top5-acc: 0.9390 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4484 - acc: 0.4936 - top5-acc: 0.9263 - val_loss: 1.3812 - val_acc: 0.5146 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4258 - acc: 0.4995 - top5-acc: 0.9293 - val_loss: 1.3134 - val_acc: 0.5350 - val_top5-acc: 0.9418 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4215 - acc: 0.5016 - top5-acc: 0.9280 - val_loss: 1.3165 - val_acc: 0.5298 - val_top5-acc: 0.9428 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4216 - acc: 0.5016 - top5-acc: 0.9279 - val_loss: 1.3445 - val_acc: 0.5160 - val_top5-acc: 0.9414 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3654 - acc: 0.5156 - top5-acc: 0.9343 - val_loss: 1.2605 - val_acc: 0.5538 - val_top5-acc: 0.9440 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3624 - acc: 0.5173 - top5-acc: 0.9339 - val_loss: 1.2791 - val_acc: 0.5414 - val_top5-acc: 0.9460 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 1.3736 - acc: 0.5156 - top5-acc: 0.9336 - val_loss: 1.2832 - val_acc: 0.5400 - val_top5-acc: 0.9464 - lr: 0.0025\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3787 - acc: 0.5120 - top5-acc: 0.9336 - val_loss: 1.2582 - val_acc: 0.5464 - val_top5-acc: 0.9504 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3628 - acc: 0.5170 - top5-acc: 0.9345 - val_loss: 1.2502 - val_acc: 0.5538 - val_top5-acc: 0.9490 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3635 - acc: 0.5189 - top5-acc: 0.9333 - val_loss: 1.2858 - val_acc: 0.5432 - val_top5-acc: 0.9446 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3649 - acc: 0.5164 - top5-acc: 0.9352 - val_loss: 1.2754 - val_acc: 0.5498 - val_top5-acc: 0.9452 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 1.3638 - acc: 0.5156 - top5-acc: 0.9339 - val_loss: 1.2933 - val_acc: 0.5322 - val_top5-acc: 0.9442 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3732 - acc: 0.5114 - top5-acc: 0.9332 - val_loss: 1.3013 - val_acc: 0.5296 - val_top5-acc: 0.9448 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3638 - acc: 0.5174 - top5-acc: 0.9346 - val_loss: 1.2662 - val_acc: 0.5462 - val_top5-acc: 0.9466 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3408 - acc: 0.5261 - top5-acc: 0.9375 - val_loss: 1.2336 - val_acc: 0.5592 - val_top5-acc: 0.9520 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3428 - acc: 0.5250 - top5-acc: 0.9339 - val_loss: 1.2400 - val_acc: 0.5550 - val_top5-acc: 0.9476 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3379 - acc: 0.5264 - top5-acc: 0.9373 - val_loss: 1.2575 - val_acc: 0.5464 - val_top5-acc: 0.9490 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3367 - acc: 0.5256 - top5-acc: 0.9374 - val_loss: 1.2543 - val_acc: 0.5502 - val_top5-acc: 0.9454 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3425 - acc: 0.5227 - top5-acc: 0.9349 - val_loss: 1.2429 - val_acc: 0.5556 - val_top5-acc: 0.9484 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3418 - acc: 0.5238 - top5-acc: 0.9360 - val_loss: 1.2424 - val_acc: 0.5574 - val_top5-acc: 0.9462 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3277 - acc: 0.5276 - top5-acc: 0.9374 - val_loss: 1.2306 - val_acc: 0.5634 - val_top5-acc: 0.9488 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3261 - acc: 0.5312 - top5-acc: 0.9387 - val_loss: 1.2502 - val_acc: 0.5520 - val_top5-acc: 0.9468 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3263 - acc: 0.5306 - top5-acc: 0.9368 - val_loss: 1.2307 - val_acc: 0.5636 - val_top5-acc: 0.9490 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3309 - acc: 0.5280 - top5-acc: 0.9362 - val_loss: 1.2358 - val_acc: 0.5608 - val_top5-acc: 0.9504 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3242 - acc: 0.5324 - top5-acc: 0.9368 - val_loss: 1.2395 - val_acc: 0.5584 - val_top5-acc: 0.9484 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3263 - acc: 0.5302 - top5-acc: 0.9383 - val_loss: 1.2373 - val_acc: 0.5598 - val_top5-acc: 0.9494 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3207 - acc: 0.5326 - top5-acc: 0.9373 - val_loss: 1.2230 - val_acc: 0.5676 - val_top5-acc: 0.9510 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3246 - acc: 0.5324 - top5-acc: 0.9381 - val_loss: 1.2321 - val_acc: 0.5640 - val_top5-acc: 0.9502 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3188 - acc: 0.5330 - top5-acc: 0.9375 - val_loss: 1.2282 - val_acc: 0.5636 - val_top5-acc: 0.9524 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3256 - acc: 0.5323 - top5-acc: 0.9369 - val_loss: 1.2372 - val_acc: 0.5624 - val_top5-acc: 0.9496 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3236 - acc: 0.5314 - top5-acc: 0.9383 - val_loss: 1.2301 - val_acc: 0.5644 - val_top5-acc: 0.9498 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.3240 - acc: 0.5303 - top5-acc: 0.9371 - val_loss: 1.2305 - val_acc: 0.5668 - val_top5-acc: 0.9514 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 1.2683 - acc: 0.5539 - top5-acc: 0.9465\n",
      "Test accuracy: 55.39%\n",
      "Test top 5 accuracy: 94.65%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.0069 - acc: 0.3714 - top5-acc: 0.8604WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 6s 53ms/step - loss: 2.0069 - acc: 0.3714 - top5-acc: 0.8604 - val_loss: 1.4828 - val_acc: 0.4798 - val_top5-acc: 0.9200 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5605 - acc: 0.4518 - top5-acc: 0.9107 - val_loss: 1.4583 - val_acc: 0.4858 - val_top5-acc: 0.9216 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5048 - acc: 0.4748 - top5-acc: 0.9184 - val_loss: 1.3935 - val_acc: 0.5114 - val_top5-acc: 0.9326 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4666 - acc: 0.4864 - top5-acc: 0.9223 - val_loss: 1.4073 - val_acc: 0.5078 - val_top5-acc: 0.9288 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4519 - acc: 0.4937 - top5-acc: 0.9232 - val_loss: 1.3477 - val_acc: 0.5226 - val_top5-acc: 0.9342 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4444 - acc: 0.4933 - top5-acc: 0.9257 - val_loss: 1.3481 - val_acc: 0.5192 - val_top5-acc: 0.9374 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4317 - acc: 0.4970 - top5-acc: 0.9258 - val_loss: 1.3047 - val_acc: 0.5446 - val_top5-acc: 0.9416 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 1.4098 - acc: 0.5055 - top5-acc: 0.9300 - val_loss: 1.3533 - val_acc: 0.5176 - val_top5-acc: 0.9362 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4119 - acc: 0.5040 - top5-acc: 0.9299 - val_loss: 1.3277 - val_acc: 0.5266 - val_top5-acc: 0.9406 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4060 - acc: 0.5070 - top5-acc: 0.9288 - val_loss: 1.2927 - val_acc: 0.5434 - val_top5-acc: 0.9414 - lr: 0.0050\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4019 - acc: 0.5100 - top5-acc: 0.9297 - val_loss: 1.2968 - val_acc: 0.5370 - val_top5-acc: 0.9424 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3938 - acc: 0.5117 - top5-acc: 0.9312 - val_loss: 1.2676 - val_acc: 0.5510 - val_top5-acc: 0.9458 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3866 - acc: 0.5135 - top5-acc: 0.9316 - val_loss: 1.2743 - val_acc: 0.5454 - val_top5-acc: 0.9426 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3822 - acc: 0.5158 - top5-acc: 0.9321 - val_loss: 1.2464 - val_acc: 0.5606 - val_top5-acc: 0.9434 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4076 - acc: 0.5111 - top5-acc: 0.9302 - val_loss: 1.2778 - val_acc: 0.5396 - val_top5-acc: 0.9458 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3977 - acc: 0.5103 - top5-acc: 0.9301 - val_loss: 1.2922 - val_acc: 0.5334 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3882 - acc: 0.5129 - top5-acc: 0.9344 - val_loss: 1.2692 - val_acc: 0.5536 - val_top5-acc: 0.9438 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3934 - acc: 0.5123 - top5-acc: 0.9322 - val_loss: 1.2872 - val_acc: 0.5432 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4077 - acc: 0.5078 - top5-acc: 0.9309 - val_loss: 1.3300 - val_acc: 0.5348 - val_top5-acc: 0.9336 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3351 - acc: 0.5310 - top5-acc: 0.9360 - val_loss: 1.2242 - val_acc: 0.5584 - val_top5-acc: 0.9478 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3356 - acc: 0.5268 - top5-acc: 0.9361 - val_loss: 1.2521 - val_acc: 0.5498 - val_top5-acc: 0.9472 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3286 - acc: 0.5291 - top5-acc: 0.9384 - val_loss: 1.2256 - val_acc: 0.5640 - val_top5-acc: 0.9472 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3285 - acc: 0.5323 - top5-acc: 0.9373 - val_loss: 1.2304 - val_acc: 0.5582 - val_top5-acc: 0.9480 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3344 - acc: 0.5260 - top5-acc: 0.9383 - val_loss: 1.2258 - val_acc: 0.5672 - val_top5-acc: 0.9466 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3281 - acc: 0.5312 - top5-acc: 0.9372 - val_loss: 1.2419 - val_acc: 0.5570 - val_top5-acc: 0.9470 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3091 - acc: 0.5404 - top5-acc: 0.9381 - val_loss: 1.2067 - val_acc: 0.5708 - val_top5-acc: 0.9490 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3059 - acc: 0.5428 - top5-acc: 0.9391 - val_loss: 1.2211 - val_acc: 0.5692 - val_top5-acc: 0.9490 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3100 - acc: 0.5380 - top5-acc: 0.9380 - val_loss: 1.2108 - val_acc: 0.5662 - val_top5-acc: 0.9474 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3141 - acc: 0.5354 - top5-acc: 0.9400 - val_loss: 1.2185 - val_acc: 0.5722 - val_top5-acc: 0.9484 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3109 - acc: 0.5378 - top5-acc: 0.9389 - val_loss: 1.2140 - val_acc: 0.5654 - val_top5-acc: 0.9494 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3095 - acc: 0.5376 - top5-acc: 0.9382 - val_loss: 1.2212 - val_acc: 0.5634 - val_top5-acc: 0.9476 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2967 - acc: 0.5428 - top5-acc: 0.9404 - val_loss: 1.1983 - val_acc: 0.5746 - val_top5-acc: 0.9506 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2979 - acc: 0.5410 - top5-acc: 0.9390 - val_loss: 1.2055 - val_acc: 0.5710 - val_top5-acc: 0.9486 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3002 - acc: 0.5418 - top5-acc: 0.9398 - val_loss: 1.2043 - val_acc: 0.5670 - val_top5-acc: 0.9496 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3006 - acc: 0.5404 - top5-acc: 0.9383 - val_loss: 1.2051 - val_acc: 0.5720 - val_top5-acc: 0.9488 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3012 - acc: 0.5405 - top5-acc: 0.9404 - val_loss: 1.2143 - val_acc: 0.5642 - val_top5-acc: 0.9504 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.3027 - acc: 0.5415 - top5-acc: 0.9384 - val_loss: 1.2049 - val_acc: 0.5658 - val_top5-acc: 0.9506 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2949 - acc: 0.5433 - top5-acc: 0.9392 - val_loss: 1.1999 - val_acc: 0.5710 - val_top5-acc: 0.9510 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2947 - acc: 0.5420 - top5-acc: 0.9418 - val_loss: 1.2045 - val_acc: 0.5714 - val_top5-acc: 0.9502 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2933 - acc: 0.5460 - top5-acc: 0.9407 - val_loss: 1.1979 - val_acc: 0.5750 - val_top5-acc: 0.9504 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2949 - acc: 0.5456 - top5-acc: 0.9408 - val_loss: 1.2054 - val_acc: 0.5692 - val_top5-acc: 0.9500 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2933 - acc: 0.5455 - top5-acc: 0.9410 - val_loss: 1.2060 - val_acc: 0.5702 - val_top5-acc: 0.9492 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2958 - acc: 0.5432 - top5-acc: 0.9410 - val_loss: 1.1996 - val_acc: 0.5768 - val_top5-acc: 0.9504 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2950 - acc: 0.5453 - top5-acc: 0.9402 - val_loss: 1.1998 - val_acc: 0.5770 - val_top5-acc: 0.9510 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 4s 50ms/step - loss: 1.2952 - acc: 0.5436 - top5-acc: 0.9409 - val_loss: 1.2101 - val_acc: 0.5732 - val_top5-acc: 0.9488 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2937 - acc: 0.5458 - top5-acc: 0.9408 - val_loss: 1.2033 - val_acc: 0.5722 - val_top5-acc: 0.9494 - lr: 1.5625e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2899 - acc: 0.5485 - top5-acc: 0.9411 - val_loss: 1.2044 - val_acc: 0.5734 - val_top5-acc: 0.9500 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2912 - acc: 0.5460 - top5-acc: 0.9424 - val_loss: 1.2034 - val_acc: 0.5742 - val_top5-acc: 0.9516 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2940 - acc: 0.5516 - top5-acc: 0.9393 - val_loss: 1.2077 - val_acc: 0.5694 - val_top5-acc: 0.9502 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.2938 - acc: 0.5456 - top5-acc: 0.9421 - val_loss: 1.2037 - val_acc: 0.5736 - val_top5-acc: 0.9496 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 1.2357 - acc: 0.5658 - top5-acc: 0.9467\n",
      "Test accuracy: 56.58%\n",
      "Test top 5 accuracy: 94.67%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 1.9190 - acc: 0.3825 - top5-acc: 0.8679WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 7s 63ms/step - loss: 1.9144 - acc: 0.3837 - top5-acc: 0.8684 - val_loss: 1.4505 - val_acc: 0.4852 - val_top5-acc: 0.9258 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4973 - acc: 0.4758 - top5-acc: 0.9191 - val_loss: 1.3643 - val_acc: 0.5188 - val_top5-acc: 0.9356 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4357 - acc: 0.4972 - top5-acc: 0.9263 - val_loss: 1.2634 - val_acc: 0.5572 - val_top5-acc: 0.9424 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3982 - acc: 0.5123 - top5-acc: 0.9300 - val_loss: 1.2949 - val_acc: 0.5400 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3760 - acc: 0.5183 - top5-acc: 0.9326 - val_loss: 1.2424 - val_acc: 0.5614 - val_top5-acc: 0.9462 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.3592 - acc: 0.5238 - top5-acc: 0.9351 - val_loss: 1.2465 - val_acc: 0.5630 - val_top5-acc: 0.9454 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.3643 - acc: 0.5242 - top5-acc: 0.9344 - val_loss: 1.2255 - val_acc: 0.5706 - val_top5-acc: 0.9466 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3473 - acc: 0.5293 - top5-acc: 0.9360 - val_loss: 1.2337 - val_acc: 0.5724 - val_top5-acc: 0.9458 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3504 - acc: 0.5263 - top5-acc: 0.9380 - val_loss: 1.2041 - val_acc: 0.5730 - val_top5-acc: 0.9502 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3298 - acc: 0.5345 - top5-acc: 0.9395 - val_loss: 1.2232 - val_acc: 0.5766 - val_top5-acc: 0.9424 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.3322 - acc: 0.5330 - top5-acc: 0.9386 - val_loss: 1.1870 - val_acc: 0.5820 - val_top5-acc: 0.9500 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.3299 - acc: 0.5352 - top5-acc: 0.9396 - val_loss: 1.2172 - val_acc: 0.5710 - val_top5-acc: 0.9502 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.3289 - acc: 0.5348 - top5-acc: 0.9399 - val_loss: 1.2039 - val_acc: 0.5764 - val_top5-acc: 0.9520 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.3212 - acc: 0.5374 - top5-acc: 0.9392 - val_loss: 1.2206 - val_acc: 0.5674 - val_top5-acc: 0.9488 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.3238 - acc: 0.5344 - top5-acc: 0.9398 - val_loss: 1.2210 - val_acc: 0.5682 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.3209 - acc: 0.5373 - top5-acc: 0.9395 - val_loss: 1.1898 - val_acc: 0.5792 - val_top5-acc: 0.9490 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 5s 57ms/step - loss: 1.2857 - acc: 0.5481 - top5-acc: 0.9424 - val_loss: 1.1460 - val_acc: 0.5952 - val_top5-acc: 0.9528 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2694 - acc: 0.5532 - top5-acc: 0.9451 - val_loss: 1.1453 - val_acc: 0.5932 - val_top5-acc: 0.9554 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2738 - acc: 0.5509 - top5-acc: 0.9436 - val_loss: 1.1435 - val_acc: 0.5982 - val_top5-acc: 0.9528 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2675 - acc: 0.5532 - top5-acc: 0.9441 - val_loss: 1.1416 - val_acc: 0.5972 - val_top5-acc: 0.9558 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2674 - acc: 0.5536 - top5-acc: 0.9444 - val_loss: 1.1540 - val_acc: 0.5926 - val_top5-acc: 0.9542 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2699 - acc: 0.5520 - top5-acc: 0.9431 - val_loss: 1.1446 - val_acc: 0.5962 - val_top5-acc: 0.9526 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2745 - acc: 0.5530 - top5-acc: 0.9436 - val_loss: 1.1592 - val_acc: 0.5986 - val_top5-acc: 0.9524 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2756 - acc: 0.5489 - top5-acc: 0.9439 - val_loss: 1.1549 - val_acc: 0.5934 - val_top5-acc: 0.9544 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2756 - acc: 0.5513 - top5-acc: 0.9435 - val_loss: 1.1369 - val_acc: 0.5984 - val_top5-acc: 0.9558 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2723 - acc: 0.5502 - top5-acc: 0.9446 - val_loss: 1.1704 - val_acc: 0.5910 - val_top5-acc: 0.9532 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2663 - acc: 0.5569 - top5-acc: 0.9426 - val_loss: 1.1518 - val_acc: 0.5972 - val_top5-acc: 0.9538 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2661 - acc: 0.5537 - top5-acc: 0.9443 - val_loss: 1.1534 - val_acc: 0.5976 - val_top5-acc: 0.9522 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2671 - acc: 0.5559 - top5-acc: 0.9447 - val_loss: 1.1496 - val_acc: 0.5924 - val_top5-acc: 0.9534 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2708 - acc: 0.5547 - top5-acc: 0.9445 - val_loss: 1.1624 - val_acc: 0.5884 - val_top5-acc: 0.9534 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2533 - acc: 0.5575 - top5-acc: 0.9456 - val_loss: 1.1311 - val_acc: 0.6012 - val_top5-acc: 0.9572 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2486 - acc: 0.5621 - top5-acc: 0.9467 - val_loss: 1.1259 - val_acc: 0.6036 - val_top5-acc: 0.9552 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2545 - acc: 0.5615 - top5-acc: 0.9449 - val_loss: 1.1408 - val_acc: 0.6020 - val_top5-acc: 0.9560 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2549 - acc: 0.5596 - top5-acc: 0.9457 - val_loss: 1.1271 - val_acc: 0.6036 - val_top5-acc: 0.9586 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2517 - acc: 0.5572 - top5-acc: 0.9466 - val_loss: 1.1403 - val_acc: 0.6006 - val_top5-acc: 0.9548 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2506 - acc: 0.5585 - top5-acc: 0.9453 - val_loss: 1.1382 - val_acc: 0.5966 - val_top5-acc: 0.9554 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2483 - acc: 0.5593 - top5-acc: 0.9464 - val_loss: 1.1429 - val_acc: 0.5994 - val_top5-acc: 0.9572 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2427 - acc: 0.5631 - top5-acc: 0.9467 - val_loss: 1.1258 - val_acc: 0.6036 - val_top5-acc: 0.9540 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2412 - acc: 0.5641 - top5-acc: 0.9455 - val_loss: 1.1308 - val_acc: 0.6032 - val_top5-acc: 0.9568 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2380 - acc: 0.5674 - top5-acc: 0.9474 - val_loss: 1.1275 - val_acc: 0.6030 - val_top5-acc: 0.9564 - lr: 6.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2358 - acc: 0.5658 - top5-acc: 0.9471 - val_loss: 1.1266 - val_acc: 0.6040 - val_top5-acc: 0.9564 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2401 - acc: 0.5648 - top5-acc: 0.9456 - val_loss: 1.1306 - val_acc: 0.6006 - val_top5-acc: 0.9558 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2368 - acc: 0.5669 - top5-acc: 0.9471 - val_loss: 1.1269 - val_acc: 0.6058 - val_top5-acc: 0.9552 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2392 - acc: 0.5634 - top5-acc: 0.9465 - val_loss: 1.1236 - val_acc: 0.6048 - val_top5-acc: 0.9564 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2349 - acc: 0.5658 - top5-acc: 0.9483 - val_loss: 1.1244 - val_acc: 0.6046 - val_top5-acc: 0.9558 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2328 - acc: 0.5655 - top5-acc: 0.9472 - val_loss: 1.1252 - val_acc: 0.6094 - val_top5-acc: 0.9574 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2375 - acc: 0.5660 - top5-acc: 0.9463 - val_loss: 1.1286 - val_acc: 0.6048 - val_top5-acc: 0.9558 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2385 - acc: 0.5659 - top5-acc: 0.9455 - val_loss: 1.1279 - val_acc: 0.6060 - val_top5-acc: 0.9538 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2378 - acc: 0.5650 - top5-acc: 0.9467 - val_loss: 1.1307 - val_acc: 0.6080 - val_top5-acc: 0.9540 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.2352 - acc: 0.5650 - top5-acc: 0.9468 - val_loss: 1.1236 - val_acc: 0.6092 - val_top5-acc: 0.9566 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.1593 - acc: 0.5970 - top5-acc: 0.9561\n",
      "Test accuracy: 59.7%\n",
      "Test top 5 accuracy: 95.61%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.9466 - acc: 0.3780 - top5-acc: 0.8623WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 7s 70ms/step - loss: 1.9466 - acc: 0.3780 - top5-acc: 0.8623 - val_loss: 1.3789 - val_acc: 0.5058 - val_top5-acc: 0.9334 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.4612 - acc: 0.4878 - top5-acc: 0.9236 - val_loss: 1.3267 - val_acc: 0.5324 - val_top5-acc: 0.9428 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.3904 - acc: 0.5123 - top5-acc: 0.9314 - val_loss: 1.2294 - val_acc: 0.5728 - val_top5-acc: 0.9476 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3491 - acc: 0.5282 - top5-acc: 0.9349 - val_loss: 1.2198 - val_acc: 0.5686 - val_top5-acc: 0.9486 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.3294 - acc: 0.5342 - top5-acc: 0.9387 - val_loss: 1.2064 - val_acc: 0.5854 - val_top5-acc: 0.9474 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3149 - acc: 0.5429 - top5-acc: 0.9380 - val_loss: 1.1570 - val_acc: 0.5932 - val_top5-acc: 0.9550 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2921 - acc: 0.5477 - top5-acc: 0.9424 - val_loss: 1.1545 - val_acc: 0.6020 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2893 - acc: 0.5498 - top5-acc: 0.9419 - val_loss: 1.1824 - val_acc: 0.5918 - val_top5-acc: 0.9522 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2854 - acc: 0.5492 - top5-acc: 0.9423 - val_loss: 1.1692 - val_acc: 0.5896 - val_top5-acc: 0.9546 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2796 - acc: 0.5544 - top5-acc: 0.9430 - val_loss: 1.1529 - val_acc: 0.5976 - val_top5-acc: 0.9518 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2830 - acc: 0.5543 - top5-acc: 0.9436 - val_loss: 1.1358 - val_acc: 0.6018 - val_top5-acc: 0.9592 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2661 - acc: 0.5574 - top5-acc: 0.9452 - val_loss: 1.1737 - val_acc: 0.5890 - val_top5-acc: 0.9564 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2754 - acc: 0.5561 - top5-acc: 0.9457 - val_loss: 1.1253 - val_acc: 0.6052 - val_top5-acc: 0.9568 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2769 - acc: 0.5513 - top5-acc: 0.9437 - val_loss: 1.1391 - val_acc: 0.6042 - val_top5-acc: 0.9558 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2713 - acc: 0.5552 - top5-acc: 0.9456 - val_loss: 1.1585 - val_acc: 0.5890 - val_top5-acc: 0.9540 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2694 - acc: 0.5563 - top5-acc: 0.9455 - val_loss: 1.1341 - val_acc: 0.6056 - val_top5-acc: 0.9622 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2708 - acc: 0.5547 - top5-acc: 0.9452 - val_loss: 1.1707 - val_acc: 0.5912 - val_top5-acc: 0.9560 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2766 - acc: 0.5554 - top5-acc: 0.9450 - val_loss: 1.1660 - val_acc: 0.5980 - val_top5-acc: 0.9536 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2304 - acc: 0.5709 - top5-acc: 0.9483 - val_loss: 1.0881 - val_acc: 0.6102 - val_top5-acc: 0.9586 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2366 - acc: 0.5664 - top5-acc: 0.9477 - val_loss: 1.0997 - val_acc: 0.6158 - val_top5-acc: 0.9592 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2272 - acc: 0.5675 - top5-acc: 0.9486 - val_loss: 1.1008 - val_acc: 0.6114 - val_top5-acc: 0.9604 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2251 - acc: 0.5693 - top5-acc: 0.9496 - val_loss: 1.0889 - val_acc: 0.6184 - val_top5-acc: 0.9612 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2241 - acc: 0.5711 - top5-acc: 0.9491 - val_loss: 1.0921 - val_acc: 0.6138 - val_top5-acc: 0.9610 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2283 - acc: 0.5705 - top5-acc: 0.9488 - val_loss: 1.0872 - val_acc: 0.6178 - val_top5-acc: 0.9598 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2237 - acc: 0.5691 - top5-acc: 0.9472 - val_loss: 1.0948 - val_acc: 0.6138 - val_top5-acc: 0.9610 - lr: 0.0025\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2202 - acc: 0.5695 - top5-acc: 0.9491 - val_loss: 1.1037 - val_acc: 0.6094 - val_top5-acc: 0.9590 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2307 - acc: 0.5682 - top5-acc: 0.9471 - val_loss: 1.1055 - val_acc: 0.6100 - val_top5-acc: 0.9602 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2327 - acc: 0.5671 - top5-acc: 0.9475 - val_loss: 1.1150 - val_acc: 0.6064 - val_top5-acc: 0.9592 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2282 - acc: 0.5700 - top5-acc: 0.9479 - val_loss: 1.0970 - val_acc: 0.6180 - val_top5-acc: 0.9622 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2119 - acc: 0.5737 - top5-acc: 0.9484 - val_loss: 1.0849 - val_acc: 0.6200 - val_top5-acc: 0.9614 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2059 - acc: 0.5770 - top5-acc: 0.9502 - val_loss: 1.0804 - val_acc: 0.6240 - val_top5-acc: 0.9616 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2055 - acc: 0.5753 - top5-acc: 0.9505 - val_loss: 1.0805 - val_acc: 0.6160 - val_top5-acc: 0.9600 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2097 - acc: 0.5796 - top5-acc: 0.9498 - val_loss: 1.0813 - val_acc: 0.6208 - val_top5-acc: 0.9626 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2076 - acc: 0.5774 - top5-acc: 0.9495 - val_loss: 1.0920 - val_acc: 0.6180 - val_top5-acc: 0.9606 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2072 - acc: 0.5758 - top5-acc: 0.9500 - val_loss: 1.0871 - val_acc: 0.6184 - val_top5-acc: 0.9606 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2157 - acc: 0.5718 - top5-acc: 0.9501 - val_loss: 1.0915 - val_acc: 0.6182 - val_top5-acc: 0.9612 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1944 - acc: 0.5808 - top5-acc: 0.9511 - val_loss: 1.0816 - val_acc: 0.6198 - val_top5-acc: 0.9608 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2027 - acc: 0.5778 - top5-acc: 0.9512 - val_loss: 1.0840 - val_acc: 0.6180 - val_top5-acc: 0.9586 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.1957 - acc: 0.5812 - top5-acc: 0.9508 - val_loss: 1.0769 - val_acc: 0.6256 - val_top5-acc: 0.9618 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.2027 - acc: 0.5782 - top5-acc: 0.9508 - val_loss: 1.0836 - val_acc: 0.6212 - val_top5-acc: 0.9608 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.1976 - acc: 0.5824 - top5-acc: 0.9503 - val_loss: 1.0829 - val_acc: 0.6206 - val_top5-acc: 0.9604 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2014 - acc: 0.5765 - top5-acc: 0.9514 - val_loss: 1.0797 - val_acc: 0.6272 - val_top5-acc: 0.9606 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1938 - acc: 0.5806 - top5-acc: 0.9512 - val_loss: 1.0795 - val_acc: 0.6226 - val_top5-acc: 0.9624 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.2054 - acc: 0.5776 - top5-acc: 0.9495 - val_loss: 1.0793 - val_acc: 0.6230 - val_top5-acc: 0.9610 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1950 - acc: 0.5830 - top5-acc: 0.9518 - val_loss: 1.0811 - val_acc: 0.6228 - val_top5-acc: 0.9626 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1934 - acc: 0.5825 - top5-acc: 0.9516 - val_loss: 1.0790 - val_acc: 0.6224 - val_top5-acc: 0.9620 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1941 - acc: 0.5816 - top5-acc: 0.9501 - val_loss: 1.0812 - val_acc: 0.6202 - val_top5-acc: 0.9598 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1968 - acc: 0.5826 - top5-acc: 0.9503 - val_loss: 1.0799 - val_acc: 0.6224 - val_top5-acc: 0.9602 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1973 - acc: 0.5786 - top5-acc: 0.9512 - val_loss: 1.0862 - val_acc: 0.6216 - val_top5-acc: 0.9600 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.1948 - acc: 0.5857 - top5-acc: 0.9506 - val_loss: 1.0764 - val_acc: 0.6236 - val_top5-acc: 0.9610 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.1130 - acc: 0.6089 - top5-acc: 0.9593\n",
      "Test accuracy: 60.89%\n",
      "Test top 5 accuracy: 95.93%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7554 - acc: 0.4248 - top5-acc: 0.8860WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 8s 79ms/step - loss: 1.7554 - acc: 0.4248 - top5-acc: 0.8860 - val_loss: 1.2790 - val_acc: 0.5462 - val_top5-acc: 0.9480 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.3653 - acc: 0.5222 - top5-acc: 0.9338 - val_loss: 1.2424 - val_acc: 0.5546 - val_top5-acc: 0.9538 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.3185 - acc: 0.5379 - top5-acc: 0.9421 - val_loss: 1.1837 - val_acc: 0.5792 - val_top5-acc: 0.9574 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2750 - acc: 0.5535 - top5-acc: 0.9438 - val_loss: 1.1605 - val_acc: 0.5846 - val_top5-acc: 0.9600 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2638 - acc: 0.5541 - top5-acc: 0.9475 - val_loss: 1.1846 - val_acc: 0.5820 - val_top5-acc: 0.9548 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2419 - acc: 0.5653 - top5-acc: 0.9484 - val_loss: 1.1178 - val_acc: 0.6102 - val_top5-acc: 0.9602 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2343 - acc: 0.5688 - top5-acc: 0.9484 - val_loss: 1.0962 - val_acc: 0.6034 - val_top5-acc: 0.9622 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.2266 - acc: 0.5720 - top5-acc: 0.9499 - val_loss: 1.1446 - val_acc: 0.5988 - val_top5-acc: 0.9568 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2200 - acc: 0.5721 - top5-acc: 0.9497 - val_loss: 1.1176 - val_acc: 0.5966 - val_top5-acc: 0.9628 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2141 - acc: 0.5732 - top5-acc: 0.9496 - val_loss: 1.0988 - val_acc: 0.6050 - val_top5-acc: 0.9628 - lr: 0.0050\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2195 - acc: 0.5732 - top5-acc: 0.9507 - val_loss: 1.0782 - val_acc: 0.6144 - val_top5-acc: 0.9636 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2113 - acc: 0.5754 - top5-acc: 0.9509 - val_loss: 1.1102 - val_acc: 0.6020 - val_top5-acc: 0.9628 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.2097 - acc: 0.5804 - top5-acc: 0.9511 - val_loss: 1.0954 - val_acc: 0.6120 - val_top5-acc: 0.9606 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.2174 - acc: 0.5722 - top5-acc: 0.9516 - val_loss: 1.1024 - val_acc: 0.6068 - val_top5-acc: 0.9590 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.2240 - acc: 0.5721 - top5-acc: 0.9494 - val_loss: 1.1150 - val_acc: 0.6096 - val_top5-acc: 0.9606 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.2180 - acc: 0.5739 - top5-acc: 0.9496 - val_loss: 1.0862 - val_acc: 0.6086 - val_top5-acc: 0.9684 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1768 - acc: 0.5848 - top5-acc: 0.9526 - val_loss: 1.0537 - val_acc: 0.6200 - val_top5-acc: 0.9650 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1692 - acc: 0.5853 - top5-acc: 0.9534 - val_loss: 1.0450 - val_acc: 0.6270 - val_top5-acc: 0.9670 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1721 - acc: 0.5866 - top5-acc: 0.9532 - val_loss: 1.0654 - val_acc: 0.6200 - val_top5-acc: 0.9648 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1790 - acc: 0.5859 - top5-acc: 0.9537 - val_loss: 1.0762 - val_acc: 0.6222 - val_top5-acc: 0.9650 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1819 - acc: 0.5844 - top5-acc: 0.9531 - val_loss: 1.0534 - val_acc: 0.6276 - val_top5-acc: 0.9652 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1779 - acc: 0.5850 - top5-acc: 0.9529 - val_loss: 1.0665 - val_acc: 0.6150 - val_top5-acc: 0.9672 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1768 - acc: 0.5848 - top5-acc: 0.9541 - val_loss: 1.0396 - val_acc: 0.6262 - val_top5-acc: 0.9680 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1680 - acc: 0.5890 - top5-acc: 0.9543 - val_loss: 1.0527 - val_acc: 0.6214 - val_top5-acc: 0.9638 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1718 - acc: 0.5879 - top5-acc: 0.9540 - val_loss: 1.0700 - val_acc: 0.6192 - val_top5-acc: 0.9664 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1697 - acc: 0.5894 - top5-acc: 0.9544 - val_loss: 1.0522 - val_acc: 0.6226 - val_top5-acc: 0.9658 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1739 - acc: 0.5868 - top5-acc: 0.9548 - val_loss: 1.0539 - val_acc: 0.6268 - val_top5-acc: 0.9668 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1680 - acc: 0.5878 - top5-acc: 0.9539 - val_loss: 1.0731 - val_acc: 0.6262 - val_top5-acc: 0.9624 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1587 - acc: 0.5921 - top5-acc: 0.9554 - val_loss: 1.0394 - val_acc: 0.6274 - val_top5-acc: 0.9688 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1578 - acc: 0.5926 - top5-acc: 0.9553 - val_loss: 1.0421 - val_acc: 0.6288 - val_top5-acc: 0.9670 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1575 - acc: 0.5926 - top5-acc: 0.9548 - val_loss: 1.0457 - val_acc: 0.6286 - val_top5-acc: 0.9636 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1577 - acc: 0.5942 - top5-acc: 0.9550 - val_loss: 1.0448 - val_acc: 0.6266 - val_top5-acc: 0.9684 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1568 - acc: 0.5937 - top5-acc: 0.9548 - val_loss: 1.0541 - val_acc: 0.6228 - val_top5-acc: 0.9650 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1579 - acc: 0.5924 - top5-acc: 0.9541 - val_loss: 1.0418 - val_acc: 0.6298 - val_top5-acc: 0.9688 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1482 - acc: 0.5975 - top5-acc: 0.9550 - val_loss: 1.0322 - val_acc: 0.6306 - val_top5-acc: 0.9684 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1454 - acc: 0.5950 - top5-acc: 0.9554 - val_loss: 1.0390 - val_acc: 0.6306 - val_top5-acc: 0.9668 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1494 - acc: 0.5950 - top5-acc: 0.9553 - val_loss: 1.0286 - val_acc: 0.6320 - val_top5-acc: 0.9690 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1467 - acc: 0.5977 - top5-acc: 0.9567 - val_loss: 1.0339 - val_acc: 0.6306 - val_top5-acc: 0.9674 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1443 - acc: 0.5971 - top5-acc: 0.9564 - val_loss: 1.0341 - val_acc: 0.6280 - val_top5-acc: 0.9690 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1490 - acc: 0.5956 - top5-acc: 0.9559 - val_loss: 1.0334 - val_acc: 0.6314 - val_top5-acc: 0.9684 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1487 - acc: 0.5949 - top5-acc: 0.9562 - val_loss: 1.0432 - val_acc: 0.6252 - val_top5-acc: 0.9668 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1438 - acc: 0.5986 - top5-acc: 0.9581 - val_loss: 1.0402 - val_acc: 0.6364 - val_top5-acc: 0.9656 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1441 - acc: 0.5966 - top5-acc: 0.9565 - val_loss: 1.0344 - val_acc: 0.6290 - val_top5-acc: 0.9680 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1421 - acc: 0.6001 - top5-acc: 0.9564 - val_loss: 1.0367 - val_acc: 0.6312 - val_top5-acc: 0.9674 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1431 - acc: 0.6004 - top5-acc: 0.9563 - val_loss: 1.0348 - val_acc: 0.6344 - val_top5-acc: 0.9690 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.1418 - acc: 0.5987 - top5-acc: 0.9567 - val_loss: 1.0376 - val_acc: 0.6308 - val_top5-acc: 0.9688 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1420 - acc: 0.5994 - top5-acc: 0.9560 - val_loss: 1.0366 - val_acc: 0.6306 - val_top5-acc: 0.9672 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1416 - acc: 0.5969 - top5-acc: 0.9573 - val_loss: 1.0344 - val_acc: 0.6352 - val_top5-acc: 0.9676 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.1427 - acc: 0.5986 - top5-acc: 0.9566 - val_loss: 1.0341 - val_acc: 0.6312 - val_top5-acc: 0.9682 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.1439 - acc: 0.5988 - top5-acc: 0.9572 - val_loss: 1.0352 - val_acc: 0.6316 - val_top5-acc: 0.9684 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 1.0696 - acc: 0.6248 - top5-acc: 0.9615\n",
      "Test accuracy: 62.48%\n",
      "Test top 5 accuracy: 96.15%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8883 - acc: 0.4101 - top5-acc: 0.8693WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 9s 87ms/step - loss: 1.8883 - acc: 0.4101 - top5-acc: 0.8693 - val_loss: 1.3389 - val_acc: 0.5258 - val_top5-acc: 0.9422 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3299 - acc: 0.5348 - top5-acc: 0.9373 - val_loss: 1.1963 - val_acc: 0.5812 - val_top5-acc: 0.9574 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.2644 - acc: 0.5535 - top5-acc: 0.9459 - val_loss: 1.1599 - val_acc: 0.5912 - val_top5-acc: 0.9576 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.2342 - acc: 0.5650 - top5-acc: 0.9492 - val_loss: 1.1116 - val_acc: 0.6156 - val_top5-acc: 0.9608 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.2117 - acc: 0.5730 - top5-acc: 0.9531 - val_loss: 1.1330 - val_acc: 0.5912 - val_top5-acc: 0.9638 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.2028 - acc: 0.5774 - top5-acc: 0.9526 - val_loss: 1.1285 - val_acc: 0.6024 - val_top5-acc: 0.9620 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1851 - acc: 0.5835 - top5-acc: 0.9548 - val_loss: 1.1073 - val_acc: 0.6060 - val_top5-acc: 0.9640 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1760 - acc: 0.5827 - top5-acc: 0.9550 - val_loss: 1.0968 - val_acc: 0.6186 - val_top5-acc: 0.9628 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1802 - acc: 0.5840 - top5-acc: 0.9553 - val_loss: 1.0799 - val_acc: 0.6158 - val_top5-acc: 0.9646 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1819 - acc: 0.5843 - top5-acc: 0.9551 - val_loss: 1.1200 - val_acc: 0.6056 - val_top5-acc: 0.9640 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1699 - acc: 0.5887 - top5-acc: 0.9552 - val_loss: 1.0700 - val_acc: 0.6298 - val_top5-acc: 0.9682 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1700 - acc: 0.5880 - top5-acc: 0.9556 - val_loss: 1.0504 - val_acc: 0.6374 - val_top5-acc: 0.9694 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1693 - acc: 0.5881 - top5-acc: 0.9555 - val_loss: 1.0621 - val_acc: 0.6214 - val_top5-acc: 0.9714 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1727 - acc: 0.5878 - top5-acc: 0.9552 - val_loss: 1.0677 - val_acc: 0.6232 - val_top5-acc: 0.9664 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1696 - acc: 0.5871 - top5-acc: 0.9554 - val_loss: 1.0537 - val_acc: 0.6288 - val_top5-acc: 0.9658 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1614 - acc: 0.5896 - top5-acc: 0.9562 - val_loss: 1.0402 - val_acc: 0.6354 - val_top5-acc: 0.9704 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1639 - acc: 0.5902 - top5-acc: 0.9564 - val_loss: 1.0264 - val_acc: 0.6386 - val_top5-acc: 0.9688 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1649 - acc: 0.5907 - top5-acc: 0.9552 - val_loss: 1.0806 - val_acc: 0.6256 - val_top5-acc: 0.9668 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1704 - acc: 0.5868 - top5-acc: 0.9564 - val_loss: 1.0686 - val_acc: 0.6212 - val_top5-acc: 0.9660 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1733 - acc: 0.5890 - top5-acc: 0.9560 - val_loss: 1.0770 - val_acc: 0.6208 - val_top5-acc: 0.9658 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1591 - acc: 0.5928 - top5-acc: 0.9564 - val_loss: 1.0664 - val_acc: 0.6314 - val_top5-acc: 0.9650 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1482 - acc: 0.5973 - top5-acc: 0.9582 - val_loss: 1.0544 - val_acc: 0.6272 - val_top5-acc: 0.9666 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1289 - acc: 0.6038 - top5-acc: 0.9586 - val_loss: 1.0139 - val_acc: 0.6424 - val_top5-acc: 0.9698 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1257 - acc: 0.6023 - top5-acc: 0.9606 - val_loss: 1.0223 - val_acc: 0.6462 - val_top5-acc: 0.9688 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1286 - acc: 0.6005 - top5-acc: 0.9575 - val_loss: 1.0359 - val_acc: 0.6388 - val_top5-acc: 0.9668 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1303 - acc: 0.6028 - top5-acc: 0.9579 - val_loss: 1.0195 - val_acc: 0.6394 - val_top5-acc: 0.9674 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1291 - acc: 0.6021 - top5-acc: 0.9595 - val_loss: 1.0159 - val_acc: 0.6378 - val_top5-acc: 0.9712 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1297 - acc: 0.6006 - top5-acc: 0.9589 - val_loss: 1.0186 - val_acc: 0.6396 - val_top5-acc: 0.9698 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1173 - acc: 0.6063 - top5-acc: 0.9581 - val_loss: 1.0161 - val_acc: 0.6390 - val_top5-acc: 0.9704 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1098 - acc: 0.6083 - top5-acc: 0.9606 - val_loss: 1.0125 - val_acc: 0.6400 - val_top5-acc: 0.9726 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1133 - acc: 0.6074 - top5-acc: 0.9590 - val_loss: 1.0131 - val_acc: 0.6426 - val_top5-acc: 0.9712 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1101 - acc: 0.6050 - top5-acc: 0.9610 - val_loss: 1.0098 - val_acc: 0.6460 - val_top5-acc: 0.9708 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1125 - acc: 0.6071 - top5-acc: 0.9604 - val_loss: 1.0111 - val_acc: 0.6470 - val_top5-acc: 0.9718 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1150 - acc: 0.6061 - top5-acc: 0.9607 - val_loss: 1.0087 - val_acc: 0.6428 - val_top5-acc: 0.9716 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1157 - acc: 0.6081 - top5-acc: 0.9589 - val_loss: 1.0155 - val_acc: 0.6388 - val_top5-acc: 0.9722 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1156 - acc: 0.6052 - top5-acc: 0.9589 - val_loss: 1.0088 - val_acc: 0.6458 - val_top5-acc: 0.9720 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1114 - acc: 0.6094 - top5-acc: 0.9591 - val_loss: 1.0225 - val_acc: 0.6452 - val_top5-acc: 0.9694 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1144 - acc: 0.6094 - top5-acc: 0.9599 - val_loss: 1.0061 - val_acc: 0.6442 - val_top5-acc: 0.9708 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1158 - acc: 0.6056 - top5-acc: 0.9598 - val_loss: 1.0207 - val_acc: 0.6364 - val_top5-acc: 0.9714 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1180 - acc: 0.6066 - top5-acc: 0.9592 - val_loss: 1.0124 - val_acc: 0.6390 - val_top5-acc: 0.9696 - lr: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1189 - acc: 0.6039 - top5-acc: 0.9595 - val_loss: 1.0341 - val_acc: 0.6330 - val_top5-acc: 0.9724 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1173 - acc: 0.6062 - top5-acc: 0.9608 - val_loss: 1.0237 - val_acc: 0.6378 - val_top5-acc: 0.9718 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1206 - acc: 0.6087 - top5-acc: 0.9599 - val_loss: 1.0089 - val_acc: 0.6462 - val_top5-acc: 0.9718 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1083 - acc: 0.6105 - top5-acc: 0.9608 - val_loss: 1.0048 - val_acc: 0.6500 - val_top5-acc: 0.9716 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1073 - acc: 0.6095 - top5-acc: 0.9608 - val_loss: 1.0042 - val_acc: 0.6468 - val_top5-acc: 0.9722 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1066 - acc: 0.6112 - top5-acc: 0.9601 - val_loss: 1.0108 - val_acc: 0.6464 - val_top5-acc: 0.9708 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1061 - acc: 0.6121 - top5-acc: 0.9604 - val_loss: 1.0056 - val_acc: 0.6500 - val_top5-acc: 0.9720 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.1037 - acc: 0.6100 - top5-acc: 0.9615 - val_loss: 1.0072 - val_acc: 0.6464 - val_top5-acc: 0.9718 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1074 - acc: 0.6099 - top5-acc: 0.9604 - val_loss: 1.0089 - val_acc: 0.6434 - val_top5-acc: 0.9722 - lr: 6.2500e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.1065 - acc: 0.6108 - top5-acc: 0.9602 - val_loss: 1.0120 - val_acc: 0.6420 - val_top5-acc: 0.9712 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 1.0402 - acc: 0.6352 - top5-acc: 0.9655\n",
      "Test accuracy: 63.52%\n",
      "Test top 5 accuracy: 96.55%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7526 - acc: 0.4204 - top5-acc: 0.8744WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 10s 96ms/step - loss: 1.7526 - acc: 0.4204 - top5-acc: 0.8744 - val_loss: 1.2577 - val_acc: 0.5506 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3090 - acc: 0.5380 - top5-acc: 0.9382 - val_loss: 1.1473 - val_acc: 0.5948 - val_top5-acc: 0.9592 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.2365 - acc: 0.5642 - top5-acc: 0.9466 - val_loss: 1.1395 - val_acc: 0.5838 - val_top5-acc: 0.9620 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.2053 - acc: 0.5762 - top5-acc: 0.9494 - val_loss: 1.0907 - val_acc: 0.6134 - val_top5-acc: 0.9594 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1893 - acc: 0.5815 - top5-acc: 0.9514 - val_loss: 1.0553 - val_acc: 0.6328 - val_top5-acc: 0.9598 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1742 - acc: 0.5911 - top5-acc: 0.9515 - val_loss: 1.0463 - val_acc: 0.6298 - val_top5-acc: 0.9648 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1619 - acc: 0.5919 - top5-acc: 0.9539 - val_loss: 1.0344 - val_acc: 0.6318 - val_top5-acc: 0.9642 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1566 - acc: 0.5931 - top5-acc: 0.9557 - val_loss: 1.0715 - val_acc: 0.6118 - val_top5-acc: 0.9608 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1666 - acc: 0.5895 - top5-acc: 0.9528 - val_loss: 1.0384 - val_acc: 0.6360 - val_top5-acc: 0.9660 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1504 - acc: 0.5935 - top5-acc: 0.9557 - val_loss: 1.0242 - val_acc: 0.6440 - val_top5-acc: 0.9650 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1560 - acc: 0.5937 - top5-acc: 0.9556 - val_loss: 1.0459 - val_acc: 0.6276 - val_top5-acc: 0.9654 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1624 - acc: 0.5915 - top5-acc: 0.9552 - val_loss: 1.0380 - val_acc: 0.6318 - val_top5-acc: 0.9652 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1467 - acc: 0.5954 - top5-acc: 0.9555 - val_loss: 1.0221 - val_acc: 0.6416 - val_top5-acc: 0.9654 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 1.1429 - acc: 0.6002 - top5-acc: 0.9565 - val_loss: 1.0025 - val_acc: 0.6472 - val_top5-acc: 0.9692 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 1.1513 - acc: 0.5990 - top5-acc: 0.9555 - val_loss: 1.0285 - val_acc: 0.6372 - val_top5-acc: 0.9654 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 1.1609 - acc: 0.5930 - top5-acc: 0.9557 - val_loss: 1.0018 - val_acc: 0.6512 - val_top5-acc: 0.9676 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1528 - acc: 0.5963 - top5-acc: 0.9562 - val_loss: 1.0173 - val_acc: 0.6442 - val_top5-acc: 0.9688 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1487 - acc: 0.5985 - top5-acc: 0.9556 - val_loss: 1.0313 - val_acc: 0.6350 - val_top5-acc: 0.9656 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1498 - acc: 0.5971 - top5-acc: 0.9549 - val_loss: 1.0638 - val_acc: 0.6154 - val_top5-acc: 0.9666 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1494 - acc: 0.5982 - top5-acc: 0.9555 - val_loss: 1.0220 - val_acc: 0.6388 - val_top5-acc: 0.9680 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1517 - acc: 0.5959 - top5-acc: 0.9563 - val_loss: 1.0427 - val_acc: 0.6358 - val_top5-acc: 0.9594 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1187 - acc: 0.6070 - top5-acc: 0.9577 - val_loss: 1.0018 - val_acc: 0.6502 - val_top5-acc: 0.9684 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1129 - acc: 0.6113 - top5-acc: 0.9573 - val_loss: 0.9900 - val_acc: 0.6500 - val_top5-acc: 0.9676 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1143 - acc: 0.6093 - top5-acc: 0.9577 - val_loss: 0.9879 - val_acc: 0.6528 - val_top5-acc: 0.9704 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1249 - acc: 0.6012 - top5-acc: 0.9565 - val_loss: 0.9975 - val_acc: 0.6430 - val_top5-acc: 0.9684 - lr: 0.0025\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1123 - acc: 0.6101 - top5-acc: 0.9584 - val_loss: 1.0029 - val_acc: 0.6446 - val_top5-acc: 0.9688 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1169 - acc: 0.6069 - top5-acc: 0.9582 - val_loss: 0.9996 - val_acc: 0.6520 - val_top5-acc: 0.9686 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1218 - acc: 0.6052 - top5-acc: 0.9585 - val_loss: 1.0003 - val_acc: 0.6534 - val_top5-acc: 0.9676 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1176 - acc: 0.6070 - top5-acc: 0.9578 - val_loss: 0.9899 - val_acc: 0.6544 - val_top5-acc: 0.9694 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1031 - acc: 0.6125 - top5-acc: 0.9588 - val_loss: 0.9958 - val_acc: 0.6468 - val_top5-acc: 0.9704 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1021 - acc: 0.6128 - top5-acc: 0.9590 - val_loss: 0.9807 - val_acc: 0.6570 - val_top5-acc: 0.9702 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1038 - acc: 0.6093 - top5-acc: 0.9593 - val_loss: 0.9780 - val_acc: 0.6582 - val_top5-acc: 0.9688 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1008 - acc: 0.6115 - top5-acc: 0.9596 - val_loss: 0.9835 - val_acc: 0.6510 - val_top5-acc: 0.9692 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1017 - acc: 0.6135 - top5-acc: 0.9588 - val_loss: 0.9855 - val_acc: 0.6556 - val_top5-acc: 0.9690 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1009 - acc: 0.6150 - top5-acc: 0.9589 - val_loss: 0.9896 - val_acc: 0.6544 - val_top5-acc: 0.9686 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.1024 - acc: 0.6133 - top5-acc: 0.9588 - val_loss: 1.0009 - val_acc: 0.6488 - val_top5-acc: 0.9686 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.1047 - acc: 0.6102 - top5-acc: 0.9592 - val_loss: 0.9911 - val_acc: 0.6516 - val_top5-acc: 0.9704 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.0943 - acc: 0.6188 - top5-acc: 0.9588 - val_loss: 0.9799 - val_acc: 0.6560 - val_top5-acc: 0.9684 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.0958 - acc: 0.6172 - top5-acc: 0.9582 - val_loss: 0.9797 - val_acc: 0.6562 - val_top5-acc: 0.9694 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0995 - acc: 0.6141 - top5-acc: 0.9590 - val_loss: 0.9911 - val_acc: 0.6536 - val_top5-acc: 0.9700 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.0952 - acc: 0.6143 - top5-acc: 0.9591 - val_loss: 0.9899 - val_acc: 0.6492 - val_top5-acc: 0.9706 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.0922 - acc: 0.6157 - top5-acc: 0.9595 - val_loss: 0.9823 - val_acc: 0.6546 - val_top5-acc: 0.9702 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0925 - acc: 0.6153 - top5-acc: 0.9599 - val_loss: 0.9819 - val_acc: 0.6568 - val_top5-acc: 0.9704 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0929 - acc: 0.6157 - top5-acc: 0.9595 - val_loss: 0.9820 - val_acc: 0.6540 - val_top5-acc: 0.9702 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0939 - acc: 0.6157 - top5-acc: 0.9606 - val_loss: 0.9821 - val_acc: 0.6522 - val_top5-acc: 0.9698 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.0920 - acc: 0.6179 - top5-acc: 0.9605 - val_loss: 0.9857 - val_acc: 0.6540 - val_top5-acc: 0.9698 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0941 - acc: 0.6170 - top5-acc: 0.9585 - val_loss: 0.9883 - val_acc: 0.6526 - val_top5-acc: 0.9702 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0905 - acc: 0.6169 - top5-acc: 0.9601 - val_loss: 0.9832 - val_acc: 0.6552 - val_top5-acc: 0.9704 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0904 - acc: 0.6200 - top5-acc: 0.9607 - val_loss: 0.9845 - val_acc: 0.6544 - val_top5-acc: 0.9710 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.0916 - acc: 0.6195 - top5-acc: 0.9593 - val_loss: 0.9827 - val_acc: 0.6534 - val_top5-acc: 0.9716 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 11s 35ms/step - loss: 1.0133 - acc: 0.6421 - top5-acc: 0.9661\n",
      "Test accuracy: 64.21%\n",
      "Test top 5 accuracy: 96.61%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.6616 - acc: 0.4361 - top5-acc: 0.8804WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 11s 103ms/step - loss: 1.6616 - acc: 0.4361 - top5-acc: 0.8804 - val_loss: 1.2282 - val_acc: 0.5688 - val_top5-acc: 0.9502 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.2936 - acc: 0.5444 - top5-acc: 0.9384 - val_loss: 1.1403 - val_acc: 0.5888 - val_top5-acc: 0.9548 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.2236 - acc: 0.5690 - top5-acc: 0.9463 - val_loss: 1.0659 - val_acc: 0.6232 - val_top5-acc: 0.9636 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1971 - acc: 0.5790 - top5-acc: 0.9502 - val_loss: 1.0757 - val_acc: 0.6232 - val_top5-acc: 0.9630 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1777 - acc: 0.5865 - top5-acc: 0.9517 - val_loss: 1.0509 - val_acc: 0.6266 - val_top5-acc: 0.9626 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1677 - acc: 0.5906 - top5-acc: 0.9519 - val_loss: 1.1004 - val_acc: 0.6164 - val_top5-acc: 0.9602 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1669 - acc: 0.5890 - top5-acc: 0.9530 - val_loss: 1.0443 - val_acc: 0.6344 - val_top5-acc: 0.9618 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1456 - acc: 0.5970 - top5-acc: 0.9549 - val_loss: 1.0261 - val_acc: 0.6382 - val_top5-acc: 0.9640 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1519 - acc: 0.5954 - top5-acc: 0.9542 - val_loss: 1.0168 - val_acc: 0.6420 - val_top5-acc: 0.9644 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1533 - acc: 0.5926 - top5-acc: 0.9538 - val_loss: 1.0130 - val_acc: 0.6388 - val_top5-acc: 0.9674 - lr: 0.0050\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1493 - acc: 0.5956 - top5-acc: 0.9541 - val_loss: 1.0196 - val_acc: 0.6372 - val_top5-acc: 0.9662 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1395 - acc: 0.5977 - top5-acc: 0.9552 - val_loss: 1.0231 - val_acc: 0.6338 - val_top5-acc: 0.9648 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1431 - acc: 0.5983 - top5-acc: 0.9540 - val_loss: 1.0295 - val_acc: 0.6472 - val_top5-acc: 0.9652 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1341 - acc: 0.6006 - top5-acc: 0.9555 - val_loss: 1.0417 - val_acc: 0.6320 - val_top5-acc: 0.9650 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1472 - acc: 0.5938 - top5-acc: 0.9564 - val_loss: 1.0072 - val_acc: 0.6464 - val_top5-acc: 0.9644 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1434 - acc: 0.5984 - top5-acc: 0.9560 - val_loss: 1.0318 - val_acc: 0.6274 - val_top5-acc: 0.9654 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1428 - acc: 0.5977 - top5-acc: 0.9552 - val_loss: 1.0539 - val_acc: 0.6234 - val_top5-acc: 0.9632 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1372 - acc: 0.5999 - top5-acc: 0.9554 - val_loss: 1.0257 - val_acc: 0.6306 - val_top5-acc: 0.9678 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1408 - acc: 0.5963 - top5-acc: 0.9566 - val_loss: 1.0059 - val_acc: 0.6454 - val_top5-acc: 0.9668 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1410 - acc: 0.6006 - top5-acc: 0.9556 - val_loss: 1.0109 - val_acc: 0.6406 - val_top5-acc: 0.9636 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1370 - acc: 0.6016 - top5-acc: 0.9563 - val_loss: 1.0342 - val_acc: 0.6310 - val_top5-acc: 0.9632 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1345 - acc: 0.5992 - top5-acc: 0.9562 - val_loss: 1.0616 - val_acc: 0.6248 - val_top5-acc: 0.9642 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1501 - acc: 0.5974 - top5-acc: 0.9543 - val_loss: 1.0113 - val_acc: 0.6406 - val_top5-acc: 0.9678 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1376 - acc: 0.5998 - top5-acc: 0.9545 - val_loss: 1.0209 - val_acc: 0.6392 - val_top5-acc: 0.9646 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1175 - acc: 0.6067 - top5-acc: 0.9582 - val_loss: 0.9933 - val_acc: 0.6520 - val_top5-acc: 0.9674 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1158 - acc: 0.6078 - top5-acc: 0.9575 - val_loss: 1.0071 - val_acc: 0.6448 - val_top5-acc: 0.9668 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1072 - acc: 0.6104 - top5-acc: 0.9577 - val_loss: 0.9955 - val_acc: 0.6484 - val_top5-acc: 0.9660 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1054 - acc: 0.6092 - top5-acc: 0.9584 - val_loss: 0.9932 - val_acc: 0.6488 - val_top5-acc: 0.9684 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1118 - acc: 0.6077 - top5-acc: 0.9582 - val_loss: 1.0200 - val_acc: 0.6360 - val_top5-acc: 0.9642 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1123 - acc: 0.6071 - top5-acc: 0.9577 - val_loss: 0.9958 - val_acc: 0.6488 - val_top5-acc: 0.9678 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0969 - acc: 0.6161 - top5-acc: 0.9598 - val_loss: 0.9819 - val_acc: 0.6508 - val_top5-acc: 0.9680 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0995 - acc: 0.6116 - top5-acc: 0.9595 - val_loss: 0.9833 - val_acc: 0.6496 - val_top5-acc: 0.9672 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1010 - acc: 0.6144 - top5-acc: 0.9583 - val_loss: 0.9810 - val_acc: 0.6544 - val_top5-acc: 0.9678 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.1017 - acc: 0.6120 - top5-acc: 0.9590 - val_loss: 0.9801 - val_acc: 0.6534 - val_top5-acc: 0.9698 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0973 - acc: 0.6141 - top5-acc: 0.9586 - val_loss: 0.9899 - val_acc: 0.6506 - val_top5-acc: 0.9678 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1041 - acc: 0.6124 - top5-acc: 0.9575 - val_loss: 0.9874 - val_acc: 0.6510 - val_top5-acc: 0.9682 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1028 - acc: 0.6109 - top5-acc: 0.9572 - val_loss: 0.9935 - val_acc: 0.6484 - val_top5-acc: 0.9672 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.1002 - acc: 0.6111 - top5-acc: 0.9583 - val_loss: 0.9937 - val_acc: 0.6494 - val_top5-acc: 0.9676 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0961 - acc: 0.6140 - top5-acc: 0.9595 - val_loss: 0.9935 - val_acc: 0.6526 - val_top5-acc: 0.9678 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0926 - acc: 0.6140 - top5-acc: 0.9596 - val_loss: 0.9844 - val_acc: 0.6510 - val_top5-acc: 0.9698 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0886 - acc: 0.6169 - top5-acc: 0.9595 - val_loss: 0.9830 - val_acc: 0.6516 - val_top5-acc: 0.9680 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0950 - acc: 0.6149 - top5-acc: 0.9595 - val_loss: 0.9852 - val_acc: 0.6514 - val_top5-acc: 0.9682 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0936 - acc: 0.6156 - top5-acc: 0.9588 - val_loss: 0.9852 - val_acc: 0.6522 - val_top5-acc: 0.9684 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0912 - acc: 0.6159 - top5-acc: 0.9594 - val_loss: 0.9867 - val_acc: 0.6528 - val_top5-acc: 0.9690 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0939 - acc: 0.6145 - top5-acc: 0.9595 - val_loss: 0.9809 - val_acc: 0.6552 - val_top5-acc: 0.9676 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0908 - acc: 0.6180 - top5-acc: 0.9587 - val_loss: 0.9850 - val_acc: 0.6530 - val_top5-acc: 0.9678 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0961 - acc: 0.6151 - top5-acc: 0.9590 - val_loss: 0.9836 - val_acc: 0.6524 - val_top5-acc: 0.9684 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.0950 - acc: 0.6173 - top5-acc: 0.9589 - val_loss: 0.9843 - val_acc: 0.6550 - val_top5-acc: 0.9690 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0938 - acc: 0.6152 - top5-acc: 0.9590 - val_loss: 0.9876 - val_acc: 0.6532 - val_top5-acc: 0.9686 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.0873 - acc: 0.6163 - top5-acc: 0.9602 - val_loss: 0.9886 - val_acc: 0.6524 - val_top5-acc: 0.9688 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 1.0144 - acc: 0.6352 - top5-acc: 0.9688\n",
      "Test accuracy: 63.52%\n",
      "Test top 5 accuracy: 96.88%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1427 - acc: 0.6150 - top5-acc: 0.9463WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 12s 112ms/step - loss: 1.1427 - acc: 0.6150 - top5-acc: 0.9463 - val_loss: 0.8820 - val_acc: 0.7000 - val_top5-acc: 0.9762 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.8506 - acc: 0.7006 - top5-acc: 0.9781 - val_loss: 0.8641 - val_acc: 0.7102 - val_top5-acc: 0.9774 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.8161 - acc: 0.7116 - top5-acc: 0.9811 - val_loss: 0.8477 - val_acc: 0.7142 - val_top5-acc: 0.9786 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.8032 - acc: 0.7157 - top5-acc: 0.9813 - val_loss: 0.8480 - val_acc: 0.7154 - val_top5-acc: 0.9778 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7928 - acc: 0.7191 - top5-acc: 0.9813 - val_loss: 0.8449 - val_acc: 0.7212 - val_top5-acc: 0.9778 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7970 - acc: 0.7200 - top5-acc: 0.9820 - val_loss: 0.8177 - val_acc: 0.7262 - val_top5-acc: 0.9814 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7936 - acc: 0.7188 - top5-acc: 0.9820 - val_loss: 0.8375 - val_acc: 0.7202 - val_top5-acc: 0.9778 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.8004 - acc: 0.7197 - top5-acc: 0.9811 - val_loss: 0.8317 - val_acc: 0.7226 - val_top5-acc: 0.9792 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7980 - acc: 0.7192 - top5-acc: 0.9812 - val_loss: 0.8272 - val_acc: 0.7264 - val_top5-acc: 0.9796 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7940 - acc: 0.7198 - top5-acc: 0.9812 - val_loss: 0.8424 - val_acc: 0.7214 - val_top5-acc: 0.9782 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7991 - acc: 0.7182 - top5-acc: 0.9816 - val_loss: 0.8365 - val_acc: 0.7168 - val_top5-acc: 0.9778 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7766 - acc: 0.7268 - top5-acc: 0.9820 - val_loss: 0.8077 - val_acc: 0.7268 - val_top5-acc: 0.9810 - lr: 0.0025\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7711 - acc: 0.7268 - top5-acc: 0.9827 - val_loss: 0.8196 - val_acc: 0.7272 - val_top5-acc: 0.9808 - lr: 0.0025\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7694 - acc: 0.7283 - top5-acc: 0.9826 - val_loss: 0.8080 - val_acc: 0.7242 - val_top5-acc: 0.9800 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7697 - acc: 0.7303 - top5-acc: 0.9826 - val_loss: 0.8085 - val_acc: 0.7276 - val_top5-acc: 0.9798 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7726 - acc: 0.7275 - top5-acc: 0.9828 - val_loss: 0.7962 - val_acc: 0.7286 - val_top5-acc: 0.9814 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7679 - acc: 0.7267 - top5-acc: 0.9825 - val_loss: 0.8190 - val_acc: 0.7274 - val_top5-acc: 0.9814 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7700 - acc: 0.7273 - top5-acc: 0.9827 - val_loss: 0.8111 - val_acc: 0.7226 - val_top5-acc: 0.9798 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7693 - acc: 0.7268 - top5-acc: 0.9825 - val_loss: 0.8071 - val_acc: 0.7290 - val_top5-acc: 0.9798 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7655 - acc: 0.7284 - top5-acc: 0.9830 - val_loss: 0.8098 - val_acc: 0.7292 - val_top5-acc: 0.9800 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7649 - acc: 0.7284 - top5-acc: 0.9820 - val_loss: 0.8011 - val_acc: 0.7304 - val_top5-acc: 0.9804 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7593 - acc: 0.7315 - top5-acc: 0.9829 - val_loss: 0.7975 - val_acc: 0.7296 - val_top5-acc: 0.9810 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7558 - acc: 0.7312 - top5-acc: 0.9834 - val_loss: 0.8012 - val_acc: 0.7268 - val_top5-acc: 0.9806 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7583 - acc: 0.7312 - top5-acc: 0.9826 - val_loss: 0.7919 - val_acc: 0.7312 - val_top5-acc: 0.9814 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7572 - acc: 0.7319 - top5-acc: 0.9826 - val_loss: 0.7970 - val_acc: 0.7294 - val_top5-acc: 0.9816 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7552 - acc: 0.7348 - top5-acc: 0.9825 - val_loss: 0.7927 - val_acc: 0.7298 - val_top5-acc: 0.9816 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7533 - acc: 0.7336 - top5-acc: 0.9829 - val_loss: 0.8087 - val_acc: 0.7254 - val_top5-acc: 0.9798 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7585 - acc: 0.7328 - top5-acc: 0.9828 - val_loss: 0.8049 - val_acc: 0.7250 - val_top5-acc: 0.9806 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7603 - acc: 0.7303 - top5-acc: 0.9836 - val_loss: 0.8042 - val_acc: 0.7272 - val_top5-acc: 0.9816 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7460 - acc: 0.7357 - top5-acc: 0.9837 - val_loss: 0.7926 - val_acc: 0.7310 - val_top5-acc: 0.9818 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7458 - acc: 0.7354 - top5-acc: 0.9843 - val_loss: 0.7893 - val_acc: 0.7292 - val_top5-acc: 0.9812 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7507 - acc: 0.7341 - top5-acc: 0.9842 - val_loss: 0.7942 - val_acc: 0.7318 - val_top5-acc: 0.9812 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7479 - acc: 0.7356 - top5-acc: 0.9837 - val_loss: 0.7919 - val_acc: 0.7294 - val_top5-acc: 0.9802 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7466 - acc: 0.7332 - top5-acc: 0.9833 - val_loss: 0.7854 - val_acc: 0.7322 - val_top5-acc: 0.9820 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7496 - acc: 0.7359 - top5-acc: 0.9837 - val_loss: 0.7868 - val_acc: 0.7300 - val_top5-acc: 0.9808 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7498 - acc: 0.7346 - top5-acc: 0.9839 - val_loss: 0.7845 - val_acc: 0.7304 - val_top5-acc: 0.9802 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7475 - acc: 0.7354 - top5-acc: 0.9840 - val_loss: 0.7831 - val_acc: 0.7288 - val_top5-acc: 0.9810 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7462 - acc: 0.7354 - top5-acc: 0.9836 - val_loss: 0.7889 - val_acc: 0.7290 - val_top5-acc: 0.9812 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7483 - acc: 0.7373 - top5-acc: 0.9838 - val_loss: 0.7832 - val_acc: 0.7302 - val_top5-acc: 0.9822 - lr: 6.2500e-04\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7493 - acc: 0.7348 - top5-acc: 0.9842 - val_loss: 0.7965 - val_acc: 0.7346 - val_top5-acc: 0.9814 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7454 - acc: 0.7363 - top5-acc: 0.9842 - val_loss: 0.7921 - val_acc: 0.7324 - val_top5-acc: 0.9818 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7507 - acc: 0.7350 - top5-acc: 0.9837 - val_loss: 0.7923 - val_acc: 0.7284 - val_top5-acc: 0.9802 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7456 - acc: 0.7387 - top5-acc: 0.9831 - val_loss: 0.7857 - val_acc: 0.7324 - val_top5-acc: 0.9810 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7503 - acc: 0.7371 - top5-acc: 0.9841 - val_loss: 0.7849 - val_acc: 0.7314 - val_top5-acc: 0.9820 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7484 - acc: 0.7373 - top5-acc: 0.9832 - val_loss: 0.7859 - val_acc: 0.7316 - val_top5-acc: 0.9816 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7483 - acc: 0.7359 - top5-acc: 0.9832 - val_loss: 0.7879 - val_acc: 0.7304 - val_top5-acc: 0.9812 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7464 - acc: 0.7370 - top5-acc: 0.9826 - val_loss: 0.7844 - val_acc: 0.7310 - val_top5-acc: 0.9810 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7449 - acc: 0.7375 - top5-acc: 0.9838 - val_loss: 0.7859 - val_acc: 0.7306 - val_top5-acc: 0.9814 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 0.7476 - acc: 0.7374 - top5-acc: 0.9836 - val_loss: 0.7855 - val_acc: 0.7300 - val_top5-acc: 0.9802 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 9s 105ms/step - loss: 0.7513 - acc: 0.7366 - top5-acc: 0.9832 - val_loss: 0.7838 - val_acc: 0.7300 - val_top5-acc: 0.9804 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 14s 43ms/step - loss: 0.8320 - acc: 0.7106 - top5-acc: 0.9774\n",
      "Test accuracy: 71.06%\n",
      "Test top 5 accuracy: 97.74%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 0.6895 - acc: 0.7632 - top5-acc: 0.9754WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 13s 120ms/step - loss: 0.6895 - acc: 0.7632 - top5-acc: 0.9754 - val_loss: 0.7695 - val_acc: 0.7698 - val_top5-acc: 0.9834 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.5033 - acc: 0.8227 - top5-acc: 0.9932 - val_loss: 0.7525 - val_acc: 0.7726 - val_top5-acc: 0.9846 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4872 - acc: 0.8277 - top5-acc: 0.9939 - val_loss: 0.7527 - val_acc: 0.7688 - val_top5-acc: 0.9842 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4882 - acc: 0.8284 - top5-acc: 0.9938 - val_loss: 0.7416 - val_acc: 0.7738 - val_top5-acc: 0.9848 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4789 - acc: 0.8312 - top5-acc: 0.9936 - val_loss: 0.7544 - val_acc: 0.7672 - val_top5-acc: 0.9858 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4746 - acc: 0.8325 - top5-acc: 0.9939 - val_loss: 0.7603 - val_acc: 0.7688 - val_top5-acc: 0.9854 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4801 - acc: 0.8301 - top5-acc: 0.9938 - val_loss: 0.7473 - val_acc: 0.7714 - val_top5-acc: 0.9854 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4792 - acc: 0.8281 - top5-acc: 0.9945 - val_loss: 0.7505 - val_acc: 0.7728 - val_top5-acc: 0.9854 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4817 - acc: 0.8286 - top5-acc: 0.9945 - val_loss: 0.7586 - val_acc: 0.7692 - val_top5-acc: 0.9868 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4664 - acc: 0.8348 - top5-acc: 0.9946 - val_loss: 0.7357 - val_acc: 0.7732 - val_top5-acc: 0.9862 - lr: 0.0025\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4677 - acc: 0.8328 - top5-acc: 0.9939 - val_loss: 0.7347 - val_acc: 0.7730 - val_top5-acc: 0.9860 - lr: 0.0025\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4678 - acc: 0.8346 - top5-acc: 0.9940 - val_loss: 0.7317 - val_acc: 0.7760 - val_top5-acc: 0.9848 - lr: 0.0025\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4693 - acc: 0.8339 - top5-acc: 0.9945 - val_loss: 0.7275 - val_acc: 0.7734 - val_top5-acc: 0.9850 - lr: 0.0025\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4629 - acc: 0.8368 - top5-acc: 0.9945 - val_loss: 0.7364 - val_acc: 0.7652 - val_top5-acc: 0.9854 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4667 - acc: 0.8348 - top5-acc: 0.9947 - val_loss: 0.7394 - val_acc: 0.7700 - val_top5-acc: 0.9862 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4613 - acc: 0.8356 - top5-acc: 0.9946 - val_loss: 0.7384 - val_acc: 0.7752 - val_top5-acc: 0.9858 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4652 - acc: 0.8341 - top5-acc: 0.9942 - val_loss: 0.7260 - val_acc: 0.7726 - val_top5-acc: 0.9862 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4653 - acc: 0.8353 - top5-acc: 0.9946 - val_loss: 0.7276 - val_acc: 0.7714 - val_top5-acc: 0.9864 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4680 - acc: 0.8348 - top5-acc: 0.9948 - val_loss: 0.7289 - val_acc: 0.7690 - val_top5-acc: 0.9868 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4624 - acc: 0.8342 - top5-acc: 0.9945 - val_loss: 0.7379 - val_acc: 0.7738 - val_top5-acc: 0.9870 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4690 - acc: 0.8330 - top5-acc: 0.9940 - val_loss: 0.7495 - val_acc: 0.7700 - val_top5-acc: 0.9864 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4658 - acc: 0.8341 - top5-acc: 0.9939 - val_loss: 0.7290 - val_acc: 0.7712 - val_top5-acc: 0.9866 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4610 - acc: 0.8364 - top5-acc: 0.9942 - val_loss: 0.7286 - val_acc: 0.7730 - val_top5-acc: 0.9850 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4565 - acc: 0.8401 - top5-acc: 0.9946 - val_loss: 0.7213 - val_acc: 0.7730 - val_top5-acc: 0.9856 - lr: 0.0012\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4550 - acc: 0.8387 - top5-acc: 0.9948 - val_loss: 0.7262 - val_acc: 0.7708 - val_top5-acc: 0.9854 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4552 - acc: 0.8373 - top5-acc: 0.9945 - val_loss: 0.7248 - val_acc: 0.7726 - val_top5-acc: 0.9844 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4569 - acc: 0.8381 - top5-acc: 0.9948 - val_loss: 0.7211 - val_acc: 0.7730 - val_top5-acc: 0.9850 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4521 - acc: 0.8400 - top5-acc: 0.9953 - val_loss: 0.7246 - val_acc: 0.7692 - val_top5-acc: 0.9856 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4579 - acc: 0.8371 - top5-acc: 0.9945 - val_loss: 0.7199 - val_acc: 0.7742 - val_top5-acc: 0.9862 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4520 - acc: 0.8398 - top5-acc: 0.9942 - val_loss: 0.7233 - val_acc: 0.7718 - val_top5-acc: 0.9858 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4557 - acc: 0.8395 - top5-acc: 0.9952 - val_loss: 0.7211 - val_acc: 0.7730 - val_top5-acc: 0.9856 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4556 - acc: 0.8385 - top5-acc: 0.9944 - val_loss: 0.7212 - val_acc: 0.7702 - val_top5-acc: 0.9866 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4572 - acc: 0.8379 - top5-acc: 0.9943 - val_loss: 0.7179 - val_acc: 0.7684 - val_top5-acc: 0.9860 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4620 - acc: 0.8354 - top5-acc: 0.9949 - val_loss: 0.7203 - val_acc: 0.7706 - val_top5-acc: 0.9858 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4602 - acc: 0.8387 - top5-acc: 0.9943 - val_loss: 0.7177 - val_acc: 0.7734 - val_top5-acc: 0.9854 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4567 - acc: 0.8366 - top5-acc: 0.9946 - val_loss: 0.7231 - val_acc: 0.7734 - val_top5-acc: 0.9858 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4560 - acc: 0.8387 - top5-acc: 0.9944 - val_loss: 0.7174 - val_acc: 0.7728 - val_top5-acc: 0.9858 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4560 - acc: 0.8383 - top5-acc: 0.9946 - val_loss: 0.7242 - val_acc: 0.7730 - val_top5-acc: 0.9852 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4529 - acc: 0.8378 - top5-acc: 0.9950 - val_loss: 0.7181 - val_acc: 0.7756 - val_top5-acc: 0.9854 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4529 - acc: 0.8394 - top5-acc: 0.9946 - val_loss: 0.7291 - val_acc: 0.7702 - val_top5-acc: 0.9850 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4596 - acc: 0.8367 - top5-acc: 0.9947 - val_loss: 0.7156 - val_acc: 0.7724 - val_top5-acc: 0.9858 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 0.4548 - acc: 0.8399 - top5-acc: 0.9948 - val_loss: 0.7210 - val_acc: 0.7724 - val_top5-acc: 0.9856 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 0.4614 - acc: 0.8371 - top5-acc: 0.9939 - val_loss: 0.7205 - val_acc: 0.7714 - val_top5-acc: 0.9852 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 10s 119ms/step - loss: 0.4594 - acc: 0.8363 - top5-acc: 0.9944 - val_loss: 0.7226 - val_acc: 0.7718 - val_top5-acc: 0.9862 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4531 - acc: 0.8401 - top5-acc: 0.9943 - val_loss: 0.7250 - val_acc: 0.7706 - val_top5-acc: 0.9856 - lr: 0.0012\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4555 - acc: 0.8391 - top5-acc: 0.9945 - val_loss: 0.7196 - val_acc: 0.7730 - val_top5-acc: 0.9856 - lr: 0.0012\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4557 - acc: 0.8370 - top5-acc: 0.9948 - val_loss: 0.7184 - val_acc: 0.7716 - val_top5-acc: 0.9856 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4519 - acc: 0.8398 - top5-acc: 0.9947 - val_loss: 0.7165 - val_acc: 0.7704 - val_top5-acc: 0.9860 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 0.4488 - acc: 0.8416 - top5-acc: 0.9950 - val_loss: 0.7205 - val_acc: 0.7728 - val_top5-acc: 0.9856 - lr: 6.2500e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 10s 117ms/step - loss: 0.4556 - acc: 0.8384 - top5-acc: 0.9952 - val_loss: 0.7119 - val_acc: 0.7732 - val_top5-acc: 0.9862 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 16s 52ms/step - loss: 0.7361 - acc: 0.7691 - top5-acc: 0.9852\n",
      "Test accuracy: 76.91%\n",
      "Test top 5 accuracy: 98.52%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.5138 - acc: 0.2442 - top5-acc: 0.7604WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 3s 27ms/step - loss: 2.5083 - acc: 0.2446 - top5-acc: 0.7613 - val_loss: 2.0051 - val_acc: 0.2868 - val_top5-acc: 0.8038 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.9772 - acc: 0.2936 - top5-acc: 0.8172 - val_loss: 1.8877 - val_acc: 0.3292 - val_top5-acc: 0.8308 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.9406 - acc: 0.3094 - top5-acc: 0.8308 - val_loss: 1.8801 - val_acc: 0.3226 - val_top5-acc: 0.8420 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.9111 - acc: 0.3184 - top5-acc: 0.8380 - val_loss: 1.8539 - val_acc: 0.3428 - val_top5-acc: 0.8446 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8989 - acc: 0.3282 - top5-acc: 0.8400 - val_loss: 1.8091 - val_acc: 0.3590 - val_top5-acc: 0.8462 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8820 - acc: 0.3314 - top5-acc: 0.8452 - val_loss: 1.8606 - val_acc: 0.3412 - val_top5-acc: 0.8450 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8970 - acc: 0.3317 - top5-acc: 0.8477 - val_loss: 1.8160 - val_acc: 0.3442 - val_top5-acc: 0.8752 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8482 - acc: 0.3451 - top5-acc: 0.8555 - val_loss: 1.8759 - val_acc: 0.3558 - val_top5-acc: 0.8604 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8448 - acc: 0.3470 - top5-acc: 0.8541 - val_loss: 1.7272 - val_acc: 0.3904 - val_top5-acc: 0.8710 - lr: 0.0050\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8296 - acc: 0.3524 - top5-acc: 0.8558 - val_loss: 1.8290 - val_acc: 0.3408 - val_top5-acc: 0.8548 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8460 - acc: 0.3476 - top5-acc: 0.8561 - val_loss: 1.7898 - val_acc: 0.3492 - val_top5-acc: 0.8728 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8100 - acc: 0.3562 - top5-acc: 0.8605 - val_loss: 1.7583 - val_acc: 0.3656 - val_top5-acc: 0.8660 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8167 - acc: 0.3560 - top5-acc: 0.8636 - val_loss: 1.8443 - val_acc: 0.3554 - val_top5-acc: 0.8678 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.8185 - acc: 0.3576 - top5-acc: 0.8624 - val_loss: 1.7591 - val_acc: 0.3762 - val_top5-acc: 0.8762 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7328 - acc: 0.3774 - top5-acc: 0.8716 - val_loss: 1.6948 - val_acc: 0.3894 - val_top5-acc: 0.8792 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7316 - acc: 0.3764 - top5-acc: 0.8742 - val_loss: 1.6948 - val_acc: 0.4010 - val_top5-acc: 0.8846 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7424 - acc: 0.3742 - top5-acc: 0.8726 - val_loss: 1.6656 - val_acc: 0.4008 - val_top5-acc: 0.8812 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7176 - acc: 0.3807 - top5-acc: 0.8750 - val_loss: 1.6563 - val_acc: 0.4022 - val_top5-acc: 0.8850 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.7283 - acc: 0.3771 - top5-acc: 0.8742 - val_loss: 1.6776 - val_acc: 0.3992 - val_top5-acc: 0.8820 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7213 - acc: 0.3786 - top5-acc: 0.8736 - val_loss: 1.6587 - val_acc: 0.4040 - val_top5-acc: 0.8848 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7252 - acc: 0.3814 - top5-acc: 0.8738 - val_loss: 1.6715 - val_acc: 0.3966 - val_top5-acc: 0.8900 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7273 - acc: 0.3803 - top5-acc: 0.8732 - val_loss: 1.6595 - val_acc: 0.3980 - val_top5-acc: 0.8810 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.7291 - acc: 0.3760 - top5-acc: 0.8764 - val_loss: 1.6880 - val_acc: 0.3956 - val_top5-acc: 0.8828 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6868 - acc: 0.3884 - top5-acc: 0.8821 - val_loss: 1.6270 - val_acc: 0.4238 - val_top5-acc: 0.8902 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6793 - acc: 0.3964 - top5-acc: 0.8795 - val_loss: 1.6542 - val_acc: 0.4084 - val_top5-acc: 0.8826 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6800 - acc: 0.3935 - top5-acc: 0.8822 - val_loss: 1.6307 - val_acc: 0.4066 - val_top5-acc: 0.8866 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6889 - acc: 0.3894 - top5-acc: 0.8812 - val_loss: 1.6325 - val_acc: 0.4206 - val_top5-acc: 0.8862 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6828 - acc: 0.3929 - top5-acc: 0.8824 - val_loss: 1.6216 - val_acc: 0.4144 - val_top5-acc: 0.8940 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6842 - acc: 0.3937 - top5-acc: 0.8811 - val_loss: 1.6323 - val_acc: 0.4050 - val_top5-acc: 0.8902 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6808 - acc: 0.3963 - top5-acc: 0.8830 - val_loss: 1.6381 - val_acc: 0.4142 - val_top5-acc: 0.8878 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6896 - acc: 0.3921 - top5-acc: 0.8810 - val_loss: 1.6637 - val_acc: 0.4014 - val_top5-acc: 0.8864 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6869 - acc: 0.3921 - top5-acc: 0.8815 - val_loss: 1.6462 - val_acc: 0.4026 - val_top5-acc: 0.8894 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6885 - acc: 0.3896 - top5-acc: 0.8801 - val_loss: 1.6418 - val_acc: 0.4026 - val_top5-acc: 0.8916 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6642 - acc: 0.3996 - top5-acc: 0.8846 - val_loss: 1.6170 - val_acc: 0.4160 - val_top5-acc: 0.8932 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6602 - acc: 0.4036 - top5-acc: 0.8859 - val_loss: 1.6187 - val_acc: 0.4160 - val_top5-acc: 0.8916 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6601 - acc: 0.4037 - top5-acc: 0.8848 - val_loss: 1.6277 - val_acc: 0.4098 - val_top5-acc: 0.8952 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6659 - acc: 0.4000 - top5-acc: 0.8847 - val_loss: 1.6137 - val_acc: 0.4216 - val_top5-acc: 0.8886 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6590 - acc: 0.4036 - top5-acc: 0.8840 - val_loss: 1.6181 - val_acc: 0.4260 - val_top5-acc: 0.8892 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6613 - acc: 0.4038 - top5-acc: 0.8837 - val_loss: 1.6139 - val_acc: 0.4216 - val_top5-acc: 0.8920 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6597 - acc: 0.4028 - top5-acc: 0.8865 - val_loss: 1.6108 - val_acc: 0.4194 - val_top5-acc: 0.8924 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6609 - acc: 0.4027 - top5-acc: 0.8844 - val_loss: 1.6308 - val_acc: 0.4130 - val_top5-acc: 0.8888 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6625 - acc: 0.4029 - top5-acc: 0.8858 - val_loss: 1.6149 - val_acc: 0.4144 - val_top5-acc: 0.8880 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6674 - acc: 0.4011 - top5-acc: 0.8841 - val_loss: 1.6211 - val_acc: 0.4148 - val_top5-acc: 0.8882 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6625 - acc: 0.4004 - top5-acc: 0.8848 - val_loss: 1.6185 - val_acc: 0.4146 - val_top5-acc: 0.8950 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6662 - acc: 0.4013 - top5-acc: 0.8842 - val_loss: 1.6157 - val_acc: 0.4192 - val_top5-acc: 0.8918 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6520 - acc: 0.4097 - top5-acc: 0.8863 - val_loss: 1.6081 - val_acc: 0.4256 - val_top5-acc: 0.8916 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6491 - acc: 0.4058 - top5-acc: 0.8855 - val_loss: 1.6133 - val_acc: 0.4236 - val_top5-acc: 0.8926 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 2s 25ms/step - loss: 1.6519 - acc: 0.4097 - top5-acc: 0.8869 - val_loss: 1.6103 - val_acc: 0.4202 - val_top5-acc: 0.8946 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6570 - acc: 0.4062 - top5-acc: 0.8869 - val_loss: 1.6281 - val_acc: 0.4196 - val_top5-acc: 0.8894 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 2s 24ms/step - loss: 1.6554 - acc: 0.4081 - top5-acc: 0.8867 - val_loss: 1.6149 - val_acc: 0.4210 - val_top5-acc: 0.8940 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 1.6241 - acc: 0.4279 - top5-acc: 0.8935\n",
      "Test accuracy: 42.79%\n",
      "Test top 5 accuracy: 89.35%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.3273 - acc: 0.2776 - top5-acc: 0.7932WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 4s 37ms/step - loss: 2.3223 - acc: 0.2782 - top5-acc: 0.7939 - val_loss: 1.7806 - val_acc: 0.3692 - val_top5-acc: 0.8672 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.8312 - acc: 0.3483 - top5-acc: 0.8618 - val_loss: 1.7309 - val_acc: 0.3806 - val_top5-acc: 0.8760 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.7633 - acc: 0.3709 - top5-acc: 0.8739 - val_loss: 1.7007 - val_acc: 0.4046 - val_top5-acc: 0.8866 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.7493 - acc: 0.3789 - top5-acc: 0.8769 - val_loss: 1.7405 - val_acc: 0.3704 - val_top5-acc: 0.8836 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.7355 - acc: 0.3828 - top5-acc: 0.8809 - val_loss: 1.7019 - val_acc: 0.3934 - val_top5-acc: 0.8884 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6952 - acc: 0.3968 - top5-acc: 0.8848 - val_loss: 1.6527 - val_acc: 0.4200 - val_top5-acc: 0.8998 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.7092 - acc: 0.3971 - top5-acc: 0.8851 - val_loss: 1.6823 - val_acc: 0.4042 - val_top5-acc: 0.8888 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6817 - acc: 0.4035 - top5-acc: 0.8893 - val_loss: 1.6161 - val_acc: 0.4250 - val_top5-acc: 0.8998 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6828 - acc: 0.4028 - top5-acc: 0.8882 - val_loss: 1.5906 - val_acc: 0.4330 - val_top5-acc: 0.9032 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6872 - acc: 0.4076 - top5-acc: 0.8894 - val_loss: 1.5847 - val_acc: 0.4372 - val_top5-acc: 0.8996 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6730 - acc: 0.4080 - top5-acc: 0.8916 - val_loss: 1.6292 - val_acc: 0.4114 - val_top5-acc: 0.9002 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6592 - acc: 0.4113 - top5-acc: 0.8902 - val_loss: 1.5941 - val_acc: 0.4346 - val_top5-acc: 0.9008 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6453 - acc: 0.4144 - top5-acc: 0.8953 - val_loss: 1.6001 - val_acc: 0.4216 - val_top5-acc: 0.9042 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6676 - acc: 0.4095 - top5-acc: 0.8918 - val_loss: 1.5366 - val_acc: 0.4408 - val_top5-acc: 0.9030 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6631 - acc: 0.4127 - top5-acc: 0.8945 - val_loss: 1.6092 - val_acc: 0.4214 - val_top5-acc: 0.8946 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6456 - acc: 0.4170 - top5-acc: 0.8957 - val_loss: 1.6387 - val_acc: 0.4328 - val_top5-acc: 0.8956 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6562 - acc: 0.4160 - top5-acc: 0.8951 - val_loss: 1.5605 - val_acc: 0.4396 - val_top5-acc: 0.9048 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6572 - acc: 0.4130 - top5-acc: 0.8952 - val_loss: 1.5762 - val_acc: 0.4492 - val_top5-acc: 0.9012 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.6373 - acc: 0.4192 - top5-acc: 0.8963 - val_loss: 1.5985 - val_acc: 0.4274 - val_top5-acc: 0.8936 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5820 - acc: 0.4326 - top5-acc: 0.9017 - val_loss: 1.5070 - val_acc: 0.4574 - val_top5-acc: 0.9126 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5616 - acc: 0.4405 - top5-acc: 0.9053 - val_loss: 1.4935 - val_acc: 0.4736 - val_top5-acc: 0.9100 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5613 - acc: 0.4373 - top5-acc: 0.9048 - val_loss: 1.5055 - val_acc: 0.4578 - val_top5-acc: 0.9138 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5683 - acc: 0.4372 - top5-acc: 0.9018 - val_loss: 1.4900 - val_acc: 0.4592 - val_top5-acc: 0.9140 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5634 - acc: 0.4370 - top5-acc: 0.9052 - val_loss: 1.5373 - val_acc: 0.4428 - val_top5-acc: 0.9070 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5826 - acc: 0.4324 - top5-acc: 0.9032 - val_loss: 1.4945 - val_acc: 0.4672 - val_top5-acc: 0.9122 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5614 - acc: 0.4397 - top5-acc: 0.9060 - val_loss: 1.5342 - val_acc: 0.4624 - val_top5-acc: 0.9006 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5679 - acc: 0.4381 - top5-acc: 0.9043 - val_loss: 1.5544 - val_acc: 0.4356 - val_top5-acc: 0.9028 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5692 - acc: 0.4336 - top5-acc: 0.9043 - val_loss: 1.4944 - val_acc: 0.4642 - val_top5-acc: 0.9104 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5363 - acc: 0.4487 - top5-acc: 0.9073 - val_loss: 1.4811 - val_acc: 0.4774 - val_top5-acc: 0.9120 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5339 - acc: 0.4497 - top5-acc: 0.9101 - val_loss: 1.4813 - val_acc: 0.4678 - val_top5-acc: 0.9142 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5329 - acc: 0.4489 - top5-acc: 0.9085 - val_loss: 1.4769 - val_acc: 0.4766 - val_top5-acc: 0.9170 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5367 - acc: 0.4499 - top5-acc: 0.9081 - val_loss: 1.4959 - val_acc: 0.4642 - val_top5-acc: 0.9090 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5323 - acc: 0.4488 - top5-acc: 0.9099 - val_loss: 1.4700 - val_acc: 0.4796 - val_top5-acc: 0.9164 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5357 - acc: 0.4493 - top5-acc: 0.9077 - val_loss: 1.4820 - val_acc: 0.4752 - val_top5-acc: 0.9138 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5339 - acc: 0.4494 - top5-acc: 0.9095 - val_loss: 1.4723 - val_acc: 0.4724 - val_top5-acc: 0.9140 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5357 - acc: 0.4474 - top5-acc: 0.9108 - val_loss: 1.4817 - val_acc: 0.4772 - val_top5-acc: 0.9136 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5317 - acc: 0.4495 - top5-acc: 0.9088 - val_loss: 1.4787 - val_acc: 0.4668 - val_top5-acc: 0.9140 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5433 - acc: 0.4466 - top5-acc: 0.9074 - val_loss: 1.4777 - val_acc: 0.4724 - val_top5-acc: 0.9152 - lr: 0.0012\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5192 - acc: 0.4549 - top5-acc: 0.9099 - val_loss: 1.4706 - val_acc: 0.4766 - val_top5-acc: 0.9136 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5180 - acc: 0.4566 - top5-acc: 0.9111 - val_loss: 1.4643 - val_acc: 0.4740 - val_top5-acc: 0.9150 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5141 - acc: 0.4570 - top5-acc: 0.9109 - val_loss: 1.4578 - val_acc: 0.4836 - val_top5-acc: 0.9192 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5195 - acc: 0.4561 - top5-acc: 0.9102 - val_loss: 1.4643 - val_acc: 0.4740 - val_top5-acc: 0.9120 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5179 - acc: 0.4564 - top5-acc: 0.9114 - val_loss: 1.4653 - val_acc: 0.4764 - val_top5-acc: 0.9148 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5161 - acc: 0.4556 - top5-acc: 0.9114 - val_loss: 1.4675 - val_acc: 0.4836 - val_top5-acc: 0.9176 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5192 - acc: 0.4543 - top5-acc: 0.9110 - val_loss: 1.4677 - val_acc: 0.4772 - val_top5-acc: 0.9144 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5227 - acc: 0.4528 - top5-acc: 0.9098 - val_loss: 1.4768 - val_acc: 0.4724 - val_top5-acc: 0.9156 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5142 - acc: 0.4568 - top5-acc: 0.9117 - val_loss: 1.4605 - val_acc: 0.4876 - val_top5-acc: 0.9146 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5106 - acc: 0.4586 - top5-acc: 0.9106 - val_loss: 1.4610 - val_acc: 0.4826 - val_top5-acc: 0.9172 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5117 - acc: 0.4587 - top5-acc: 0.9119 - val_loss: 1.4662 - val_acc: 0.4808 - val_top5-acc: 0.9132 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 3s 33ms/step - loss: 1.5128 - acc: 0.4595 - top5-acc: 0.9116 - val_loss: 1.4627 - val_acc: 0.4838 - val_top5-acc: 0.9166 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 1.4811 - acc: 0.4752 - top5-acc: 0.9190\n",
      "Test accuracy: 47.52%\n",
      "Test top 5 accuracy: 91.9%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.2432 - acc: 0.2949 - top5-acc: 0.8047WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 5s 45ms/step - loss: 2.2407 - acc: 0.2952 - top5-acc: 0.8050 - val_loss: 1.7429 - val_acc: 0.3776 - val_top5-acc: 0.8792 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.7439 - acc: 0.3731 - top5-acc: 0.8785 - val_loss: 1.6303 - val_acc: 0.4150 - val_top5-acc: 0.8956 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6932 - acc: 0.3935 - top5-acc: 0.8884 - val_loss: 1.6032 - val_acc: 0.4158 - val_top5-acc: 0.9024 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6720 - acc: 0.4062 - top5-acc: 0.8912 - val_loss: 1.5862 - val_acc: 0.4370 - val_top5-acc: 0.8966 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6462 - acc: 0.4117 - top5-acc: 0.8950 - val_loss: 1.6035 - val_acc: 0.4230 - val_top5-acc: 0.9050 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6302 - acc: 0.4218 - top5-acc: 0.8969 - val_loss: 1.5353 - val_acc: 0.4528 - val_top5-acc: 0.9080 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6209 - acc: 0.4227 - top5-acc: 0.9000 - val_loss: 1.5571 - val_acc: 0.4398 - val_top5-acc: 0.9090 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6243 - acc: 0.4189 - top5-acc: 0.9015 - val_loss: 1.5491 - val_acc: 0.4476 - val_top5-acc: 0.9124 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6121 - acc: 0.4287 - top5-acc: 0.9036 - val_loss: 1.4962 - val_acc: 0.4670 - val_top5-acc: 0.9126 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 4s 40ms/step - loss: 1.6131 - acc: 0.4296 - top5-acc: 0.9016 - val_loss: 1.5253 - val_acc: 0.4546 - val_top5-acc: 0.9084 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5950 - acc: 0.4327 - top5-acc: 0.9040 - val_loss: 1.5542 - val_acc: 0.4514 - val_top5-acc: 0.9086 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6034 - acc: 0.4340 - top5-acc: 0.9029 - val_loss: 1.5730 - val_acc: 0.4440 - val_top5-acc: 0.9134 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5919 - acc: 0.4340 - top5-acc: 0.9052 - val_loss: 1.5596 - val_acc: 0.4474 - val_top5-acc: 0.9116 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.6076 - acc: 0.4319 - top5-acc: 0.9059 - val_loss: 1.5328 - val_acc: 0.4548 - val_top5-acc: 0.9078 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5317 - acc: 0.4541 - top5-acc: 0.9127 - val_loss: 1.4352 - val_acc: 0.4854 - val_top5-acc: 0.9236 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5173 - acc: 0.4555 - top5-acc: 0.9142 - val_loss: 1.4651 - val_acc: 0.4774 - val_top5-acc: 0.9186 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5103 - acc: 0.4609 - top5-acc: 0.9118 - val_loss: 1.4600 - val_acc: 0.4718 - val_top5-acc: 0.9218 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5125 - acc: 0.4592 - top5-acc: 0.9144 - val_loss: 1.4858 - val_acc: 0.4636 - val_top5-acc: 0.9186 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5136 - acc: 0.4578 - top5-acc: 0.9132 - val_loss: 1.4625 - val_acc: 0.4718 - val_top5-acc: 0.9184 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5122 - acc: 0.4585 - top5-acc: 0.9144 - val_loss: 1.4287 - val_acc: 0.4862 - val_top5-acc: 0.9244 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5069 - acc: 0.4579 - top5-acc: 0.9140 - val_loss: 1.4589 - val_acc: 0.4734 - val_top5-acc: 0.9208 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5180 - acc: 0.4558 - top5-acc: 0.9121 - val_loss: 1.4568 - val_acc: 0.4792 - val_top5-acc: 0.9198 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5135 - acc: 0.4600 - top5-acc: 0.9140 - val_loss: 1.4514 - val_acc: 0.4770 - val_top5-acc: 0.9204 - lr: 0.0025\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5284 - acc: 0.4531 - top5-acc: 0.9131 - val_loss: 1.4527 - val_acc: 0.4788 - val_top5-acc: 0.9206 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.5142 - acc: 0.4581 - top5-acc: 0.9134 - val_loss: 1.4616 - val_acc: 0.4842 - val_top5-acc: 0.9210 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4868 - acc: 0.4680 - top5-acc: 0.9155 - val_loss: 1.4125 - val_acc: 0.4920 - val_top5-acc: 0.9266 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4823 - acc: 0.4682 - top5-acc: 0.9169 - val_loss: 1.4123 - val_acc: 0.4936 - val_top5-acc: 0.9228 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4782 - acc: 0.4691 - top5-acc: 0.9171 - val_loss: 1.4193 - val_acc: 0.4874 - val_top5-acc: 0.9246 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4790 - acc: 0.4680 - top5-acc: 0.9194 - val_loss: 1.4195 - val_acc: 0.4842 - val_top5-acc: 0.9268 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4792 - acc: 0.4694 - top5-acc: 0.9175 - val_loss: 1.4318 - val_acc: 0.4874 - val_top5-acc: 0.9200 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4803 - acc: 0.4724 - top5-acc: 0.9172 - val_loss: 1.4260 - val_acc: 0.4830 - val_top5-acc: 0.9234 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4824 - acc: 0.4694 - top5-acc: 0.9172 - val_loss: 1.4283 - val_acc: 0.4892 - val_top5-acc: 0.9250 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4723 - acc: 0.4727 - top5-acc: 0.9179 - val_loss: 1.4052 - val_acc: 0.4982 - val_top5-acc: 0.9268 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4647 - acc: 0.4763 - top5-acc: 0.9193 - val_loss: 1.4072 - val_acc: 0.4956 - val_top5-acc: 0.9268 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4681 - acc: 0.4760 - top5-acc: 0.9192 - val_loss: 1.4094 - val_acc: 0.4992 - val_top5-acc: 0.9252 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4677 - acc: 0.4740 - top5-acc: 0.9185 - val_loss: 1.4088 - val_acc: 0.4994 - val_top5-acc: 0.9244 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4648 - acc: 0.4760 - top5-acc: 0.9206 - val_loss: 1.4186 - val_acc: 0.4916 - val_top5-acc: 0.9230 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4669 - acc: 0.4747 - top5-acc: 0.9188 - val_loss: 1.4139 - val_acc: 0.4958 - val_top5-acc: 0.9258 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4578 - acc: 0.4798 - top5-acc: 0.9206 - val_loss: 1.4061 - val_acc: 0.4940 - val_top5-acc: 0.9260 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4639 - acc: 0.4781 - top5-acc: 0.9194 - val_loss: 1.4109 - val_acc: 0.4896 - val_top5-acc: 0.9254 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4611 - acc: 0.4780 - top5-acc: 0.9193 - val_loss: 1.4058 - val_acc: 0.5006 - val_top5-acc: 0.9258 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4569 - acc: 0.4816 - top5-acc: 0.9197 - val_loss: 1.4115 - val_acc: 0.4896 - val_top5-acc: 0.9266 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4609 - acc: 0.4803 - top5-acc: 0.9198 - val_loss: 1.4084 - val_acc: 0.4958 - val_top5-acc: 0.9254 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4557 - acc: 0.4833 - top5-acc: 0.9210 - val_loss: 1.4029 - val_acc: 0.4978 - val_top5-acc: 0.9252 - lr: 1.5625e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4594 - acc: 0.4809 - top5-acc: 0.9203 - val_loss: 1.4077 - val_acc: 0.4952 - val_top5-acc: 0.9252 - lr: 1.5625e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4574 - acc: 0.4803 - top5-acc: 0.9194 - val_loss: 1.4055 - val_acc: 0.4994 - val_top5-acc: 0.9256 - lr: 1.5625e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4555 - acc: 0.4807 - top5-acc: 0.9202 - val_loss: 1.4108 - val_acc: 0.4924 - val_top5-acc: 0.9252 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4560 - acc: 0.4799 - top5-acc: 0.9204 - val_loss: 1.4062 - val_acc: 0.4990 - val_top5-acc: 0.9236 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4610 - acc: 0.4798 - top5-acc: 0.9191 - val_loss: 1.4063 - val_acc: 0.5010 - val_top5-acc: 0.9244 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 4s 41ms/step - loss: 1.4590 - acc: 0.4798 - top5-acc: 0.9206 - val_loss: 1.4080 - val_acc: 0.4990 - val_top5-acc: 0.9234 - lr: 7.8125e-05\n",
      "313/313 [==============================] - 4s 13ms/step - loss: 1.4214 - acc: 0.5037 - top5-acc: 0.9233\n",
      "Test accuracy: 50.37%\n",
      "Test top 5 accuracy: 92.33%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "87/88 [============================>.] - ETA: 0s - loss: 2.1007 - acc: 0.3156 - top5-acc: 0.8261WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 6s 54ms/step - loss: 2.0968 - acc: 0.3162 - top5-acc: 0.8267 - val_loss: 1.6767 - val_acc: 0.3950 - val_top5-acc: 0.8902 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.6894 - acc: 0.3940 - top5-acc: 0.8898 - val_loss: 1.5400 - val_acc: 0.4508 - val_top5-acc: 0.9074 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.6313 - acc: 0.4130 - top5-acc: 0.8981 - val_loss: 1.5494 - val_acc: 0.4522 - val_top5-acc: 0.9086 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.6130 - acc: 0.4244 - top5-acc: 0.9014 - val_loss: 1.4987 - val_acc: 0.4596 - val_top5-acc: 0.9154 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5891 - acc: 0.4300 - top5-acc: 0.9060 - val_loss: 1.5229 - val_acc: 0.4616 - val_top5-acc: 0.9154 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5909 - acc: 0.4332 - top5-acc: 0.9064 - val_loss: 1.4739 - val_acc: 0.4748 - val_top5-acc: 0.9210 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5697 - acc: 0.4402 - top5-acc: 0.9075 - val_loss: 1.5076 - val_acc: 0.4628 - val_top5-acc: 0.9146 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5498 - acc: 0.4460 - top5-acc: 0.9116 - val_loss: 1.4738 - val_acc: 0.4746 - val_top5-acc: 0.9188 - lr: 0.0050\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5540 - acc: 0.4499 - top5-acc: 0.9105 - val_loss: 1.5084 - val_acc: 0.4638 - val_top5-acc: 0.9186 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5710 - acc: 0.4436 - top5-acc: 0.9095 - val_loss: 1.4738 - val_acc: 0.4742 - val_top5-acc: 0.9232 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5369 - acc: 0.4543 - top5-acc: 0.9135 - val_loss: 1.4648 - val_acc: 0.4732 - val_top5-acc: 0.9230 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5487 - acc: 0.4500 - top5-acc: 0.9136 - val_loss: 1.4837 - val_acc: 0.4740 - val_top5-acc: 0.9206 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5463 - acc: 0.4521 - top5-acc: 0.9139 - val_loss: 1.4890 - val_acc: 0.4756 - val_top5-acc: 0.9188 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5274 - acc: 0.4557 - top5-acc: 0.9156 - val_loss: 1.4312 - val_acc: 0.4846 - val_top5-acc: 0.9268 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5308 - acc: 0.4545 - top5-acc: 0.9156 - val_loss: 1.4491 - val_acc: 0.4732 - val_top5-acc: 0.9246 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5279 - acc: 0.4576 - top5-acc: 0.9154 - val_loss: 1.4506 - val_acc: 0.4768 - val_top5-acc: 0.9248 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5344 - acc: 0.4538 - top5-acc: 0.9155 - val_loss: 1.4631 - val_acc: 0.4766 - val_top5-acc: 0.9210 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5113 - acc: 0.4606 - top5-acc: 0.9166 - val_loss: 1.4316 - val_acc: 0.4866 - val_top5-acc: 0.9290 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.5183 - acc: 0.4607 - top5-acc: 0.9183 - val_loss: 1.4419 - val_acc: 0.4844 - val_top5-acc: 0.9234 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4656 - acc: 0.4743 - top5-acc: 0.9212 - val_loss: 1.4054 - val_acc: 0.4986 - val_top5-acc: 0.9276 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4644 - acc: 0.4770 - top5-acc: 0.9219 - val_loss: 1.4016 - val_acc: 0.4968 - val_top5-acc: 0.9294 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4579 - acc: 0.4775 - top5-acc: 0.9223 - val_loss: 1.3991 - val_acc: 0.4992 - val_top5-acc: 0.9328 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4582 - acc: 0.4767 - top5-acc: 0.9215 - val_loss: 1.3796 - val_acc: 0.5022 - val_top5-acc: 0.9316 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4612 - acc: 0.4778 - top5-acc: 0.9209 - val_loss: 1.3651 - val_acc: 0.5130 - val_top5-acc: 0.9346 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4543 - acc: 0.4793 - top5-acc: 0.9235 - val_loss: 1.4092 - val_acc: 0.4810 - val_top5-acc: 0.9296 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4600 - acc: 0.4750 - top5-acc: 0.9212 - val_loss: 1.4022 - val_acc: 0.4934 - val_top5-acc: 0.9290 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4592 - acc: 0.4792 - top5-acc: 0.9204 - val_loss: 1.4041 - val_acc: 0.4868 - val_top5-acc: 0.9320 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4509 - acc: 0.4819 - top5-acc: 0.9246 - val_loss: 1.3882 - val_acc: 0.5024 - val_top5-acc: 0.9290 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4563 - acc: 0.4762 - top5-acc: 0.9243 - val_loss: 1.3836 - val_acc: 0.4992 - val_top5-acc: 0.9306 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4307 - acc: 0.4854 - top5-acc: 0.9250 - val_loss: 1.3726 - val_acc: 0.5100 - val_top5-acc: 0.9312 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4294 - acc: 0.4888 - top5-acc: 0.9266 - val_loss: 1.3536 - val_acc: 0.5140 - val_top5-acc: 0.9354 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4262 - acc: 0.4920 - top5-acc: 0.9246 - val_loss: 1.3594 - val_acc: 0.5108 - val_top5-acc: 0.9334 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4280 - acc: 0.4914 - top5-acc: 0.9242 - val_loss: 1.3597 - val_acc: 0.5150 - val_top5-acc: 0.9346 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4323 - acc: 0.4877 - top5-acc: 0.9248 - val_loss: 1.3607 - val_acc: 0.5096 - val_top5-acc: 0.9338 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4287 - acc: 0.4922 - top5-acc: 0.9244 - val_loss: 1.3615 - val_acc: 0.5060 - val_top5-acc: 0.9348 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4320 - acc: 0.4865 - top5-acc: 0.9260 - val_loss: 1.3833 - val_acc: 0.5026 - val_top5-acc: 0.9324 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4149 - acc: 0.4931 - top5-acc: 0.9274 - val_loss: 1.3579 - val_acc: 0.5048 - val_top5-acc: 0.9334 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4182 - acc: 0.4942 - top5-acc: 0.9267 - val_loss: 1.3562 - val_acc: 0.5116 - val_top5-acc: 0.9324 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4197 - acc: 0.4928 - top5-acc: 0.9269 - val_loss: 1.3472 - val_acc: 0.5190 - val_top5-acc: 0.9328 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4220 - acc: 0.4916 - top5-acc: 0.9264 - val_loss: 1.3719 - val_acc: 0.4986 - val_top5-acc: 0.9352 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4212 - acc: 0.4922 - top5-acc: 0.9266 - val_loss: 1.3462 - val_acc: 0.5204 - val_top5-acc: 0.9332 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4184 - acc: 0.4940 - top5-acc: 0.9262 - val_loss: 1.3491 - val_acc: 0.5154 - val_top5-acc: 0.9332 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4174 - acc: 0.4963 - top5-acc: 0.9271 - val_loss: 1.3594 - val_acc: 0.5096 - val_top5-acc: 0.9324 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4219 - acc: 0.4925 - top5-acc: 0.9262 - val_loss: 1.3556 - val_acc: 0.5186 - val_top5-acc: 0.9356 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4169 - acc: 0.4940 - top5-acc: 0.9255 - val_loss: 1.3505 - val_acc: 0.5190 - val_top5-acc: 0.9346 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4206 - acc: 0.4947 - top5-acc: 0.9242 - val_loss: 1.3547 - val_acc: 0.5170 - val_top5-acc: 0.9334 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4166 - acc: 0.4960 - top5-acc: 0.9261 - val_loss: 1.3495 - val_acc: 0.5172 - val_top5-acc: 0.9324 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4161 - acc: 0.4956 - top5-acc: 0.9257 - val_loss: 1.3522 - val_acc: 0.5158 - val_top5-acc: 0.9350 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4113 - acc: 0.4972 - top5-acc: 0.9279 - val_loss: 1.3533 - val_acc: 0.5172 - val_top5-acc: 0.9344 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 4s 49ms/step - loss: 1.4108 - acc: 0.4968 - top5-acc: 0.9263 - val_loss: 1.3479 - val_acc: 0.5196 - val_top5-acc: 0.9348 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 1.3666 - acc: 0.5128 - top5-acc: 0.9342\n",
      "Test accuracy: 51.28%\n",
      "Test top 5 accuracy: 93.42%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.0799 - acc: 0.3185 - top5-acc: 0.8305WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 7s 63ms/step - loss: 2.0799 - acc: 0.3185 - top5-acc: 0.8305 - val_loss: 1.6241 - val_acc: 0.4102 - val_top5-acc: 0.9016 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.6660 - acc: 0.4009 - top5-acc: 0.8931 - val_loss: 1.5392 - val_acc: 0.4502 - val_top5-acc: 0.9124 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.6032 - acc: 0.4250 - top5-acc: 0.9004 - val_loss: 1.5136 - val_acc: 0.4558 - val_top5-acc: 0.9110 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5722 - acc: 0.4403 - top5-acc: 0.9064 - val_loss: 1.5337 - val_acc: 0.4534 - val_top5-acc: 0.9144 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5712 - acc: 0.4377 - top5-acc: 0.9070 - val_loss: 1.5246 - val_acc: 0.4502 - val_top5-acc: 0.9154 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.5574 - acc: 0.4444 - top5-acc: 0.9094 - val_loss: 1.4894 - val_acc: 0.4706 - val_top5-acc: 0.9204 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5563 - acc: 0.4471 - top5-acc: 0.9111 - val_loss: 1.4457 - val_acc: 0.4824 - val_top5-acc: 0.9228 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5400 - acc: 0.4539 - top5-acc: 0.9118 - val_loss: 1.4562 - val_acc: 0.4730 - val_top5-acc: 0.9258 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5246 - acc: 0.4576 - top5-acc: 0.9144 - val_loss: 1.4665 - val_acc: 0.4778 - val_top5-acc: 0.9222 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5309 - acc: 0.4558 - top5-acc: 0.9142 - val_loss: 1.4077 - val_acc: 0.4984 - val_top5-acc: 0.9310 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5525 - acc: 0.4532 - top5-acc: 0.9123 - val_loss: 1.4554 - val_acc: 0.4726 - val_top5-acc: 0.9264 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5220 - acc: 0.4607 - top5-acc: 0.9148 - val_loss: 1.4483 - val_acc: 0.4854 - val_top5-acc: 0.9272 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.5091 - acc: 0.4651 - top5-acc: 0.9167 - val_loss: 1.4125 - val_acc: 0.4934 - val_top5-acc: 0.9280 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4985 - acc: 0.4662 - top5-acc: 0.9165 - val_loss: 1.4839 - val_acc: 0.4768 - val_top5-acc: 0.9228 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4983 - acc: 0.4712 - top5-acc: 0.9192 - val_loss: 1.4274 - val_acc: 0.4936 - val_top5-acc: 0.9278 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4563 - acc: 0.4799 - top5-acc: 0.9222 - val_loss: 1.3809 - val_acc: 0.5082 - val_top5-acc: 0.9328 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4458 - acc: 0.4815 - top5-acc: 0.9253 - val_loss: 1.3655 - val_acc: 0.5150 - val_top5-acc: 0.9328 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4518 - acc: 0.4821 - top5-acc: 0.9221 - val_loss: 1.3739 - val_acc: 0.5086 - val_top5-acc: 0.9320 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4498 - acc: 0.4836 - top5-acc: 0.9241 - val_loss: 1.3620 - val_acc: 0.5210 - val_top5-acc: 0.9362 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4476 - acc: 0.4825 - top5-acc: 0.9245 - val_loss: 1.3667 - val_acc: 0.5104 - val_top5-acc: 0.9292 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4485 - acc: 0.4840 - top5-acc: 0.9244 - val_loss: 1.3779 - val_acc: 0.5096 - val_top5-acc: 0.9328 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4412 - acc: 0.4837 - top5-acc: 0.9230 - val_loss: 1.3658 - val_acc: 0.5196 - val_top5-acc: 0.9338 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4506 - acc: 0.4839 - top5-acc: 0.9229 - val_loss: 1.3851 - val_acc: 0.5034 - val_top5-acc: 0.9340 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4442 - acc: 0.4841 - top5-acc: 0.9249 - val_loss: 1.3772 - val_acc: 0.5080 - val_top5-acc: 0.9374 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4235 - acc: 0.4941 - top5-acc: 0.9248 - val_loss: 1.3706 - val_acc: 0.5168 - val_top5-acc: 0.9358 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4240 - acc: 0.4901 - top5-acc: 0.9261 - val_loss: 1.3503 - val_acc: 0.5178 - val_top5-acc: 0.9340 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4187 - acc: 0.4942 - top5-acc: 0.9260 - val_loss: 1.3464 - val_acc: 0.5238 - val_top5-acc: 0.9366 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4191 - acc: 0.4950 - top5-acc: 0.9269 - val_loss: 1.3532 - val_acc: 0.5184 - val_top5-acc: 0.9354 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4172 - acc: 0.4952 - top5-acc: 0.9269 - val_loss: 1.3479 - val_acc: 0.5198 - val_top5-acc: 0.9358 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4191 - acc: 0.4940 - top5-acc: 0.9272 - val_loss: 1.3533 - val_acc: 0.5238 - val_top5-acc: 0.9334 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4216 - acc: 0.4935 - top5-acc: 0.9252 - val_loss: 1.3609 - val_acc: 0.5108 - val_top5-acc: 0.9340 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4193 - acc: 0.4957 - top5-acc: 0.9263 - val_loss: 1.3416 - val_acc: 0.5228 - val_top5-acc: 0.9364 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4202 - acc: 0.4942 - top5-acc: 0.9253 - val_loss: 1.3565 - val_acc: 0.5132 - val_top5-acc: 0.9348 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4147 - acc: 0.4965 - top5-acc: 0.9261 - val_loss: 1.3596 - val_acc: 0.5132 - val_top5-acc: 0.9324 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4220 - acc: 0.4938 - top5-acc: 0.9268 - val_loss: 1.3687 - val_acc: 0.5136 - val_top5-acc: 0.9334 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4226 - acc: 0.4912 - top5-acc: 0.9273 - val_loss: 1.3686 - val_acc: 0.5094 - val_top5-acc: 0.9354 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4187 - acc: 0.4942 - top5-acc: 0.9270 - val_loss: 1.3528 - val_acc: 0.5236 - val_top5-acc: 0.9350 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4085 - acc: 0.4981 - top5-acc: 0.9280 - val_loss: 1.3507 - val_acc: 0.5208 - val_top5-acc: 0.9360 - lr: 6.2500e-04\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4086 - acc: 0.4942 - top5-acc: 0.9301 - val_loss: 1.3458 - val_acc: 0.5178 - val_top5-acc: 0.9372 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4008 - acc: 0.5047 - top5-acc: 0.9275 - val_loss: 1.3529 - val_acc: 0.5178 - val_top5-acc: 0.9350 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4069 - acc: 0.4994 - top5-acc: 0.9265 - val_loss: 1.3394 - val_acc: 0.5268 - val_top5-acc: 0.9360 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4076 - acc: 0.4992 - top5-acc: 0.9286 - val_loss: 1.3442 - val_acc: 0.5236 - val_top5-acc: 0.9388 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.4085 - acc: 0.4989 - top5-acc: 0.9278 - val_loss: 1.3441 - val_acc: 0.5258 - val_top5-acc: 0.9368 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4065 - acc: 0.4987 - top5-acc: 0.9280 - val_loss: 1.3408 - val_acc: 0.5310 - val_top5-acc: 0.9356 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4071 - acc: 0.4977 - top5-acc: 0.9295 - val_loss: 1.3444 - val_acc: 0.5264 - val_top5-acc: 0.9350 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4076 - acc: 0.4989 - top5-acc: 0.9285 - val_loss: 1.3520 - val_acc: 0.5174 - val_top5-acc: 0.9410 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4001 - acc: 0.5032 - top5-acc: 0.9283 - val_loss: 1.3395 - val_acc: 0.5264 - val_top5-acc: 0.9364 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4048 - acc: 0.4992 - top5-acc: 0.9277 - val_loss: 1.3370 - val_acc: 0.5268 - val_top5-acc: 0.9368 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 5s 59ms/step - loss: 1.3978 - acc: 0.5040 - top5-acc: 0.9292 - val_loss: 1.3379 - val_acc: 0.5296 - val_top5-acc: 0.9380 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 5s 58ms/step - loss: 1.4016 - acc: 0.5037 - top5-acc: 0.9274 - val_loss: 1.3477 - val_acc: 0.5276 - val_top5-acc: 0.9368 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 1.3557 - acc: 0.5157 - top5-acc: 0.9345\n",
      "Test accuracy: 51.57%\n",
      "Test top 5 accuracy: 93.45%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.9963 - acc: 0.3320 - top5-acc: 0.8384WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 8s 70ms/step - loss: 1.9963 - acc: 0.3320 - top5-acc: 0.8384 - val_loss: 1.5929 - val_acc: 0.4276 - val_top5-acc: 0.9016 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.6375 - acc: 0.4128 - top5-acc: 0.8954 - val_loss: 1.5517 - val_acc: 0.4360 - val_top5-acc: 0.9092 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.6006 - acc: 0.4257 - top5-acc: 0.9028 - val_loss: 1.5053 - val_acc: 0.4630 - val_top5-acc: 0.9156 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5664 - acc: 0.4423 - top5-acc: 0.9088 - val_loss: 1.5022 - val_acc: 0.4600 - val_top5-acc: 0.9184 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5576 - acc: 0.4465 - top5-acc: 0.9094 - val_loss: 1.4912 - val_acc: 0.4766 - val_top5-acc: 0.9192 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5387 - acc: 0.4524 - top5-acc: 0.9136 - val_loss: 1.4703 - val_acc: 0.4838 - val_top5-acc: 0.9218 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5338 - acc: 0.4580 - top5-acc: 0.9120 - val_loss: 1.4699 - val_acc: 0.4730 - val_top5-acc: 0.9216 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5191 - acc: 0.4634 - top5-acc: 0.9151 - val_loss: 1.4647 - val_acc: 0.4756 - val_top5-acc: 0.9222 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5038 - acc: 0.4656 - top5-acc: 0.9171 - val_loss: 1.4192 - val_acc: 0.4960 - val_top5-acc: 0.9302 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5030 - acc: 0.4660 - top5-acc: 0.9195 - val_loss: 1.4279 - val_acc: 0.4900 - val_top5-acc: 0.9244 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4982 - acc: 0.4693 - top5-acc: 0.9182 - val_loss: 1.5072 - val_acc: 0.4614 - val_top5-acc: 0.9144 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4919 - acc: 0.4709 - top5-acc: 0.9187 - val_loss: 1.4443 - val_acc: 0.4858 - val_top5-acc: 0.9218 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.5193 - acc: 0.4671 - top5-acc: 0.9184 - val_loss: 1.4473 - val_acc: 0.4932 - val_top5-acc: 0.9230 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4885 - acc: 0.4725 - top5-acc: 0.9202 - val_loss: 1.3916 - val_acc: 0.5052 - val_top5-acc: 0.9316 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4754 - acc: 0.4760 - top5-acc: 0.9229 - val_loss: 1.4295 - val_acc: 0.4930 - val_top5-acc: 0.9290 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4828 - acc: 0.4735 - top5-acc: 0.9216 - val_loss: 1.3972 - val_acc: 0.4976 - val_top5-acc: 0.9326 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4769 - acc: 0.4768 - top5-acc: 0.9220 - val_loss: 1.4026 - val_acc: 0.4920 - val_top5-acc: 0.9320 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4647 - acc: 0.4813 - top5-acc: 0.9235 - val_loss: 1.3748 - val_acc: 0.5100 - val_top5-acc: 0.9370 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4676 - acc: 0.4793 - top5-acc: 0.9218 - val_loss: 1.4475 - val_acc: 0.4846 - val_top5-acc: 0.9264 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4615 - acc: 0.4844 - top5-acc: 0.9225 - val_loss: 1.3926 - val_acc: 0.5008 - val_top5-acc: 0.9310 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.4696 - acc: 0.4805 - top5-acc: 0.9207 - val_loss: 1.3683 - val_acc: 0.5176 - val_top5-acc: 0.9348 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4815 - acc: 0.4787 - top5-acc: 0.9216 - val_loss: 1.3963 - val_acc: 0.5024 - val_top5-acc: 0.9324 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4680 - acc: 0.4812 - top5-acc: 0.9240 - val_loss: 1.3957 - val_acc: 0.4996 - val_top5-acc: 0.9342 - lr: 0.0050\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4713 - acc: 0.4775 - top5-acc: 0.9224 - val_loss: 1.4278 - val_acc: 0.4908 - val_top5-acc: 0.9238 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4705 - acc: 0.4814 - top5-acc: 0.9221 - val_loss: 1.4136 - val_acc: 0.4972 - val_top5-acc: 0.9324 - lr: 0.0050\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4763 - acc: 0.4806 - top5-acc: 0.9222 - val_loss: 1.4075 - val_acc: 0.5090 - val_top5-acc: 0.9270 - lr: 0.0050\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4203 - acc: 0.4933 - top5-acc: 0.9285 - val_loss: 1.3394 - val_acc: 0.5318 - val_top5-acc: 0.9396 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.4047 - acc: 0.4987 - top5-acc: 0.9290 - val_loss: 1.3398 - val_acc: 0.5242 - val_top5-acc: 0.9372 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 6s 65ms/step - loss: 1.4084 - acc: 0.4998 - top5-acc: 0.9285 - val_loss: 1.3500 - val_acc: 0.5152 - val_top5-acc: 0.9340 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 6s 64ms/step - loss: 1.4112 - acc: 0.4993 - top5-acc: 0.9262 - val_loss: 1.3277 - val_acc: 0.5342 - val_top5-acc: 0.9410 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4052 - acc: 0.5016 - top5-acc: 0.9274 - val_loss: 1.3514 - val_acc: 0.5194 - val_top5-acc: 0.9338 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.4087 - acc: 0.4986 - top5-acc: 0.9282 - val_loss: 1.3443 - val_acc: 0.5238 - val_top5-acc: 0.9432 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 6s 68ms/step - loss: 1.4061 - acc: 0.4976 - top5-acc: 0.9294 - val_loss: 1.3369 - val_acc: 0.5256 - val_top5-acc: 0.9372 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4125 - acc: 0.4954 - top5-acc: 0.9295 - val_loss: 1.3526 - val_acc: 0.5164 - val_top5-acc: 0.9320 - lr: 0.0025\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4107 - acc: 0.4975 - top5-acc: 0.9273 - val_loss: 1.3268 - val_acc: 0.5328 - val_top5-acc: 0.9366 - lr: 0.0025\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4062 - acc: 0.4986 - top5-acc: 0.9300 - val_loss: 1.3453 - val_acc: 0.5266 - val_top5-acc: 0.9404 - lr: 0.0025\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4129 - acc: 0.4970 - top5-acc: 0.9282 - val_loss: 1.3171 - val_acc: 0.5328 - val_top5-acc: 0.9416 - lr: 0.0025\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4164 - acc: 0.4961 - top5-acc: 0.9278 - val_loss: 1.3393 - val_acc: 0.5278 - val_top5-acc: 0.9356 - lr: 0.0025\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.4105 - acc: 0.4982 - top5-acc: 0.9290 - val_loss: 1.3367 - val_acc: 0.5214 - val_top5-acc: 0.9334 - lr: 0.0025\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4056 - acc: 0.4997 - top5-acc: 0.9292 - val_loss: 1.3425 - val_acc: 0.5218 - val_top5-acc: 0.9368 - lr: 0.0025\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4133 - acc: 0.4975 - top5-acc: 0.9272 - val_loss: 1.3483 - val_acc: 0.5188 - val_top5-acc: 0.9402 - lr: 0.0025\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.4203 - acc: 0.4939 - top5-acc: 0.9272 - val_loss: 1.3275 - val_acc: 0.5306 - val_top5-acc: 0.9380 - lr: 0.0025\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 6s 67ms/step - loss: 1.3918 - acc: 0.5067 - top5-acc: 0.9299 - val_loss: 1.3161 - val_acc: 0.5330 - val_top5-acc: 0.9388 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3878 - acc: 0.5065 - top5-acc: 0.9303 - val_loss: 1.3220 - val_acc: 0.5372 - val_top5-acc: 0.9408 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3898 - acc: 0.5047 - top5-acc: 0.9317 - val_loss: 1.3267 - val_acc: 0.5334 - val_top5-acc: 0.9426 - lr: 0.0012\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3868 - acc: 0.5074 - top5-acc: 0.9312 - val_loss: 1.3207 - val_acc: 0.5358 - val_top5-acc: 0.9402 - lr: 0.0012\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3860 - acc: 0.5067 - top5-acc: 0.9306 - val_loss: 1.3098 - val_acc: 0.5354 - val_top5-acc: 0.9392 - lr: 0.0012\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3903 - acc: 0.5037 - top5-acc: 0.9288 - val_loss: 1.3163 - val_acc: 0.5304 - val_top5-acc: 0.9412 - lr: 0.0012\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3886 - acc: 0.5048 - top5-acc: 0.9325 - val_loss: 1.3122 - val_acc: 0.5420 - val_top5-acc: 0.9410 - lr: 0.0012\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 6s 66ms/step - loss: 1.3929 - acc: 0.5031 - top5-acc: 0.9309 - val_loss: 1.3247 - val_acc: 0.5306 - val_top5-acc: 0.9400 - lr: 0.0012\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 1.3470 - acc: 0.5168 - top5-acc: 0.9387\n",
      "Test accuracy: 51.68%\n",
      "Test top 5 accuracy: 93.87%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.9889 - acc: 0.3384 - top5-acc: 0.8418WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 8s 79ms/step - loss: 1.9889 - acc: 0.3384 - top5-acc: 0.8418 - val_loss: 1.6060 - val_acc: 0.4144 - val_top5-acc: 0.9084 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.6081 - acc: 0.4253 - top5-acc: 0.9005 - val_loss: 1.5124 - val_acc: 0.4518 - val_top5-acc: 0.9172 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.5591 - acc: 0.4429 - top5-acc: 0.9083 - val_loss: 1.4470 - val_acc: 0.4812 - val_top5-acc: 0.9256 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.5285 - acc: 0.4539 - top5-acc: 0.9129 - val_loss: 1.5038 - val_acc: 0.4632 - val_top5-acc: 0.9228 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.5148 - acc: 0.4610 - top5-acc: 0.9152 - val_loss: 1.4445 - val_acc: 0.4920 - val_top5-acc: 0.9308 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.4942 - acc: 0.4687 - top5-acc: 0.9172 - val_loss: 1.4302 - val_acc: 0.4812 - val_top5-acc: 0.9282 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.4837 - acc: 0.4737 - top5-acc: 0.9206 - val_loss: 1.4133 - val_acc: 0.4924 - val_top5-acc: 0.9268 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.4727 - acc: 0.4723 - top5-acc: 0.9239 - val_loss: 1.4344 - val_acc: 0.4764 - val_top5-acc: 0.9296 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4722 - acc: 0.4746 - top5-acc: 0.9218 - val_loss: 1.4069 - val_acc: 0.4994 - val_top5-acc: 0.9322 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4477 - acc: 0.4850 - top5-acc: 0.9239 - val_loss: 1.4034 - val_acc: 0.4916 - val_top5-acc: 0.9312 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4623 - acc: 0.4773 - top5-acc: 0.9228 - val_loss: 1.3582 - val_acc: 0.5060 - val_top5-acc: 0.9378 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4565 - acc: 0.4826 - top5-acc: 0.9243 - val_loss: 1.3629 - val_acc: 0.5180 - val_top5-acc: 0.9366 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.4565 - acc: 0.4816 - top5-acc: 0.9233 - val_loss: 1.3884 - val_acc: 0.4970 - val_top5-acc: 0.9368 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4409 - acc: 0.4866 - top5-acc: 0.9265 - val_loss: 1.4213 - val_acc: 0.4936 - val_top5-acc: 0.9234 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4467 - acc: 0.4874 - top5-acc: 0.9245 - val_loss: 1.3594 - val_acc: 0.5126 - val_top5-acc: 0.9368 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4503 - acc: 0.4843 - top5-acc: 0.9261 - val_loss: 1.3982 - val_acc: 0.4952 - val_top5-acc: 0.9290 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4041 - acc: 0.4984 - top5-acc: 0.9280 - val_loss: 1.3165 - val_acc: 0.5274 - val_top5-acc: 0.9408 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.3956 - acc: 0.5025 - top5-acc: 0.9294 - val_loss: 1.3127 - val_acc: 0.5324 - val_top5-acc: 0.9410 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4034 - acc: 0.4990 - top5-acc: 0.9297 - val_loss: 1.3243 - val_acc: 0.5224 - val_top5-acc: 0.9390 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3919 - acc: 0.5027 - top5-acc: 0.9311 - val_loss: 1.3346 - val_acc: 0.5214 - val_top5-acc: 0.9370 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.4049 - acc: 0.4981 - top5-acc: 0.9306 - val_loss: 1.3186 - val_acc: 0.5268 - val_top5-acc: 0.9424 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3895 - acc: 0.5026 - top5-acc: 0.9329 - val_loss: 1.3394 - val_acc: 0.5244 - val_top5-acc: 0.9372 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3929 - acc: 0.5017 - top5-acc: 0.9319 - val_loss: 1.3318 - val_acc: 0.5208 - val_top5-acc: 0.9376 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3818 - acc: 0.5064 - top5-acc: 0.9310 - val_loss: 1.3057 - val_acc: 0.5394 - val_top5-acc: 0.9422 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.3727 - acc: 0.5094 - top5-acc: 0.9334 - val_loss: 1.2968 - val_acc: 0.5368 - val_top5-acc: 0.9418 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.3764 - acc: 0.5084 - top5-acc: 0.9322 - val_loss: 1.3003 - val_acc: 0.5374 - val_top5-acc: 0.9392 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.3682 - acc: 0.5116 - top5-acc: 0.9338 - val_loss: 1.3052 - val_acc: 0.5362 - val_top5-acc: 0.9384 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3702 - acc: 0.5111 - top5-acc: 0.9339 - val_loss: 1.3107 - val_acc: 0.5336 - val_top5-acc: 0.9388 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3736 - acc: 0.5104 - top5-acc: 0.9324 - val_loss: 1.3042 - val_acc: 0.5358 - val_top5-acc: 0.9412 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3730 - acc: 0.5137 - top5-acc: 0.9332 - val_loss: 1.3207 - val_acc: 0.5330 - val_top5-acc: 0.9366 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3645 - acc: 0.5140 - top5-acc: 0.9344 - val_loss: 1.2982 - val_acc: 0.5364 - val_top5-acc: 0.9398 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3611 - acc: 0.5153 - top5-acc: 0.9341 - val_loss: 1.2923 - val_acc: 0.5442 - val_top5-acc: 0.9420 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3656 - acc: 0.5153 - top5-acc: 0.9340 - val_loss: 1.3049 - val_acc: 0.5448 - val_top5-acc: 0.9382 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3648 - acc: 0.5127 - top5-acc: 0.9332 - val_loss: 1.2972 - val_acc: 0.5394 - val_top5-acc: 0.9432 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3681 - acc: 0.5154 - top5-acc: 0.9318 - val_loss: 1.3077 - val_acc: 0.5360 - val_top5-acc: 0.9390 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3686 - acc: 0.5128 - top5-acc: 0.9331 - val_loss: 1.2966 - val_acc: 0.5418 - val_top5-acc: 0.9422 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3600 - acc: 0.5176 - top5-acc: 0.9356 - val_loss: 1.3074 - val_acc: 0.5394 - val_top5-acc: 0.9402 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 6s 74ms/step - loss: 1.3610 - acc: 0.5157 - top5-acc: 0.9327 - val_loss: 1.2983 - val_acc: 0.5418 - val_top5-acc: 0.9402 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3583 - acc: 0.5150 - top5-acc: 0.9354 - val_loss: 1.2997 - val_acc: 0.5384 - val_top5-acc: 0.9402 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3597 - acc: 0.5160 - top5-acc: 0.9346 - val_loss: 1.2977 - val_acc: 0.5428 - val_top5-acc: 0.9406 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3559 - acc: 0.5167 - top5-acc: 0.9352 - val_loss: 1.3008 - val_acc: 0.5356 - val_top5-acc: 0.9388 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3602 - acc: 0.5184 - top5-acc: 0.9339 - val_loss: 1.3012 - val_acc: 0.5410 - val_top5-acc: 0.9394 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 1.3570 - acc: 0.5182 - top5-acc: 0.9342 - val_loss: 1.2957 - val_acc: 0.5410 - val_top5-acc: 0.9406 - lr: 1.5625e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3578 - acc: 0.5208 - top5-acc: 0.9336 - val_loss: 1.2959 - val_acc: 0.5406 - val_top5-acc: 0.9426 - lr: 1.5625e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 6s 73ms/step - loss: 1.3580 - acc: 0.5166 - top5-acc: 0.9336 - val_loss: 1.2975 - val_acc: 0.5436 - val_top5-acc: 0.9396 - lr: 1.5625e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3623 - acc: 0.5151 - top5-acc: 0.9345 - val_loss: 1.2985 - val_acc: 0.5406 - val_top5-acc: 0.9400 - lr: 1.5625e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 7s 75ms/step - loss: 1.3607 - acc: 0.5168 - top5-acc: 0.9341 - val_loss: 1.3016 - val_acc: 0.5416 - val_top5-acc: 0.9414 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3609 - acc: 0.5159 - top5-acc: 0.9345 - val_loss: 1.3006 - val_acc: 0.5404 - val_top5-acc: 0.9440 - lr: 7.8125e-05\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3570 - acc: 0.5212 - top5-acc: 0.9362 - val_loss: 1.2992 - val_acc: 0.5440 - val_top5-acc: 0.9432 - lr: 7.8125e-05\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 7s 74ms/step - loss: 1.3595 - acc: 0.5192 - top5-acc: 0.9347 - val_loss: 1.3035 - val_acc: 0.5434 - val_top5-acc: 0.9406 - lr: 7.8125e-05\n",
      "313/313 [==============================] - 9s 28ms/step - loss: 1.3110 - acc: 0.5396 - top5-acc: 0.9411\n",
      "Test accuracy: 53.96%\n",
      "Test top 5 accuracy: 94.11%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 2.0507 - acc: 0.3345 - top5-acc: 0.8343WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 9s 87ms/step - loss: 2.0507 - acc: 0.3345 - top5-acc: 0.8343 - val_loss: 1.5692 - val_acc: 0.4372 - val_top5-acc: 0.9144 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.5963 - acc: 0.4272 - top5-acc: 0.9034 - val_loss: 1.5241 - val_acc: 0.4390 - val_top5-acc: 0.9204 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.5438 - acc: 0.4456 - top5-acc: 0.9115 - val_loss: 1.4372 - val_acc: 0.4876 - val_top5-acc: 0.9260 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.5235 - acc: 0.4571 - top5-acc: 0.9158 - val_loss: 1.4398 - val_acc: 0.4862 - val_top5-acc: 0.9298 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.5033 - acc: 0.4626 - top5-acc: 0.9164 - val_loss: 1.3950 - val_acc: 0.5068 - val_top5-acc: 0.9336 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.4915 - acc: 0.4702 - top5-acc: 0.9196 - val_loss: 1.4319 - val_acc: 0.4910 - val_top5-acc: 0.9262 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4774 - acc: 0.4721 - top5-acc: 0.9221 - val_loss: 1.4322 - val_acc: 0.4774 - val_top5-acc: 0.9328 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.4596 - acc: 0.4808 - top5-acc: 0.9228 - val_loss: 1.3807 - val_acc: 0.5112 - val_top5-acc: 0.9338 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4636 - acc: 0.4747 - top5-acc: 0.9222 - val_loss: 1.3862 - val_acc: 0.5036 - val_top5-acc: 0.9340 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4633 - acc: 0.4781 - top5-acc: 0.9255 - val_loss: 1.3663 - val_acc: 0.5140 - val_top5-acc: 0.9326 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4486 - acc: 0.4828 - top5-acc: 0.9250 - val_loss: 1.3931 - val_acc: 0.5082 - val_top5-acc: 0.9354 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4585 - acc: 0.4832 - top5-acc: 0.9254 - val_loss: 1.3926 - val_acc: 0.5074 - val_top5-acc: 0.9354 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4420 - acc: 0.4845 - top5-acc: 0.9275 - val_loss: 1.3691 - val_acc: 0.5052 - val_top5-acc: 0.9374 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4425 - acc: 0.4869 - top5-acc: 0.9255 - val_loss: 1.3598 - val_acc: 0.5138 - val_top5-acc: 0.9394 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4324 - acc: 0.4899 - top5-acc: 0.9279 - val_loss: 1.3214 - val_acc: 0.5280 - val_top5-acc: 0.9382 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.4431 - acc: 0.4883 - top5-acc: 0.9267 - val_loss: 1.3806 - val_acc: 0.5160 - val_top5-acc: 0.9360 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4333 - acc: 0.4884 - top5-acc: 0.9279 - val_loss: 1.3837 - val_acc: 0.5046 - val_top5-acc: 0.9306 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.4483 - acc: 0.4828 - top5-acc: 0.9272 - val_loss: 1.3702 - val_acc: 0.5194 - val_top5-acc: 0.9366 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.4249 - acc: 0.4950 - top5-acc: 0.9290 - val_loss: 1.3467 - val_acc: 0.5206 - val_top5-acc: 0.9378 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.4196 - acc: 0.4936 - top5-acc: 0.9289 - val_loss: 1.3451 - val_acc: 0.5296 - val_top5-acc: 0.9374 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3851 - acc: 0.5071 - top5-acc: 0.9331 - val_loss: 1.3220 - val_acc: 0.5294 - val_top5-acc: 0.9380 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3917 - acc: 0.5027 - top5-acc: 0.9320 - val_loss: 1.3470 - val_acc: 0.5238 - val_top5-acc: 0.9364 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.3890 - acc: 0.5064 - top5-acc: 0.9309 - val_loss: 1.3148 - val_acc: 0.5256 - val_top5-acc: 0.9410 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3883 - acc: 0.5064 - top5-acc: 0.9306 - val_loss: 1.3101 - val_acc: 0.5330 - val_top5-acc: 0.9422 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3930 - acc: 0.5013 - top5-acc: 0.9328 - val_loss: 1.3220 - val_acc: 0.5272 - val_top5-acc: 0.9432 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3849 - acc: 0.5091 - top5-acc: 0.9317 - val_loss: 1.2943 - val_acc: 0.5358 - val_top5-acc: 0.9474 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3878 - acc: 0.5033 - top5-acc: 0.9316 - val_loss: 1.3324 - val_acc: 0.5234 - val_top5-acc: 0.9392 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.3871 - acc: 0.5059 - top5-acc: 0.9317 - val_loss: 1.3183 - val_acc: 0.5250 - val_top5-acc: 0.9404 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3866 - acc: 0.5048 - top5-acc: 0.9327 - val_loss: 1.2947 - val_acc: 0.5402 - val_top5-acc: 0.9442 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3857 - acc: 0.5067 - top5-acc: 0.9309 - val_loss: 1.3147 - val_acc: 0.5330 - val_top5-acc: 0.9402 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.3867 - acc: 0.5089 - top5-acc: 0.9292 - val_loss: 1.3046 - val_acc: 0.5344 - val_top5-acc: 0.9402 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.3654 - acc: 0.5140 - top5-acc: 0.9338 - val_loss: 1.3000 - val_acc: 0.5332 - val_top5-acc: 0.9408 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 7s 81ms/step - loss: 1.3659 - acc: 0.5143 - top5-acc: 0.9341 - val_loss: 1.2925 - val_acc: 0.5402 - val_top5-acc: 0.9434 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3627 - acc: 0.5120 - top5-acc: 0.9355 - val_loss: 1.2892 - val_acc: 0.5402 - val_top5-acc: 0.9432 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3662 - acc: 0.5135 - top5-acc: 0.9340 - val_loss: 1.2937 - val_acc: 0.5408 - val_top5-acc: 0.9426 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3630 - acc: 0.5149 - top5-acc: 0.9344 - val_loss: 1.2972 - val_acc: 0.5344 - val_top5-acc: 0.9398 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3682 - acc: 0.5105 - top5-acc: 0.9347 - val_loss: 1.3068 - val_acc: 0.5322 - val_top5-acc: 0.9438 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3661 - acc: 0.5137 - top5-acc: 0.9339 - val_loss: 1.2898 - val_acc: 0.5422 - val_top5-acc: 0.9428 - lr: 0.0012\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3603 - acc: 0.5167 - top5-acc: 0.9353 - val_loss: 1.2937 - val_acc: 0.5458 - val_top5-acc: 0.9410 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3571 - acc: 0.5195 - top5-acc: 0.9343 - val_loss: 1.2787 - val_acc: 0.5478 - val_top5-acc: 0.9448 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3549 - acc: 0.5200 - top5-acc: 0.9342 - val_loss: 1.2934 - val_acc: 0.5436 - val_top5-acc: 0.9426 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3545 - acc: 0.5165 - top5-acc: 0.9338 - val_loss: 1.2789 - val_acc: 0.5520 - val_top5-acc: 0.9428 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3567 - acc: 0.5172 - top5-acc: 0.9355 - val_loss: 1.2868 - val_acc: 0.5484 - val_top5-acc: 0.9420 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3529 - acc: 0.5160 - top5-acc: 0.9359 - val_loss: 1.2915 - val_acc: 0.5428 - val_top5-acc: 0.9414 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3551 - acc: 0.5185 - top5-acc: 0.9339 - val_loss: 1.2886 - val_acc: 0.5444 - val_top5-acc: 0.9426 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3525 - acc: 0.5163 - top5-acc: 0.9350 - val_loss: 1.2765 - val_acc: 0.5514 - val_top5-acc: 0.9448 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3502 - acc: 0.5198 - top5-acc: 0.9370 - val_loss: 1.2816 - val_acc: 0.5430 - val_top5-acc: 0.9448 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 7s 83ms/step - loss: 1.3489 - acc: 0.5199 - top5-acc: 0.9362 - val_loss: 1.2804 - val_acc: 0.5516 - val_top5-acc: 0.9446 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3558 - acc: 0.5190 - top5-acc: 0.9354 - val_loss: 1.2835 - val_acc: 0.5458 - val_top5-acc: 0.9450 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 7s 82ms/step - loss: 1.3551 - acc: 0.5180 - top5-acc: 0.9345 - val_loss: 1.2874 - val_acc: 0.5472 - val_top5-acc: 0.9438 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 10s 32ms/step - loss: 1.2933 - acc: 0.5440 - top5-acc: 0.9434\n",
      "Test accuracy: 54.4%\n",
      "Test top 5 accuracy: 94.34%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8953 - acc: 0.3528 - top5-acc: 0.8480WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 10s 96ms/step - loss: 1.8953 - acc: 0.3528 - top5-acc: 0.8480 - val_loss: 1.5472 - val_acc: 0.4324 - val_top5-acc: 0.9174 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 1.5914 - acc: 0.4315 - top5-acc: 0.9031 - val_loss: 1.4887 - val_acc: 0.4604 - val_top5-acc: 0.9212 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 1.5354 - acc: 0.4523 - top5-acc: 0.9122 - val_loss: 1.4544 - val_acc: 0.4718 - val_top5-acc: 0.9220 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.5201 - acc: 0.4603 - top5-acc: 0.9158 - val_loss: 1.4438 - val_acc: 0.4898 - val_top5-acc: 0.9176 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.4884 - acc: 0.4706 - top5-acc: 0.9196 - val_loss: 1.3813 - val_acc: 0.5106 - val_top5-acc: 0.9350 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.4767 - acc: 0.4747 - top5-acc: 0.9197 - val_loss: 1.4131 - val_acc: 0.4952 - val_top5-acc: 0.9302 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.4738 - acc: 0.4769 - top5-acc: 0.9212 - val_loss: 1.3797 - val_acc: 0.5032 - val_top5-acc: 0.9356 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.4595 - acc: 0.4811 - top5-acc: 0.9240 - val_loss: 1.3763 - val_acc: 0.5028 - val_top5-acc: 0.9336 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.4464 - acc: 0.4867 - top5-acc: 0.9246 - val_loss: 1.3642 - val_acc: 0.5156 - val_top5-acc: 0.9384 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.4383 - acc: 0.4900 - top5-acc: 0.9262 - val_loss: 1.3694 - val_acc: 0.5086 - val_top5-acc: 0.9376 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.4245 - acc: 0.4917 - top5-acc: 0.9280 - val_loss: 1.3408 - val_acc: 0.5210 - val_top5-acc: 0.9392 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.4339 - acc: 0.4907 - top5-acc: 0.9276 - val_loss: 1.3282 - val_acc: 0.5284 - val_top5-acc: 0.9418 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.4377 - acc: 0.4869 - top5-acc: 0.9263 - val_loss: 1.3610 - val_acc: 0.5190 - val_top5-acc: 0.9350 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.4315 - acc: 0.4910 - top5-acc: 0.9267 - val_loss: 1.3474 - val_acc: 0.5108 - val_top5-acc: 0.9346 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.4279 - acc: 0.4942 - top5-acc: 0.9274 - val_loss: 1.3755 - val_acc: 0.5100 - val_top5-acc: 0.9366 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.4267 - acc: 0.4939 - top5-acc: 0.9290 - val_loss: 1.3594 - val_acc: 0.5194 - val_top5-acc: 0.9382 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.4245 - acc: 0.4938 - top5-acc: 0.9285 - val_loss: 1.3791 - val_acc: 0.5060 - val_top5-acc: 0.9310 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3876 - acc: 0.5068 - top5-acc: 0.9312 - val_loss: 1.3017 - val_acc: 0.5354 - val_top5-acc: 0.9406 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3810 - acc: 0.5082 - top5-acc: 0.9322 - val_loss: 1.3023 - val_acc: 0.5348 - val_top5-acc: 0.9458 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3789 - acc: 0.5074 - top5-acc: 0.9338 - val_loss: 1.3149 - val_acc: 0.5266 - val_top5-acc: 0.9394 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3703 - acc: 0.5120 - top5-acc: 0.9333 - val_loss: 1.3047 - val_acc: 0.5398 - val_top5-acc: 0.9426 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3806 - acc: 0.5062 - top5-acc: 0.9322 - val_loss: 1.2981 - val_acc: 0.5346 - val_top5-acc: 0.9440 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3757 - acc: 0.5101 - top5-acc: 0.9325 - val_loss: 1.3268 - val_acc: 0.5270 - val_top5-acc: 0.9422 - lr: 0.0025\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3752 - acc: 0.5105 - top5-acc: 0.9329 - val_loss: 1.2840 - val_acc: 0.5416 - val_top5-acc: 0.9434 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3750 - acc: 0.5093 - top5-acc: 0.9326 - val_loss: 1.3086 - val_acc: 0.5298 - val_top5-acc: 0.9446 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3825 - acc: 0.5077 - top5-acc: 0.9322 - val_loss: 1.3265 - val_acc: 0.5288 - val_top5-acc: 0.9392 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3751 - acc: 0.5107 - top5-acc: 0.9329 - val_loss: 1.2903 - val_acc: 0.5378 - val_top5-acc: 0.9456 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3683 - acc: 0.5141 - top5-acc: 0.9340 - val_loss: 1.3112 - val_acc: 0.5296 - val_top5-acc: 0.9424 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3762 - acc: 0.5097 - top5-acc: 0.9323 - val_loss: 1.3062 - val_acc: 0.5300 - val_top5-acc: 0.9440 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3606 - acc: 0.5143 - top5-acc: 0.9339 - val_loss: 1.2830 - val_acc: 0.5408 - val_top5-acc: 0.9384 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3556 - acc: 0.5172 - top5-acc: 0.9350 - val_loss: 1.2771 - val_acc: 0.5428 - val_top5-acc: 0.9406 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3540 - acc: 0.5204 - top5-acc: 0.9348 - val_loss: 1.2745 - val_acc: 0.5460 - val_top5-acc: 0.9482 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3533 - acc: 0.5189 - top5-acc: 0.9344 - val_loss: 1.2899 - val_acc: 0.5368 - val_top5-acc: 0.9422 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3556 - acc: 0.5195 - top5-acc: 0.9363 - val_loss: 1.3011 - val_acc: 0.5300 - val_top5-acc: 0.9456 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3557 - acc: 0.5188 - top5-acc: 0.9337 - val_loss: 1.2769 - val_acc: 0.5448 - val_top5-acc: 0.9456 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3598 - acc: 0.5171 - top5-acc: 0.9342 - val_loss: 1.2918 - val_acc: 0.5420 - val_top5-acc: 0.9434 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3555 - acc: 0.5199 - top5-acc: 0.9356 - val_loss: 1.2891 - val_acc: 0.5384 - val_top5-acc: 0.9440 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3492 - acc: 0.5209 - top5-acc: 0.9345 - val_loss: 1.2821 - val_acc: 0.5456 - val_top5-acc: 0.9452 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3504 - acc: 0.5198 - top5-acc: 0.9357 - val_loss: 1.2791 - val_acc: 0.5408 - val_top5-acc: 0.9446 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3488 - acc: 0.5176 - top5-acc: 0.9368 - val_loss: 1.2693 - val_acc: 0.5460 - val_top5-acc: 0.9488 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3521 - acc: 0.5182 - top5-acc: 0.9352 - val_loss: 1.2744 - val_acc: 0.5484 - val_top5-acc: 0.9446 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3495 - acc: 0.5220 - top5-acc: 0.9360 - val_loss: 1.2715 - val_acc: 0.5490 - val_top5-acc: 0.9474 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3506 - acc: 0.5195 - top5-acc: 0.9356 - val_loss: 1.2722 - val_acc: 0.5512 - val_top5-acc: 0.9452 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 8s 89ms/step - loss: 1.3479 - acc: 0.5180 - top5-acc: 0.9359 - val_loss: 1.2765 - val_acc: 0.5478 - val_top5-acc: 0.9462 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3481 - acc: 0.5238 - top5-acc: 0.9364 - val_loss: 1.2710 - val_acc: 0.5528 - val_top5-acc: 0.9472 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3450 - acc: 0.5247 - top5-acc: 0.9351 - val_loss: 1.2773 - val_acc: 0.5456 - val_top5-acc: 0.9464 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3510 - acc: 0.5188 - top5-acc: 0.9352 - val_loss: 1.2805 - val_acc: 0.5428 - val_top5-acc: 0.9440 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3427 - acc: 0.5244 - top5-acc: 0.9369 - val_loss: 1.2813 - val_acc: 0.5432 - val_top5-acc: 0.9444 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 8s 91ms/step - loss: 1.3484 - acc: 0.5212 - top5-acc: 0.9368 - val_loss: 1.2692 - val_acc: 0.5506 - val_top5-acc: 0.9472 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 8s 90ms/step - loss: 1.3463 - acc: 0.5216 - top5-acc: 0.9353 - val_loss: 1.2793 - val_acc: 0.5446 - val_top5-acc: 0.9466 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 11s 36ms/step - loss: 1.2911 - acc: 0.5405 - top5-acc: 0.9470\n",
      "Test accuracy: 54.05%\n",
      "Test top 5 accuracy: 94.7%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8517 - acc: 0.3674 - top5-acc: 0.8584WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 11s 105ms/step - loss: 1.8517 - acc: 0.3674 - top5-acc: 0.8584 - val_loss: 1.5178 - val_acc: 0.4466 - val_top5-acc: 0.9140 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.5558 - acc: 0.4410 - top5-acc: 0.9098 - val_loss: 1.4559 - val_acc: 0.4804 - val_top5-acc: 0.9258 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.5045 - acc: 0.4636 - top5-acc: 0.9168 - val_loss: 1.4005 - val_acc: 0.4948 - val_top5-acc: 0.9314 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4781 - acc: 0.4714 - top5-acc: 0.9209 - val_loss: 1.3761 - val_acc: 0.5072 - val_top5-acc: 0.9278 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4653 - acc: 0.4794 - top5-acc: 0.9223 - val_loss: 1.3692 - val_acc: 0.5092 - val_top5-acc: 0.9328 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4522 - acc: 0.4819 - top5-acc: 0.9235 - val_loss: 1.3737 - val_acc: 0.5052 - val_top5-acc: 0.9374 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4443 - acc: 0.4869 - top5-acc: 0.9249 - val_loss: 1.3368 - val_acc: 0.5246 - val_top5-acc: 0.9390 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4265 - acc: 0.4922 - top5-acc: 0.9276 - val_loss: 1.3573 - val_acc: 0.5112 - val_top5-acc: 0.9382 - lr: 0.0050\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4187 - acc: 0.4954 - top5-acc: 0.9272 - val_loss: 1.3307 - val_acc: 0.5260 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4109 - acc: 0.4976 - top5-acc: 0.9297 - val_loss: 1.3732 - val_acc: 0.5136 - val_top5-acc: 0.9316 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4125 - acc: 0.4976 - top5-acc: 0.9291 - val_loss: 1.3285 - val_acc: 0.5180 - val_top5-acc: 0.9422 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4206 - acc: 0.4956 - top5-acc: 0.9283 - val_loss: 1.3212 - val_acc: 0.5368 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3996 - acc: 0.5031 - top5-acc: 0.9325 - val_loss: 1.2960 - val_acc: 0.5392 - val_top5-acc: 0.9488 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4042 - acc: 0.4998 - top5-acc: 0.9311 - val_loss: 1.2980 - val_acc: 0.5358 - val_top5-acc: 0.9450 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.4023 - acc: 0.5034 - top5-acc: 0.9303 - val_loss: 1.3220 - val_acc: 0.5372 - val_top5-acc: 0.9380 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3918 - acc: 0.5019 - top5-acc: 0.9306 - val_loss: 1.3229 - val_acc: 0.5342 - val_top5-acc: 0.9440 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.4001 - acc: 0.5038 - top5-acc: 0.9311 - val_loss: 1.2952 - val_acc: 0.5466 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3851 - acc: 0.5072 - top5-acc: 0.9332 - val_loss: 1.2864 - val_acc: 0.5478 - val_top5-acc: 0.9418 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3982 - acc: 0.5034 - top5-acc: 0.9320 - val_loss: 1.3034 - val_acc: 0.5368 - val_top5-acc: 0.9442 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3838 - acc: 0.5065 - top5-acc: 0.9344 - val_loss: 1.2757 - val_acc: 0.5466 - val_top5-acc: 0.9430 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3860 - acc: 0.5063 - top5-acc: 0.9319 - val_loss: 1.3454 - val_acc: 0.5172 - val_top5-acc: 0.9442 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3867 - acc: 0.5062 - top5-acc: 0.9319 - val_loss: 1.3330 - val_acc: 0.5206 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.4035 - acc: 0.5017 - top5-acc: 0.9311 - val_loss: 1.2835 - val_acc: 0.5486 - val_top5-acc: 0.9420 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3894 - acc: 0.5042 - top5-acc: 0.9324 - val_loss: 1.2873 - val_acc: 0.5436 - val_top5-acc: 0.9458 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3892 - acc: 0.5060 - top5-acc: 0.9333 - val_loss: 1.2959 - val_acc: 0.5420 - val_top5-acc: 0.9442 - lr: 0.0050\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3526 - acc: 0.5176 - top5-acc: 0.9364 - val_loss: 1.2712 - val_acc: 0.5524 - val_top5-acc: 0.9462 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3527 - acc: 0.5153 - top5-acc: 0.9364 - val_loss: 1.2573 - val_acc: 0.5542 - val_top5-acc: 0.9484 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3497 - acc: 0.5177 - top5-acc: 0.9359 - val_loss: 1.2813 - val_acc: 0.5384 - val_top5-acc: 0.9506 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3526 - acc: 0.5181 - top5-acc: 0.9351 - val_loss: 1.2775 - val_acc: 0.5442 - val_top5-acc: 0.9446 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3493 - acc: 0.5191 - top5-acc: 0.9370 - val_loss: 1.2635 - val_acc: 0.5518 - val_top5-acc: 0.9474 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3546 - acc: 0.5169 - top5-acc: 0.9349 - val_loss: 1.2923 - val_acc: 0.5304 - val_top5-acc: 0.9436 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3578 - acc: 0.5162 - top5-acc: 0.9356 - val_loss: 1.2593 - val_acc: 0.5554 - val_top5-acc: 0.9478 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3345 - acc: 0.5240 - top5-acc: 0.9378 - val_loss: 1.2575 - val_acc: 0.5570 - val_top5-acc: 0.9520 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3312 - acc: 0.5297 - top5-acc: 0.9385 - val_loss: 1.2609 - val_acc: 0.5478 - val_top5-acc: 0.9480 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3364 - acc: 0.5259 - top5-acc: 0.9368 - val_loss: 1.2514 - val_acc: 0.5602 - val_top5-acc: 0.9478 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3345 - acc: 0.5258 - top5-acc: 0.9381 - val_loss: 1.2492 - val_acc: 0.5560 - val_top5-acc: 0.9496 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3356 - acc: 0.5223 - top5-acc: 0.9366 - val_loss: 1.2456 - val_acc: 0.5604 - val_top5-acc: 0.9484 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3357 - acc: 0.5242 - top5-acc: 0.9388 - val_loss: 1.2600 - val_acc: 0.5530 - val_top5-acc: 0.9482 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3358 - acc: 0.5236 - top5-acc: 0.9389 - val_loss: 1.2603 - val_acc: 0.5542 - val_top5-acc: 0.9466 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3371 - acc: 0.5247 - top5-acc: 0.9373 - val_loss: 1.2561 - val_acc: 0.5526 - val_top5-acc: 0.9490 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3332 - acc: 0.5257 - top5-acc: 0.9362 - val_loss: 1.2598 - val_acc: 0.5532 - val_top5-acc: 0.9472 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3359 - acc: 0.5252 - top5-acc: 0.9371 - val_loss: 1.2642 - val_acc: 0.5490 - val_top5-acc: 0.9484 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 9s 97ms/step - loss: 1.3239 - acc: 0.5276 - top5-acc: 0.9391 - val_loss: 1.2518 - val_acc: 0.5632 - val_top5-acc: 0.9512 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3278 - acc: 0.5282 - top5-acc: 0.9372 - val_loss: 1.2514 - val_acc: 0.5546 - val_top5-acc: 0.9474 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3302 - acc: 0.5230 - top5-acc: 0.9386 - val_loss: 1.2497 - val_acc: 0.5594 - val_top5-acc: 0.9506 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3270 - acc: 0.5278 - top5-acc: 0.9391 - val_loss: 1.2545 - val_acc: 0.5562 - val_top5-acc: 0.9474 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 9s 99ms/step - loss: 1.3281 - acc: 0.5280 - top5-acc: 0.9390 - val_loss: 1.2458 - val_acc: 0.5616 - val_top5-acc: 0.9500 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3248 - acc: 0.5312 - top5-acc: 0.9392 - val_loss: 1.2482 - val_acc: 0.5590 - val_top5-acc: 0.9482 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3235 - acc: 0.5319 - top5-acc: 0.9396 - val_loss: 1.2454 - val_acc: 0.5600 - val_top5-acc: 0.9488 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 9s 98ms/step - loss: 1.3242 - acc: 0.5298 - top5-acc: 0.9387 - val_loss: 1.2514 - val_acc: 0.5582 - val_top5-acc: 0.9496 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 12s 39ms/step - loss: 1.2585 - acc: 0.5473 - top5-acc: 0.9489\n",
      "Test accuracy: 54.73%\n",
      "Test top 5 accuracy: 94.89%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8327 - acc: 0.3678 - top5-acc: 0.8583WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 14s 113ms/step - loss: 1.8327 - acc: 0.3678 - top5-acc: 0.8583 - val_loss: 1.5515 - val_acc: 0.4382 - val_top5-acc: 0.9134 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.5297 - acc: 0.4514 - top5-acc: 0.9136 - val_loss: 1.4225 - val_acc: 0.4892 - val_top5-acc: 0.9272 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.4823 - acc: 0.4694 - top5-acc: 0.9208 - val_loss: 1.4243 - val_acc: 0.4860 - val_top5-acc: 0.9290 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.4502 - acc: 0.4818 - top5-acc: 0.9243 - val_loss: 1.3941 - val_acc: 0.4958 - val_top5-acc: 0.9306 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.4389 - acc: 0.4850 - top5-acc: 0.9272 - val_loss: 1.3885 - val_acc: 0.4954 - val_top5-acc: 0.9378 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.4253 - acc: 0.4916 - top5-acc: 0.9289 - val_loss: 1.3314 - val_acc: 0.5180 - val_top5-acc: 0.9360 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.4156 - acc: 0.4942 - top5-acc: 0.9309 - val_loss: 1.3292 - val_acc: 0.5224 - val_top5-acc: 0.9410 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3938 - acc: 0.5000 - top5-acc: 0.9327 - val_loss: 1.3619 - val_acc: 0.5112 - val_top5-acc: 0.9400 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3907 - acc: 0.5025 - top5-acc: 0.9313 - val_loss: 1.3405 - val_acc: 0.5052 - val_top5-acc: 0.9420 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3971 - acc: 0.5017 - top5-acc: 0.9312 - val_loss: 1.3047 - val_acc: 0.5380 - val_top5-acc: 0.9424 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.4003 - acc: 0.5012 - top5-acc: 0.9320 - val_loss: 1.3222 - val_acc: 0.5222 - val_top5-acc: 0.9404 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3922 - acc: 0.5038 - top5-acc: 0.9329 - val_loss: 1.3388 - val_acc: 0.5116 - val_top5-acc: 0.9394 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.4036 - acc: 0.4983 - top5-acc: 0.9324 - val_loss: 1.3464 - val_acc: 0.5204 - val_top5-acc: 0.9410 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3849 - acc: 0.5051 - top5-acc: 0.9348 - val_loss: 1.3077 - val_acc: 0.5202 - val_top5-acc: 0.9458 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3724 - acc: 0.5094 - top5-acc: 0.9358 - val_loss: 1.2972 - val_acc: 0.5376 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3893 - acc: 0.5037 - top5-acc: 0.9334 - val_loss: 1.3071 - val_acc: 0.5252 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3778 - acc: 0.5077 - top5-acc: 0.9344 - val_loss: 1.3040 - val_acc: 0.5306 - val_top5-acc: 0.9432 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3827 - acc: 0.5063 - top5-acc: 0.9345 - val_loss: 1.2886 - val_acc: 0.5374 - val_top5-acc: 0.9470 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3731 - acc: 0.5105 - top5-acc: 0.9350 - val_loss: 1.3258 - val_acc: 0.5222 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3656 - acc: 0.5125 - top5-acc: 0.9349 - val_loss: 1.2865 - val_acc: 0.5336 - val_top5-acc: 0.9446 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.3738 - acc: 0.5089 - top5-acc: 0.9348 - val_loss: 1.3279 - val_acc: 0.5246 - val_top5-acc: 0.9444 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.3766 - acc: 0.5082 - top5-acc: 0.9354 - val_loss: 1.2613 - val_acc: 0.5488 - val_top5-acc: 0.9496 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3736 - acc: 0.5103 - top5-acc: 0.9356 - val_loss: 1.2590 - val_acc: 0.5488 - val_top5-acc: 0.9480 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3683 - acc: 0.5123 - top5-acc: 0.9355 - val_loss: 1.2839 - val_acc: 0.5446 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3751 - acc: 0.5092 - top5-acc: 0.9362 - val_loss: 1.2819 - val_acc: 0.5364 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3603 - acc: 0.5174 - top5-acc: 0.9349 - val_loss: 1.2929 - val_acc: 0.5418 - val_top5-acc: 0.9446 - lr: 0.0050\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3714 - acc: 0.5116 - top5-acc: 0.9343 - val_loss: 1.2779 - val_acc: 0.5406 - val_top5-acc: 0.9494 - lr: 0.0050\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3645 - acc: 0.5149 - top5-acc: 0.9359 - val_loss: 1.2671 - val_acc: 0.5400 - val_top5-acc: 0.9472 - lr: 0.0050\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3302 - acc: 0.5237 - top5-acc: 0.9390 - val_loss: 1.2519 - val_acc: 0.5498 - val_top5-acc: 0.9466 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 9s 106ms/step - loss: 1.3414 - acc: 0.5208 - top5-acc: 0.9379 - val_loss: 1.2641 - val_acc: 0.5422 - val_top5-acc: 0.9500 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3399 - acc: 0.5206 - top5-acc: 0.9384 - val_loss: 1.2463 - val_acc: 0.5602 - val_top5-acc: 0.9482 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3362 - acc: 0.5201 - top5-acc: 0.9386 - val_loss: 1.2434 - val_acc: 0.5554 - val_top5-acc: 0.9510 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3368 - acc: 0.5200 - top5-acc: 0.9378 - val_loss: 1.2440 - val_acc: 0.5530 - val_top5-acc: 0.9492 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3362 - acc: 0.5222 - top5-acc: 0.9398 - val_loss: 1.2573 - val_acc: 0.5426 - val_top5-acc: 0.9498 - lr: 0.0025\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3364 - acc: 0.5201 - top5-acc: 0.9376 - val_loss: 1.2961 - val_acc: 0.5314 - val_top5-acc: 0.9470 - lr: 0.0025\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3387 - acc: 0.5203 - top5-acc: 0.9368 - val_loss: 1.2555 - val_acc: 0.5540 - val_top5-acc: 0.9504 - lr: 0.0025\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3323 - acc: 0.5245 - top5-acc: 0.9385 - val_loss: 1.2511 - val_acc: 0.5522 - val_top5-acc: 0.9476 - lr: 0.0025\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3161 - acc: 0.5288 - top5-acc: 0.9409 - val_loss: 1.2369 - val_acc: 0.5528 - val_top5-acc: 0.9514 - lr: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3195 - acc: 0.5285 - top5-acc: 0.9404 - val_loss: 1.2347 - val_acc: 0.5582 - val_top5-acc: 0.9504 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3184 - acc: 0.5261 - top5-acc: 0.9408 - val_loss: 1.2271 - val_acc: 0.5606 - val_top5-acc: 0.9492 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3161 - acc: 0.5282 - top5-acc: 0.9401 - val_loss: 1.2348 - val_acc: 0.5590 - val_top5-acc: 0.9504 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3173 - acc: 0.5298 - top5-acc: 0.9400 - val_loss: 1.2336 - val_acc: 0.5578 - val_top5-acc: 0.9502 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3177 - acc: 0.5310 - top5-acc: 0.9397 - val_loss: 1.2365 - val_acc: 0.5600 - val_top5-acc: 0.9510 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3176 - acc: 0.5311 - top5-acc: 0.9410 - val_loss: 1.2386 - val_acc: 0.5554 - val_top5-acc: 0.9504 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3194 - acc: 0.5283 - top5-acc: 0.9405 - val_loss: 1.2392 - val_acc: 0.5510 - val_top5-acc: 0.9500 - lr: 0.0012\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3069 - acc: 0.5340 - top5-acc: 0.9414 - val_loss: 1.2295 - val_acc: 0.5626 - val_top5-acc: 0.9520 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3106 - acc: 0.5321 - top5-acc: 0.9390 - val_loss: 1.2298 - val_acc: 0.5662 - val_top5-acc: 0.9466 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3082 - acc: 0.5334 - top5-acc: 0.9409 - val_loss: 1.2285 - val_acc: 0.5588 - val_top5-acc: 0.9506 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3088 - acc: 0.5344 - top5-acc: 0.9404 - val_loss: 1.2303 - val_acc: 0.5624 - val_top5-acc: 0.9498 - lr: 6.2500e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 9s 107ms/step - loss: 1.3118 - acc: 0.5297 - top5-acc: 0.9415 - val_loss: 1.2354 - val_acc: 0.5656 - val_top5-acc: 0.9518 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 14s 44ms/step - loss: 1.2398 - acc: 0.5558 - top5-acc: 0.9500\n",
      "Test accuracy: 55.58%\n",
      "Test top 5 accuracy: 95.0%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7808 - acc: 0.3733 - top5-acc: 0.8630WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 13s 121ms/step - loss: 1.7808 - acc: 0.3733 - top5-acc: 0.8630 - val_loss: 1.5042 - val_acc: 0.4598 - val_top5-acc: 0.9178 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.5206 - acc: 0.4539 - top5-acc: 0.9155 - val_loss: 1.4641 - val_acc: 0.4760 - val_top5-acc: 0.9258 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.4719 - acc: 0.4718 - top5-acc: 0.9228 - val_loss: 1.4023 - val_acc: 0.5044 - val_top5-acc: 0.9300 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.4491 - acc: 0.4820 - top5-acc: 0.9246 - val_loss: 1.3824 - val_acc: 0.5198 - val_top5-acc: 0.9332 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.4315 - acc: 0.4857 - top5-acc: 0.9275 - val_loss: 1.3472 - val_acc: 0.5240 - val_top5-acc: 0.9368 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.4131 - acc: 0.4948 - top5-acc: 0.9291 - val_loss: 1.3808 - val_acc: 0.5110 - val_top5-acc: 0.9334 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.4064 - acc: 0.4988 - top5-acc: 0.9303 - val_loss: 1.3502 - val_acc: 0.5208 - val_top5-acc: 0.9390 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3833 - acc: 0.5047 - top5-acc: 0.9340 - val_loss: 1.3125 - val_acc: 0.5272 - val_top5-acc: 0.9426 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 1.3914 - acc: 0.5030 - top5-acc: 0.9319 - val_loss: 1.3077 - val_acc: 0.5308 - val_top5-acc: 0.9416 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 1.3792 - acc: 0.5084 - top5-acc: 0.9312 - val_loss: 1.3108 - val_acc: 0.5310 - val_top5-acc: 0.9400 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 1.3762 - acc: 0.5089 - top5-acc: 0.9334 - val_loss: 1.2933 - val_acc: 0.5380 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 1.3737 - acc: 0.5099 - top5-acc: 0.9356 - val_loss: 1.2892 - val_acc: 0.5430 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3813 - acc: 0.5052 - top5-acc: 0.9353 - val_loss: 1.3162 - val_acc: 0.5298 - val_top5-acc: 0.9436 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3697 - acc: 0.5132 - top5-acc: 0.9339 - val_loss: 1.2884 - val_acc: 0.5380 - val_top5-acc: 0.9476 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3660 - acc: 0.5116 - top5-acc: 0.9369 - val_loss: 1.3451 - val_acc: 0.5180 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3722 - acc: 0.5108 - top5-acc: 0.9353 - val_loss: 1.2806 - val_acc: 0.5474 - val_top5-acc: 0.9478 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3719 - acc: 0.5110 - top5-acc: 0.9347 - val_loss: 1.2857 - val_acc: 0.5460 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3614 - acc: 0.5155 - top5-acc: 0.9340 - val_loss: 1.2626 - val_acc: 0.5498 - val_top5-acc: 0.9488 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3633 - acc: 0.5160 - top5-acc: 0.9362 - val_loss: 1.3080 - val_acc: 0.5358 - val_top5-acc: 0.9450 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3575 - acc: 0.5133 - top5-acc: 0.9352 - val_loss: 1.2963 - val_acc: 0.5350 - val_top5-acc: 0.9456 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3633 - acc: 0.5122 - top5-acc: 0.9367 - val_loss: 1.2947 - val_acc: 0.5360 - val_top5-acc: 0.9418 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3572 - acc: 0.5150 - top5-acc: 0.9358 - val_loss: 1.2657 - val_acc: 0.5454 - val_top5-acc: 0.9520 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3681 - acc: 0.5116 - top5-acc: 0.9342 - val_loss: 1.2824 - val_acc: 0.5374 - val_top5-acc: 0.9492 - lr: 0.0050\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3285 - acc: 0.5250 - top5-acc: 0.9395 - val_loss: 1.2392 - val_acc: 0.5610 - val_top5-acc: 0.9504 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3245 - acc: 0.5263 - top5-acc: 0.9397 - val_loss: 1.2484 - val_acc: 0.5548 - val_top5-acc: 0.9510 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3255 - acc: 0.5254 - top5-acc: 0.9383 - val_loss: 1.2511 - val_acc: 0.5538 - val_top5-acc: 0.9470 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3317 - acc: 0.5243 - top5-acc: 0.9390 - val_loss: 1.2589 - val_acc: 0.5496 - val_top5-acc: 0.9490 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3275 - acc: 0.5247 - top5-acc: 0.9404 - val_loss: 1.2354 - val_acc: 0.5608 - val_top5-acc: 0.9520 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3335 - acc: 0.5248 - top5-acc: 0.9386 - val_loss: 1.2490 - val_acc: 0.5504 - val_top5-acc: 0.9490 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3212 - acc: 0.5255 - top5-acc: 0.9398 - val_loss: 1.2425 - val_acc: 0.5556 - val_top5-acc: 0.9510 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3261 - acc: 0.5280 - top5-acc: 0.9388 - val_loss: 1.2649 - val_acc: 0.5464 - val_top5-acc: 0.9504 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3277 - acc: 0.5260 - top5-acc: 0.9391 - val_loss: 1.2581 - val_acc: 0.5618 - val_top5-acc: 0.9500 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3297 - acc: 0.5229 - top5-acc: 0.9395 - val_loss: 1.2514 - val_acc: 0.5508 - val_top5-acc: 0.9500 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3112 - acc: 0.5347 - top5-acc: 0.9394 - val_loss: 1.2462 - val_acc: 0.5544 - val_top5-acc: 0.9512 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3142 - acc: 0.5312 - top5-acc: 0.9405 - val_loss: 1.2399 - val_acc: 0.5510 - val_top5-acc: 0.9510 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3132 - acc: 0.5312 - top5-acc: 0.9397 - val_loss: 1.2348 - val_acc: 0.5602 - val_top5-acc: 0.9532 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3147 - acc: 0.5300 - top5-acc: 0.9398 - val_loss: 1.2346 - val_acc: 0.5592 - val_top5-acc: 0.9506 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3126 - acc: 0.5285 - top5-acc: 0.9409 - val_loss: 1.2404 - val_acc: 0.5554 - val_top5-acc: 0.9512 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3115 - acc: 0.5326 - top5-acc: 0.9402 - val_loss: 1.2331 - val_acc: 0.5610 - val_top5-acc: 0.9534 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3161 - acc: 0.5305 - top5-acc: 0.9400 - val_loss: 1.2354 - val_acc: 0.5608 - val_top5-acc: 0.9536 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3143 - acc: 0.5316 - top5-acc: 0.9412 - val_loss: 1.2464 - val_acc: 0.5560 - val_top5-acc: 0.9524 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3140 - acc: 0.5327 - top5-acc: 0.9392 - val_loss: 1.2331 - val_acc: 0.5606 - val_top5-acc: 0.9508 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3134 - acc: 0.5300 - top5-acc: 0.9402 - val_loss: 1.2392 - val_acc: 0.5576 - val_top5-acc: 0.9486 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3122 - acc: 0.5310 - top5-acc: 0.9410 - val_loss: 1.2286 - val_acc: 0.5642 - val_top5-acc: 0.9514 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3149 - acc: 0.5327 - top5-acc: 0.9400 - val_loss: 1.2405 - val_acc: 0.5570 - val_top5-acc: 0.9516 - lr: 0.0012\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 10s 113ms/step - loss: 1.3095 - acc: 0.5310 - top5-acc: 0.9410 - val_loss: 1.2467 - val_acc: 0.5580 - val_top5-acc: 0.9518 - lr: 0.0012\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3153 - acc: 0.5325 - top5-acc: 0.9395 - val_loss: 1.2411 - val_acc: 0.5532 - val_top5-acc: 0.9516 - lr: 0.0012\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 10s 114ms/step - loss: 1.3086 - acc: 0.5326 - top5-acc: 0.9404 - val_loss: 1.2452 - val_acc: 0.5536 - val_top5-acc: 0.9498 - lr: 0.0012\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 1.3123 - acc: 0.5321 - top5-acc: 0.9415 - val_loss: 1.2323 - val_acc: 0.5606 - val_top5-acc: 0.9508 - lr: 0.0012\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 10s 115ms/step - loss: 1.3050 - acc: 0.5330 - top5-acc: 0.9420 - val_loss: 1.2319 - val_acc: 0.5640 - val_top5-acc: 0.9520 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 15s 49ms/step - loss: 1.2383 - acc: 0.5556 - top5-acc: 0.9507\n",
      "Test accuracy: 55.56%\n",
      "Test top 5 accuracy: 95.07%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8196 - acc: 0.3668 - top5-acc: 0.8555WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 14s 131ms/step - loss: 1.8196 - acc: 0.3668 - top5-acc: 0.8555 - val_loss: 1.4807 - val_acc: 0.4648 - val_top5-acc: 0.9152 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.5235 - acc: 0.4566 - top5-acc: 0.9135 - val_loss: 1.4045 - val_acc: 0.5000 - val_top5-acc: 0.9278 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.4628 - acc: 0.4762 - top5-acc: 0.9240 - val_loss: 1.3733 - val_acc: 0.5064 - val_top5-acc: 0.9336 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.4364 - acc: 0.4840 - top5-acc: 0.9278 - val_loss: 1.3742 - val_acc: 0.5020 - val_top5-acc: 0.9354 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.4254 - acc: 0.4896 - top5-acc: 0.9294 - val_loss: 1.3271 - val_acc: 0.5246 - val_top5-acc: 0.9390 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.4010 - acc: 0.5009 - top5-acc: 0.9302 - val_loss: 1.3289 - val_acc: 0.5326 - val_top5-acc: 0.9366 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.4036 - acc: 0.5024 - top5-acc: 0.9318 - val_loss: 1.3085 - val_acc: 0.5348 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3955 - acc: 0.5022 - top5-acc: 0.9309 - val_loss: 1.3516 - val_acc: 0.5224 - val_top5-acc: 0.9412 - lr: 0.0050\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3903 - acc: 0.5034 - top5-acc: 0.9332 - val_loss: 1.3115 - val_acc: 0.5310 - val_top5-acc: 0.9410 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3832 - acc: 0.5071 - top5-acc: 0.9318 - val_loss: 1.2975 - val_acc: 0.5408 - val_top5-acc: 0.9440 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3663 - acc: 0.5126 - top5-acc: 0.9352 - val_loss: 1.3192 - val_acc: 0.5292 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3682 - acc: 0.5137 - top5-acc: 0.9356 - val_loss: 1.2911 - val_acc: 0.5400 - val_top5-acc: 0.9416 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3632 - acc: 0.5130 - top5-acc: 0.9344 - val_loss: 1.2787 - val_acc: 0.5508 - val_top5-acc: 0.9456 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3676 - acc: 0.5151 - top5-acc: 0.9344 - val_loss: 1.3257 - val_acc: 0.5296 - val_top5-acc: 0.9396 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3647 - acc: 0.5128 - top5-acc: 0.9364 - val_loss: 1.2980 - val_acc: 0.5416 - val_top5-acc: 0.9424 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3605 - acc: 0.5165 - top5-acc: 0.9353 - val_loss: 1.2896 - val_acc: 0.5370 - val_top5-acc: 0.9428 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3590 - acc: 0.5161 - top5-acc: 0.9370 - val_loss: 1.2681 - val_acc: 0.5496 - val_top5-acc: 0.9476 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3571 - acc: 0.5149 - top5-acc: 0.9359 - val_loss: 1.2619 - val_acc: 0.5526 - val_top5-acc: 0.9434 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3634 - acc: 0.5130 - top5-acc: 0.9372 - val_loss: 1.3214 - val_acc: 0.5278 - val_top5-acc: 0.9426 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3677 - acc: 0.5122 - top5-acc: 0.9358 - val_loss: 1.2658 - val_acc: 0.5450 - val_top5-acc: 0.9496 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3605 - acc: 0.5153 - top5-acc: 0.9345 - val_loss: 1.2791 - val_acc: 0.5534 - val_top5-acc: 0.9466 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 1.3622 - acc: 0.5156 - top5-acc: 0.9358 - val_loss: 1.2640 - val_acc: 0.5440 - val_top5-acc: 0.9478 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3613 - acc: 0.5163 - top5-acc: 0.9354 - val_loss: 1.3067 - val_acc: 0.5316 - val_top5-acc: 0.9446 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3308 - acc: 0.5226 - top5-acc: 0.9386 - val_loss: 1.2391 - val_acc: 0.5606 - val_top5-acc: 0.9484 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3224 - acc: 0.5266 - top5-acc: 0.9378 - val_loss: 1.2553 - val_acc: 0.5554 - val_top5-acc: 0.9496 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3239 - acc: 0.5253 - top5-acc: 0.9394 - val_loss: 1.2412 - val_acc: 0.5590 - val_top5-acc: 0.9510 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3220 - acc: 0.5291 - top5-acc: 0.9399 - val_loss: 1.2382 - val_acc: 0.5560 - val_top5-acc: 0.9526 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3214 - acc: 0.5299 - top5-acc: 0.9394 - val_loss: 1.2329 - val_acc: 0.5586 - val_top5-acc: 0.9492 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3222 - acc: 0.5267 - top5-acc: 0.9405 - val_loss: 1.2542 - val_acc: 0.5504 - val_top5-acc: 0.9514 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3208 - acc: 0.5284 - top5-acc: 0.9382 - val_loss: 1.2370 - val_acc: 0.5574 - val_top5-acc: 0.9512 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3262 - acc: 0.5245 - top5-acc: 0.9397 - val_loss: 1.2434 - val_acc: 0.5512 - val_top5-acc: 0.9512 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3221 - acc: 0.5268 - top5-acc: 0.9396 - val_loss: 1.2357 - val_acc: 0.5642 - val_top5-acc: 0.9498 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3249 - acc: 0.5280 - top5-acc: 0.9393 - val_loss: 1.2358 - val_acc: 0.5584 - val_top5-acc: 0.9490 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3123 - acc: 0.5283 - top5-acc: 0.9417 - val_loss: 1.2312 - val_acc: 0.5624 - val_top5-acc: 0.9536 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3080 - acc: 0.5352 - top5-acc: 0.9396 - val_loss: 1.2263 - val_acc: 0.5626 - val_top5-acc: 0.9512 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3097 - acc: 0.5318 - top5-acc: 0.9414 - val_loss: 1.2365 - val_acc: 0.5610 - val_top5-acc: 0.9516 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3045 - acc: 0.5352 - top5-acc: 0.9416 - val_loss: 1.2199 - val_acc: 0.5678 - val_top5-acc: 0.9520 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3044 - acc: 0.5338 - top5-acc: 0.9413 - val_loss: 1.2286 - val_acc: 0.5632 - val_top5-acc: 0.9524 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3098 - acc: 0.5333 - top5-acc: 0.9399 - val_loss: 1.2224 - val_acc: 0.5670 - val_top5-acc: 0.9520 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3090 - acc: 0.5306 - top5-acc: 0.9403 - val_loss: 1.2241 - val_acc: 0.5642 - val_top5-acc: 0.9522 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3060 - acc: 0.5338 - top5-acc: 0.9406 - val_loss: 1.2226 - val_acc: 0.5670 - val_top5-acc: 0.9508 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 11s 122ms/step - loss: 1.3102 - acc: 0.5314 - top5-acc: 0.9415 - val_loss: 1.2236 - val_acc: 0.5664 - val_top5-acc: 0.9510 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.2994 - acc: 0.5350 - top5-acc: 0.9413 - val_loss: 1.2234 - val_acc: 0.5672 - val_top5-acc: 0.9526 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 11s 124ms/step - loss: 1.3031 - acc: 0.5331 - top5-acc: 0.9421 - val_loss: 1.2299 - val_acc: 0.5672 - val_top5-acc: 0.9504 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3006 - acc: 0.5376 - top5-acc: 0.9413 - val_loss: 1.2291 - val_acc: 0.5634 - val_top5-acc: 0.9510 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3019 - acc: 0.5352 - top5-acc: 0.9410 - val_loss: 1.2284 - val_acc: 0.5656 - val_top5-acc: 0.9522 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.2968 - acc: 0.5373 - top5-acc: 0.9420 - val_loss: 1.2275 - val_acc: 0.5650 - val_top5-acc: 0.9530 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.3000 - acc: 0.5397 - top5-acc: 0.9421 - val_loss: 1.2211 - val_acc: 0.5706 - val_top5-acc: 0.9514 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.2987 - acc: 0.5370 - top5-acc: 0.9414 - val_loss: 1.2264 - val_acc: 0.5664 - val_top5-acc: 0.9526 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 11s 123ms/step - loss: 1.2950 - acc: 0.5420 - top5-acc: 0.9434 - val_loss: 1.2237 - val_acc: 0.5670 - val_top5-acc: 0.9528 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 17s 54ms/step - loss: 1.2260 - acc: 0.5634 - top5-acc: 0.9520\n",
      "Test accuracy: 56.34%\n",
      "Test top 5 accuracy: 95.2%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7706 - acc: 0.3799 - top5-acc: 0.8641WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 14s 139ms/step - loss: 1.7706 - acc: 0.3799 - top5-acc: 0.8641 - val_loss: 1.4598 - val_acc: 0.4838 - val_top5-acc: 0.9224 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.5040 - acc: 0.4636 - top5-acc: 0.9163 - val_loss: 1.4351 - val_acc: 0.4846 - val_top5-acc: 0.9298 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.4539 - acc: 0.4806 - top5-acc: 0.9258 - val_loss: 1.3741 - val_acc: 0.5146 - val_top5-acc: 0.9338 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.4243 - acc: 0.4934 - top5-acc: 0.9285 - val_loss: 1.3426 - val_acc: 0.5136 - val_top5-acc: 0.9430 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3981 - acc: 0.5022 - top5-acc: 0.9315 - val_loss: 1.3148 - val_acc: 0.5366 - val_top5-acc: 0.9398 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.3890 - acc: 0.5055 - top5-acc: 0.9334 - val_loss: 1.3024 - val_acc: 0.5362 - val_top5-acc: 0.9468 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3752 - acc: 0.5118 - top5-acc: 0.9340 - val_loss: 1.2941 - val_acc: 0.5412 - val_top5-acc: 0.9454 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3623 - acc: 0.5138 - top5-acc: 0.9372 - val_loss: 1.3406 - val_acc: 0.5296 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3658 - acc: 0.5149 - top5-acc: 0.9368 - val_loss: 1.2714 - val_acc: 0.5556 - val_top5-acc: 0.9438 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 11s 131ms/step - loss: 1.3520 - acc: 0.5144 - top5-acc: 0.9378 - val_loss: 1.2796 - val_acc: 0.5484 - val_top5-acc: 0.9426 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3617 - acc: 0.5193 - top5-acc: 0.9358 - val_loss: 1.3229 - val_acc: 0.5376 - val_top5-acc: 0.9430 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3623 - acc: 0.5141 - top5-acc: 0.9359 - val_loss: 1.3019 - val_acc: 0.5330 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.3464 - acc: 0.5184 - top5-acc: 0.9378 - val_loss: 1.2670 - val_acc: 0.5532 - val_top5-acc: 0.9500 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.3521 - acc: 0.5169 - top5-acc: 0.9359 - val_loss: 1.2804 - val_acc: 0.5470 - val_top5-acc: 0.9482 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.3447 - acc: 0.5216 - top5-acc: 0.9364 - val_loss: 1.2490 - val_acc: 0.5520 - val_top5-acc: 0.9500 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3417 - acc: 0.5225 - top5-acc: 0.9378 - val_loss: 1.3065 - val_acc: 0.5334 - val_top5-acc: 0.9490 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3460 - acc: 0.5209 - top5-acc: 0.9374 - val_loss: 1.2656 - val_acc: 0.5528 - val_top5-acc: 0.9496 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3397 - acc: 0.5257 - top5-acc: 0.9384 - val_loss: 1.2663 - val_acc: 0.5488 - val_top5-acc: 0.9480 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3358 - acc: 0.5239 - top5-acc: 0.9394 - val_loss: 1.2730 - val_acc: 0.5422 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3350 - acc: 0.5252 - top5-acc: 0.9403 - val_loss: 1.2611 - val_acc: 0.5536 - val_top5-acc: 0.9474 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.3076 - acc: 0.5330 - top5-acc: 0.9419 - val_loss: 1.2345 - val_acc: 0.5588 - val_top5-acc: 0.9490 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3107 - acc: 0.5337 - top5-acc: 0.9400 - val_loss: 1.2257 - val_acc: 0.5722 - val_top5-acc: 0.9504 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3077 - acc: 0.5316 - top5-acc: 0.9411 - val_loss: 1.2389 - val_acc: 0.5590 - val_top5-acc: 0.9504 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 12s 132ms/step - loss: 1.3051 - acc: 0.5350 - top5-acc: 0.9403 - val_loss: 1.2237 - val_acc: 0.5702 - val_top5-acc: 0.9498 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3073 - acc: 0.5352 - top5-acc: 0.9410 - val_loss: 1.2385 - val_acc: 0.5608 - val_top5-acc: 0.9480 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3039 - acc: 0.5363 - top5-acc: 0.9416 - val_loss: 1.2289 - val_acc: 0.5692 - val_top5-acc: 0.9538 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.3137 - acc: 0.5321 - top5-acc: 0.9426 - val_loss: 1.2341 - val_acc: 0.5660 - val_top5-acc: 0.9504 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.3031 - acc: 0.5363 - top5-acc: 0.9405 - val_loss: 1.2289 - val_acc: 0.5622 - val_top5-acc: 0.9528 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.3142 - acc: 0.5295 - top5-acc: 0.9408 - val_loss: 1.2337 - val_acc: 0.5610 - val_top5-acc: 0.9526 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.2940 - acc: 0.5398 - top5-acc: 0.9421 - val_loss: 1.2134 - val_acc: 0.5746 - val_top5-acc: 0.9544 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2888 - acc: 0.5426 - top5-acc: 0.9417 - val_loss: 1.2158 - val_acc: 0.5708 - val_top5-acc: 0.9514 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.2887 - acc: 0.5388 - top5-acc: 0.9426 - val_loss: 1.2192 - val_acc: 0.5676 - val_top5-acc: 0.9538 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.2953 - acc: 0.5392 - top5-acc: 0.9431 - val_loss: 1.2196 - val_acc: 0.5750 - val_top5-acc: 0.9526 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 11s 131ms/step - loss: 1.2947 - acc: 0.5391 - top5-acc: 0.9433 - val_loss: 1.2233 - val_acc: 0.5684 - val_top5-acc: 0.9530 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2902 - acc: 0.5374 - top5-acc: 0.9434 - val_loss: 1.2253 - val_acc: 0.5646 - val_top5-acc: 0.9546 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.2867 - acc: 0.5418 - top5-acc: 0.9424 - val_loss: 1.2155 - val_acc: 0.5690 - val_top5-acc: 0.9524 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 12s 131ms/step - loss: 1.2825 - acc: 0.5455 - top5-acc: 0.9435 - val_loss: 1.2217 - val_acc: 0.5704 - val_top5-acc: 0.9494 - lr: 6.2500e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2869 - acc: 0.5410 - top5-acc: 0.9440 - val_loss: 1.2190 - val_acc: 0.5716 - val_top5-acc: 0.9536 - lr: 6.2500e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2839 - acc: 0.5422 - top5-acc: 0.9435 - val_loss: 1.2120 - val_acc: 0.5706 - val_top5-acc: 0.9520 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2840 - acc: 0.5426 - top5-acc: 0.9424 - val_loss: 1.2144 - val_acc: 0.5714 - val_top5-acc: 0.9546 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2887 - acc: 0.5432 - top5-acc: 0.9421 - val_loss: 1.2164 - val_acc: 0.5710 - val_top5-acc: 0.9536 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2836 - acc: 0.5408 - top5-acc: 0.9445 - val_loss: 1.2108 - val_acc: 0.5726 - val_top5-acc: 0.9508 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2843 - acc: 0.5416 - top5-acc: 0.9425 - val_loss: 1.2123 - val_acc: 0.5740 - val_top5-acc: 0.9544 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2849 - acc: 0.5444 - top5-acc: 0.9433 - val_loss: 1.2132 - val_acc: 0.5744 - val_top5-acc: 0.9520 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2860 - acc: 0.5436 - top5-acc: 0.9427 - val_loss: 1.2170 - val_acc: 0.5728 - val_top5-acc: 0.9512 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2866 - acc: 0.5432 - top5-acc: 0.9419 - val_loss: 1.2189 - val_acc: 0.5710 - val_top5-acc: 0.9538 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2846 - acc: 0.5432 - top5-acc: 0.9431 - val_loss: 1.2226 - val_acc: 0.5684 - val_top5-acc: 0.9530 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2824 - acc: 0.5441 - top5-acc: 0.9434 - val_loss: 1.2186 - val_acc: 0.5712 - val_top5-acc: 0.9522 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2827 - acc: 0.5448 - top5-acc: 0.9438 - val_loss: 1.2160 - val_acc: 0.5710 - val_top5-acc: 0.9534 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 11s 130ms/step - loss: 1.2825 - acc: 0.5428 - top5-acc: 0.9432 - val_loss: 1.2229 - val_acc: 0.5708 - val_top5-acc: 0.9522 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 18s 59ms/step - loss: 1.2244 - acc: 0.5608 - top5-acc: 0.9513\n",
      "Test accuracy: 56.08%\n",
      "Test top 5 accuracy: 95.13%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8010 - acc: 0.3740 - top5-acc: 0.8637WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 15s 148ms/step - loss: 1.8010 - acc: 0.3740 - top5-acc: 0.8637 - val_loss: 1.4567 - val_acc: 0.4800 - val_top5-acc: 0.9238 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.4910 - acc: 0.4652 - top5-acc: 0.9180 - val_loss: 1.4015 - val_acc: 0.5090 - val_top5-acc: 0.9326 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.4421 - acc: 0.4824 - top5-acc: 0.9270 - val_loss: 1.3459 - val_acc: 0.5208 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.4089 - acc: 0.4959 - top5-acc: 0.9311 - val_loss: 1.3395 - val_acc: 0.5286 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.3904 - acc: 0.5026 - top5-acc: 0.9332 - val_loss: 1.3494 - val_acc: 0.5314 - val_top5-acc: 0.9350 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3826 - acc: 0.5045 - top5-acc: 0.9327 - val_loss: 1.3193 - val_acc: 0.5278 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3716 - acc: 0.5117 - top5-acc: 0.9339 - val_loss: 1.2784 - val_acc: 0.5524 - val_top5-acc: 0.9456 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3647 - acc: 0.5128 - top5-acc: 0.9340 - val_loss: 1.2911 - val_acc: 0.5396 - val_top5-acc: 0.9468 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.3540 - acc: 0.5170 - top5-acc: 0.9368 - val_loss: 1.3117 - val_acc: 0.5258 - val_top5-acc: 0.9438 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3458 - acc: 0.5168 - top5-acc: 0.9388 - val_loss: 1.2984 - val_acc: 0.5350 - val_top5-acc: 0.9458 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3542 - acc: 0.5167 - top5-acc: 0.9365 - val_loss: 1.2918 - val_acc: 0.5452 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3500 - acc: 0.5192 - top5-acc: 0.9371 - val_loss: 1.2659 - val_acc: 0.5514 - val_top5-acc: 0.9466 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.3395 - acc: 0.5224 - top5-acc: 0.9394 - val_loss: 1.2549 - val_acc: 0.5556 - val_top5-acc: 0.9488 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.3362 - acc: 0.5217 - top5-acc: 0.9389 - val_loss: 1.2471 - val_acc: 0.5604 - val_top5-acc: 0.9490 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3304 - acc: 0.5251 - top5-acc: 0.9379 - val_loss: 1.2541 - val_acc: 0.5608 - val_top5-acc: 0.9476 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.3389 - acc: 0.5216 - top5-acc: 0.9392 - val_loss: 1.2593 - val_acc: 0.5548 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.3394 - acc: 0.5230 - top5-acc: 0.9382 - val_loss: 1.2410 - val_acc: 0.5608 - val_top5-acc: 0.9488 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.3361 - acc: 0.5230 - top5-acc: 0.9386 - val_loss: 1.2707 - val_acc: 0.5506 - val_top5-acc: 0.9498 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.3240 - acc: 0.5253 - top5-acc: 0.9393 - val_loss: 1.2691 - val_acc: 0.5456 - val_top5-acc: 0.9512 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3362 - acc: 0.5266 - top5-acc: 0.9398 - val_loss: 1.2563 - val_acc: 0.5604 - val_top5-acc: 0.9492 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3280 - acc: 0.5295 - top5-acc: 0.9387 - val_loss: 1.2715 - val_acc: 0.5420 - val_top5-acc: 0.9486 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.3361 - acc: 0.5242 - top5-acc: 0.9400 - val_loss: 1.2650 - val_acc: 0.5452 - val_top5-acc: 0.9518 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2966 - acc: 0.5392 - top5-acc: 0.9416 - val_loss: 1.2152 - val_acc: 0.5718 - val_top5-acc: 0.9530 - lr: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2960 - acc: 0.5378 - top5-acc: 0.9423 - val_loss: 1.2188 - val_acc: 0.5714 - val_top5-acc: 0.9542 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2990 - acc: 0.5353 - top5-acc: 0.9418 - val_loss: 1.2231 - val_acc: 0.5676 - val_top5-acc: 0.9512 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2983 - acc: 0.5386 - top5-acc: 0.9410 - val_loss: 1.2210 - val_acc: 0.5660 - val_top5-acc: 0.9508 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2961 - acc: 0.5360 - top5-acc: 0.9422 - val_loss: 1.2193 - val_acc: 0.5640 - val_top5-acc: 0.9520 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2982 - acc: 0.5358 - top5-acc: 0.9425 - val_loss: 1.2217 - val_acc: 0.5688 - val_top5-acc: 0.9508 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2833 - acc: 0.5403 - top5-acc: 0.9432 - val_loss: 1.2074 - val_acc: 0.5702 - val_top5-acc: 0.9528 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2868 - acc: 0.5380 - top5-acc: 0.9430 - val_loss: 1.2067 - val_acc: 0.5762 - val_top5-acc: 0.9530 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2824 - acc: 0.5455 - top5-acc: 0.9448 - val_loss: 1.2112 - val_acc: 0.5706 - val_top5-acc: 0.9532 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2846 - acc: 0.5428 - top5-acc: 0.9414 - val_loss: 1.2160 - val_acc: 0.5688 - val_top5-acc: 0.9526 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2869 - acc: 0.5383 - top5-acc: 0.9433 - val_loss: 1.2031 - val_acc: 0.5712 - val_top5-acc: 0.9538 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2883 - acc: 0.5419 - top5-acc: 0.9426 - val_loss: 1.2115 - val_acc: 0.5728 - val_top5-acc: 0.9534 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2851 - acc: 0.5426 - top5-acc: 0.9424 - val_loss: 1.2103 - val_acc: 0.5682 - val_top5-acc: 0.9520 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2826 - acc: 0.5436 - top5-acc: 0.9430 - val_loss: 1.2157 - val_acc: 0.5688 - val_top5-acc: 0.9520 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2861 - acc: 0.5397 - top5-acc: 0.9438 - val_loss: 1.2167 - val_acc: 0.5740 - val_top5-acc: 0.9524 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2785 - acc: 0.5426 - top5-acc: 0.9438 - val_loss: 1.2082 - val_acc: 0.5722 - val_top5-acc: 0.9528 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2791 - acc: 0.5443 - top5-acc: 0.9440 - val_loss: 1.2086 - val_acc: 0.5758 - val_top5-acc: 0.9532 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2793 - acc: 0.5432 - top5-acc: 0.9445 - val_loss: 1.2111 - val_acc: 0.5702 - val_top5-acc: 0.9520 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2778 - acc: 0.5460 - top5-acc: 0.9449 - val_loss: 1.2116 - val_acc: 0.5732 - val_top5-acc: 0.9518 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2812 - acc: 0.5424 - top5-acc: 0.9438 - val_loss: 1.2057 - val_acc: 0.5740 - val_top5-acc: 0.9548 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2816 - acc: 0.5433 - top5-acc: 0.9441 - val_loss: 1.2014 - val_acc: 0.5752 - val_top5-acc: 0.9544 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2797 - acc: 0.5459 - top5-acc: 0.9445 - val_loss: 1.2021 - val_acc: 0.5786 - val_top5-acc: 0.9546 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2834 - acc: 0.5435 - top5-acc: 0.9428 - val_loss: 1.2255 - val_acc: 0.5658 - val_top5-acc: 0.9516 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 12s 138ms/step - loss: 1.2760 - acc: 0.5461 - top5-acc: 0.9444 - val_loss: 1.2093 - val_acc: 0.5802 - val_top5-acc: 0.9514 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2815 - acc: 0.5424 - top5-acc: 0.9429 - val_loss: 1.2143 - val_acc: 0.5748 - val_top5-acc: 0.9518 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2800 - acc: 0.5443 - top5-acc: 0.9445 - val_loss: 1.2173 - val_acc: 0.5728 - val_top5-acc: 0.9514 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 12s 140ms/step - loss: 1.2824 - acc: 0.5412 - top5-acc: 0.9429 - val_loss: 1.2046 - val_acc: 0.5780 - val_top5-acc: 0.9536 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 12s 139ms/step - loss: 1.2760 - acc: 0.5463 - top5-acc: 0.9443 - val_loss: 1.2069 - val_acc: 0.5788 - val_top5-acc: 0.9534 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 20s 63ms/step - loss: 1.2150 - acc: 0.5650 - top5-acc: 0.9527\n",
      "Test accuracy: 56.5%\n",
      "Test top 5 accuracy: 95.27%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7677 - acc: 0.3797 - top5-acc: 0.8647WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 16s 156ms/step - loss: 1.7677 - acc: 0.3797 - top5-acc: 0.8647 - val_loss: 1.4589 - val_acc: 0.4694 - val_top5-acc: 0.9284 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.4895 - acc: 0.4695 - top5-acc: 0.9188 - val_loss: 1.4148 - val_acc: 0.4914 - val_top5-acc: 0.9278 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.4413 - acc: 0.4830 - top5-acc: 0.9274 - val_loss: 1.3304 - val_acc: 0.5266 - val_top5-acc: 0.9420 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.4112 - acc: 0.4962 - top5-acc: 0.9303 - val_loss: 1.3421 - val_acc: 0.5214 - val_top5-acc: 0.9380 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3817 - acc: 0.5068 - top5-acc: 0.9332 - val_loss: 1.3524 - val_acc: 0.5094 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3687 - acc: 0.5127 - top5-acc: 0.9333 - val_loss: 1.3103 - val_acc: 0.5268 - val_top5-acc: 0.9446 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3667 - acc: 0.5110 - top5-acc: 0.9342 - val_loss: 1.2584 - val_acc: 0.5544 - val_top5-acc: 0.9502 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3502 - acc: 0.5171 - top5-acc: 0.9380 - val_loss: 1.2555 - val_acc: 0.5612 - val_top5-acc: 0.9496 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3513 - acc: 0.5179 - top5-acc: 0.9374 - val_loss: 1.2773 - val_acc: 0.5432 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3467 - acc: 0.5198 - top5-acc: 0.9364 - val_loss: 1.3091 - val_acc: 0.5350 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3431 - acc: 0.5225 - top5-acc: 0.9379 - val_loss: 1.2848 - val_acc: 0.5402 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3336 - acc: 0.5247 - top5-acc: 0.9370 - val_loss: 1.2521 - val_acc: 0.5560 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 1.3286 - acc: 0.5263 - top5-acc: 0.9388 - val_loss: 1.2816 - val_acc: 0.5352 - val_top5-acc: 0.9428 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 1.3328 - acc: 0.5242 - top5-acc: 0.9392 - val_loss: 1.2687 - val_acc: 0.5478 - val_top5-acc: 0.9484 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3201 - acc: 0.5290 - top5-acc: 0.9393 - val_loss: 1.2899 - val_acc: 0.5334 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3285 - acc: 0.5279 - top5-acc: 0.9394 - val_loss: 1.2475 - val_acc: 0.5576 - val_top5-acc: 0.9474 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3196 - acc: 0.5279 - top5-acc: 0.9408 - val_loss: 1.2561 - val_acc: 0.5502 - val_top5-acc: 0.9474 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3259 - acc: 0.5290 - top5-acc: 0.9396 - val_loss: 1.2543 - val_acc: 0.5608 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3196 - acc: 0.5294 - top5-acc: 0.9401 - val_loss: 1.2359 - val_acc: 0.5688 - val_top5-acc: 0.9502 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3158 - acc: 0.5323 - top5-acc: 0.9397 - val_loss: 1.2525 - val_acc: 0.5540 - val_top5-acc: 0.9466 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 1.3141 - acc: 0.5323 - top5-acc: 0.9414 - val_loss: 1.2418 - val_acc: 0.5592 - val_top5-acc: 0.9512 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 1.3219 - acc: 0.5305 - top5-acc: 0.9394 - val_loss: 1.2492 - val_acc: 0.5562 - val_top5-acc: 0.9496 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.3186 - acc: 0.5290 - top5-acc: 0.9412 - val_loss: 1.2238 - val_acc: 0.5640 - val_top5-acc: 0.9508 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3236 - acc: 0.5272 - top5-acc: 0.9402 - val_loss: 1.2691 - val_acc: 0.5422 - val_top5-acc: 0.9472 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3179 - acc: 0.5310 - top5-acc: 0.9416 - val_loss: 1.2421 - val_acc: 0.5576 - val_top5-acc: 0.9482 - lr: 0.0050\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3120 - acc: 0.5346 - top5-acc: 0.9408 - val_loss: 1.2108 - val_acc: 0.5720 - val_top5-acc: 0.9508 - lr: 0.0050\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3139 - acc: 0.5318 - top5-acc: 0.9403 - val_loss: 1.2403 - val_acc: 0.5528 - val_top5-acc: 0.9512 - lr: 0.0050\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3122 - acc: 0.5324 - top5-acc: 0.9418 - val_loss: 1.2175 - val_acc: 0.5702 - val_top5-acc: 0.9518 - lr: 0.0050\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3042 - acc: 0.5388 - top5-acc: 0.9423 - val_loss: 1.2398 - val_acc: 0.5590 - val_top5-acc: 0.9538 - lr: 0.0050\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3135 - acc: 0.5320 - top5-acc: 0.9414 - val_loss: 1.2188 - val_acc: 0.5670 - val_top5-acc: 0.9544 - lr: 0.0050\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3132 - acc: 0.5340 - top5-acc: 0.9405 - val_loss: 1.2031 - val_acc: 0.5732 - val_top5-acc: 0.9526 - lr: 0.0050\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3099 - acc: 0.5338 - top5-acc: 0.9423 - val_loss: 1.2390 - val_acc: 0.5620 - val_top5-acc: 0.9472 - lr: 0.0050\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3103 - acc: 0.5363 - top5-acc: 0.9408 - val_loss: 1.2202 - val_acc: 0.5688 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3143 - acc: 0.5322 - top5-acc: 0.9423 - val_loss: 1.2120 - val_acc: 0.5726 - val_top5-acc: 0.9540 - lr: 0.0050\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3066 - acc: 0.5317 - top5-acc: 0.9427 - val_loss: 1.2181 - val_acc: 0.5694 - val_top5-acc: 0.9512 - lr: 0.0050\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.3070 - acc: 0.5344 - top5-acc: 0.9424 - val_loss: 1.2347 - val_acc: 0.5584 - val_top5-acc: 0.9506 - lr: 0.0050\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 13s 148ms/step - loss: 1.2773 - acc: 0.5451 - top5-acc: 0.9455 - val_loss: 1.2244 - val_acc: 0.5710 - val_top5-acc: 0.9508 - lr: 0.0025\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2840 - acc: 0.5392 - top5-acc: 0.9438 - val_loss: 1.1936 - val_acc: 0.5796 - val_top5-acc: 0.9538 - lr: 0.0025\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2751 - acc: 0.5453 - top5-acc: 0.9445 - val_loss: 1.1945 - val_acc: 0.5766 - val_top5-acc: 0.9564 - lr: 0.0025\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 13s 145ms/step - loss: 1.2850 - acc: 0.5437 - top5-acc: 0.9423 - val_loss: 1.2181 - val_acc: 0.5618 - val_top5-acc: 0.9540 - lr: 0.0025\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 1.2813 - acc: 0.5432 - top5-acc: 0.9438 - val_loss: 1.2118 - val_acc: 0.5636 - val_top5-acc: 0.9544 - lr: 0.0025\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2743 - acc: 0.5436 - top5-acc: 0.9445 - val_loss: 1.1987 - val_acc: 0.5760 - val_top5-acc: 0.9518 - lr: 0.0025\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2775 - acc: 0.5438 - top5-acc: 0.9449 - val_loss: 1.2008 - val_acc: 0.5710 - val_top5-acc: 0.9544 - lr: 0.0025\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2683 - acc: 0.5467 - top5-acc: 0.9447 - val_loss: 1.1887 - val_acc: 0.5820 - val_top5-acc: 0.9568 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2665 - acc: 0.5496 - top5-acc: 0.9446 - val_loss: 1.1907 - val_acc: 0.5822 - val_top5-acc: 0.9552 - lr: 0.0012\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2685 - acc: 0.5458 - top5-acc: 0.9461 - val_loss: 1.1997 - val_acc: 0.5754 - val_top5-acc: 0.9510 - lr: 0.0012\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2665 - acc: 0.5483 - top5-acc: 0.9453 - val_loss: 1.1996 - val_acc: 0.5752 - val_top5-acc: 0.9524 - lr: 0.0012\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 13s 145ms/step - loss: 1.2699 - acc: 0.5482 - top5-acc: 0.9442 - val_loss: 1.1942 - val_acc: 0.5794 - val_top5-acc: 0.9532 - lr: 0.0012\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 13s 146ms/step - loss: 1.2676 - acc: 0.5490 - top5-acc: 0.9449 - val_loss: 1.2055 - val_acc: 0.5738 - val_top5-acc: 0.9534 - lr: 0.0012\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 13s 147ms/step - loss: 1.2600 - acc: 0.5495 - top5-acc: 0.9463 - val_loss: 1.1878 - val_acc: 0.5788 - val_top5-acc: 0.9554 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 21s 68ms/step - loss: 1.1977 - acc: 0.5696 - top5-acc: 0.9517\n",
      "Test accuracy: 56.96%\n",
      "Test top 5 accuracy: 95.17%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7037 - acc: 0.3859 - top5-acc: 0.8776WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 17s 165ms/step - loss: 1.7037 - acc: 0.3859 - top5-acc: 0.8776 - val_loss: 1.4436 - val_acc: 0.4798 - val_top5-acc: 0.9262 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 13s 153ms/step - loss: 1.4682 - acc: 0.4716 - top5-acc: 0.9228 - val_loss: 1.3762 - val_acc: 0.5036 - val_top5-acc: 0.9366 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.4175 - acc: 0.4893 - top5-acc: 0.9293 - val_loss: 1.3475 - val_acc: 0.5186 - val_top5-acc: 0.9382 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3877 - acc: 0.5046 - top5-acc: 0.9326 - val_loss: 1.3198 - val_acc: 0.5268 - val_top5-acc: 0.9402 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3716 - acc: 0.5103 - top5-acc: 0.9353 - val_loss: 1.3309 - val_acc: 0.5230 - val_top5-acc: 0.9420 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3510 - acc: 0.5173 - top5-acc: 0.9384 - val_loss: 1.3140 - val_acc: 0.5298 - val_top5-acc: 0.9416 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3499 - acc: 0.5175 - top5-acc: 0.9364 - val_loss: 1.3057 - val_acc: 0.5252 - val_top5-acc: 0.9486 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3373 - acc: 0.5235 - top5-acc: 0.9387 - val_loss: 1.2738 - val_acc: 0.5478 - val_top5-acc: 0.9450 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3336 - acc: 0.5229 - top5-acc: 0.9376 - val_loss: 1.3100 - val_acc: 0.5380 - val_top5-acc: 0.9412 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.3322 - acc: 0.5236 - top5-acc: 0.9394 - val_loss: 1.2684 - val_acc: 0.5456 - val_top5-acc: 0.9492 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3231 - acc: 0.5279 - top5-acc: 0.9394 - val_loss: 1.2850 - val_acc: 0.5442 - val_top5-acc: 0.9488 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3241 - acc: 0.5288 - top5-acc: 0.9401 - val_loss: 1.2680 - val_acc: 0.5516 - val_top5-acc: 0.9518 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3174 - acc: 0.5341 - top5-acc: 0.9416 - val_loss: 1.2303 - val_acc: 0.5604 - val_top5-acc: 0.9510 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 14s 154ms/step - loss: 1.3132 - acc: 0.5328 - top5-acc: 0.9413 - val_loss: 1.2403 - val_acc: 0.5566 - val_top5-acc: 0.9508 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3106 - acc: 0.5325 - top5-acc: 0.9414 - val_loss: 1.2415 - val_acc: 0.5616 - val_top5-acc: 0.9512 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.3054 - acc: 0.5328 - top5-acc: 0.9418 - val_loss: 1.2263 - val_acc: 0.5644 - val_top5-acc: 0.9524 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3113 - acc: 0.5342 - top5-acc: 0.9419 - val_loss: 1.2766 - val_acc: 0.5490 - val_top5-acc: 0.9522 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3037 - acc: 0.5369 - top5-acc: 0.9430 - val_loss: 1.2883 - val_acc: 0.5356 - val_top5-acc: 0.9500 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.3073 - acc: 0.5343 - top5-acc: 0.9419 - val_loss: 1.2444 - val_acc: 0.5594 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3051 - acc: 0.5344 - top5-acc: 0.9424 - val_loss: 1.2669 - val_acc: 0.5478 - val_top5-acc: 0.9488 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2892 - acc: 0.5433 - top5-acc: 0.9431 - val_loss: 1.2149 - val_acc: 0.5728 - val_top5-acc: 0.9516 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3056 - acc: 0.5381 - top5-acc: 0.9420 - val_loss: 1.2455 - val_acc: 0.5608 - val_top5-acc: 0.9538 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3168 - acc: 0.5308 - top5-acc: 0.9408 - val_loss: 1.2181 - val_acc: 0.5642 - val_top5-acc: 0.9560 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2985 - acc: 0.5370 - top5-acc: 0.9421 - val_loss: 1.2152 - val_acc: 0.5672 - val_top5-acc: 0.9516 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.3086 - acc: 0.5330 - top5-acc: 0.9422 - val_loss: 1.2546 - val_acc: 0.5554 - val_top5-acc: 0.9512 - lr: 0.0050\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2989 - acc: 0.5379 - top5-acc: 0.9419 - val_loss: 1.2488 - val_acc: 0.5560 - val_top5-acc: 0.9526 - lr: 0.0050\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2739 - acc: 0.5489 - top5-acc: 0.9439 - val_loss: 1.2140 - val_acc: 0.5654 - val_top5-acc: 0.9532 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2690 - acc: 0.5464 - top5-acc: 0.9451 - val_loss: 1.2075 - val_acc: 0.5746 - val_top5-acc: 0.9526 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 14s 154ms/step - loss: 1.2707 - acc: 0.5487 - top5-acc: 0.9449 - val_loss: 1.1954 - val_acc: 0.5784 - val_top5-acc: 0.9544 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2722 - acc: 0.5458 - top5-acc: 0.9449 - val_loss: 1.2211 - val_acc: 0.5644 - val_top5-acc: 0.9552 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2713 - acc: 0.5475 - top5-acc: 0.9444 - val_loss: 1.2083 - val_acc: 0.5704 - val_top5-acc: 0.9526 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2755 - acc: 0.5436 - top5-acc: 0.9439 - val_loss: 1.2189 - val_acc: 0.5626 - val_top5-acc: 0.9520 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2734 - acc: 0.5455 - top5-acc: 0.9451 - val_loss: 1.2007 - val_acc: 0.5766 - val_top5-acc: 0.9526 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2723 - acc: 0.5469 - top5-acc: 0.9434 - val_loss: 1.1969 - val_acc: 0.5726 - val_top5-acc: 0.9548 - lr: 0.0025\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2585 - acc: 0.5527 - top5-acc: 0.9453 - val_loss: 1.1877 - val_acc: 0.5850 - val_top5-acc: 0.9564 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2587 - acc: 0.5524 - top5-acc: 0.9461 - val_loss: 1.1874 - val_acc: 0.5794 - val_top5-acc: 0.9550 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 14s 154ms/step - loss: 1.2599 - acc: 0.5510 - top5-acc: 0.9466 - val_loss: 1.1985 - val_acc: 0.5728 - val_top5-acc: 0.9550 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2582 - acc: 0.5507 - top5-acc: 0.9456 - val_loss: 1.1985 - val_acc: 0.5756 - val_top5-acc: 0.9554 - lr: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2555 - acc: 0.5508 - top5-acc: 0.9459 - val_loss: 1.1904 - val_acc: 0.5794 - val_top5-acc: 0.9558 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2605 - acc: 0.5537 - top5-acc: 0.9446 - val_loss: 1.1809 - val_acc: 0.5872 - val_top5-acc: 0.9560 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2591 - acc: 0.5519 - top5-acc: 0.9469 - val_loss: 1.1801 - val_acc: 0.5894 - val_top5-acc: 0.9570 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2608 - acc: 0.5518 - top5-acc: 0.9462 - val_loss: 1.1924 - val_acc: 0.5826 - val_top5-acc: 0.9554 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2607 - acc: 0.5536 - top5-acc: 0.9461 - val_loss: 1.1845 - val_acc: 0.5812 - val_top5-acc: 0.9558 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2642 - acc: 0.5486 - top5-acc: 0.9450 - val_loss: 1.1994 - val_acc: 0.5798 - val_top5-acc: 0.9550 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2664 - acc: 0.5492 - top5-acc: 0.9440 - val_loss: 1.1873 - val_acc: 0.5830 - val_top5-acc: 0.9548 - lr: 0.0012\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2589 - acc: 0.5512 - top5-acc: 0.9458 - val_loss: 1.2054 - val_acc: 0.5748 - val_top5-acc: 0.9534 - lr: 0.0012\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2512 - acc: 0.5549 - top5-acc: 0.9472 - val_loss: 1.1905 - val_acc: 0.5836 - val_top5-acc: 0.9560 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2571 - acc: 0.5533 - top5-acc: 0.9457 - val_loss: 1.1803 - val_acc: 0.5848 - val_top5-acc: 0.9564 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 14s 156ms/step - loss: 1.2522 - acc: 0.5556 - top5-acc: 0.9461 - val_loss: 1.1844 - val_acc: 0.5870 - val_top5-acc: 0.9566 - lr: 6.2500e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 14s 155ms/step - loss: 1.2569 - acc: 0.5527 - top5-acc: 0.9457 - val_loss: 1.1938 - val_acc: 0.5814 - val_top5-acc: 0.9550 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 23s 72ms/step - loss: 1.2052 - acc: 0.5710 - top5-acc: 0.9519\n",
      "Test accuracy: 57.1%\n",
      "Test top 5 accuracy: 95.19%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.6875 - acc: 0.3985 - top5-acc: 0.8811WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 18s 174ms/step - loss: 1.6875 - acc: 0.3985 - top5-acc: 0.8811 - val_loss: 1.4260 - val_acc: 0.4852 - val_top5-acc: 0.9236 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 14s 165ms/step - loss: 1.4408 - acc: 0.4834 - top5-acc: 0.9255 - val_loss: 1.3341 - val_acc: 0.5306 - val_top5-acc: 0.9408 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 14s 161ms/step - loss: 1.4049 - acc: 0.4965 - top5-acc: 0.9307 - val_loss: 1.3200 - val_acc: 0.5234 - val_top5-acc: 0.9454 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3652 - acc: 0.5135 - top5-acc: 0.9356 - val_loss: 1.3055 - val_acc: 0.5378 - val_top5-acc: 0.9440 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3504 - acc: 0.5158 - top5-acc: 0.9375 - val_loss: 1.2674 - val_acc: 0.5472 - val_top5-acc: 0.9448 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3451 - acc: 0.5183 - top5-acc: 0.9374 - val_loss: 1.2643 - val_acc: 0.5496 - val_top5-acc: 0.9490 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3352 - acc: 0.5258 - top5-acc: 0.9387 - val_loss: 1.2640 - val_acc: 0.5512 - val_top5-acc: 0.9472 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.3279 - acc: 0.5282 - top5-acc: 0.9388 - val_loss: 1.2755 - val_acc: 0.5520 - val_top5-acc: 0.9466 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3162 - acc: 0.5295 - top5-acc: 0.9398 - val_loss: 1.2484 - val_acc: 0.5558 - val_top5-acc: 0.9490 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3119 - acc: 0.5318 - top5-acc: 0.9414 - val_loss: 1.2398 - val_acc: 0.5612 - val_top5-acc: 0.9518 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.3063 - acc: 0.5333 - top5-acc: 0.9432 - val_loss: 1.2335 - val_acc: 0.5632 - val_top5-acc: 0.9518 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.3004 - acc: 0.5365 - top5-acc: 0.9422 - val_loss: 1.2446 - val_acc: 0.5612 - val_top5-acc: 0.9466 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3156 - acc: 0.5329 - top5-acc: 0.9403 - val_loss: 1.2309 - val_acc: 0.5602 - val_top5-acc: 0.9526 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.3089 - acc: 0.5332 - top5-acc: 0.9424 - val_loss: 1.2475 - val_acc: 0.5448 - val_top5-acc: 0.9532 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.3021 - acc: 0.5366 - top5-acc: 0.9415 - val_loss: 1.2222 - val_acc: 0.5680 - val_top5-acc: 0.9490 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.2911 - acc: 0.5386 - top5-acc: 0.9436 - val_loss: 1.2586 - val_acc: 0.5456 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.3020 - acc: 0.5344 - top5-acc: 0.9428 - val_loss: 1.2121 - val_acc: 0.5710 - val_top5-acc: 0.9536 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.2937 - acc: 0.5356 - top5-acc: 0.9446 - val_loss: 1.2120 - val_acc: 0.5664 - val_top5-acc: 0.9486 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.2951 - acc: 0.5376 - top5-acc: 0.9446 - val_loss: 1.2095 - val_acc: 0.5750 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2901 - acc: 0.5400 - top5-acc: 0.9440 - val_loss: 1.1983 - val_acc: 0.5794 - val_top5-acc: 0.9508 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2965 - acc: 0.5388 - top5-acc: 0.9424 - val_loss: 1.2261 - val_acc: 0.5702 - val_top5-acc: 0.9548 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2925 - acc: 0.5404 - top5-acc: 0.9430 - val_loss: 1.2306 - val_acc: 0.5668 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2928 - acc: 0.5406 - top5-acc: 0.9440 - val_loss: 1.2118 - val_acc: 0.5740 - val_top5-acc: 0.9548 - lr: 0.0050\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2917 - acc: 0.5399 - top5-acc: 0.9436 - val_loss: 1.2160 - val_acc: 0.5630 - val_top5-acc: 0.9550 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2941 - acc: 0.5403 - top5-acc: 0.9427 - val_loss: 1.2527 - val_acc: 0.5492 - val_top5-acc: 0.9520 - lr: 0.0050\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2623 - acc: 0.5512 - top5-acc: 0.9461 - val_loss: 1.1950 - val_acc: 0.5718 - val_top5-acc: 0.9542 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2644 - acc: 0.5483 - top5-acc: 0.9462 - val_loss: 1.1835 - val_acc: 0.5848 - val_top5-acc: 0.9530 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2665 - acc: 0.5505 - top5-acc: 0.9454 - val_loss: 1.2074 - val_acc: 0.5656 - val_top5-acc: 0.9538 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2661 - acc: 0.5493 - top5-acc: 0.9450 - val_loss: 1.1938 - val_acc: 0.5770 - val_top5-acc: 0.9564 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2649 - acc: 0.5483 - top5-acc: 0.9481 - val_loss: 1.1744 - val_acc: 0.5918 - val_top5-acc: 0.9564 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2622 - acc: 0.5496 - top5-acc: 0.9463 - val_loss: 1.2085 - val_acc: 0.5718 - val_top5-acc: 0.9538 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2642 - acc: 0.5488 - top5-acc: 0.9457 - val_loss: 1.1837 - val_acc: 0.5846 - val_top5-acc: 0.9556 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2596 - acc: 0.5519 - top5-acc: 0.9468 - val_loss: 1.1832 - val_acc: 0.5854 - val_top5-acc: 0.9546 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2600 - acc: 0.5535 - top5-acc: 0.9459 - val_loss: 1.2037 - val_acc: 0.5752 - val_top5-acc: 0.9518 - lr: 0.0025\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.2631 - acc: 0.5484 - top5-acc: 0.9456 - val_loss: 1.1779 - val_acc: 0.5882 - val_top5-acc: 0.9552 - lr: 0.0025\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.2535 - acc: 0.5547 - top5-acc: 0.9466 - val_loss: 1.1720 - val_acc: 0.5928 - val_top5-acc: 0.9566 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2461 - acc: 0.5563 - top5-acc: 0.9474 - val_loss: 1.1817 - val_acc: 0.5852 - val_top5-acc: 0.9578 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 14s 158ms/step - loss: 1.2440 - acc: 0.5566 - top5-acc: 0.9463 - val_loss: 1.1726 - val_acc: 0.5844 - val_top5-acc: 0.9568 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2519 - acc: 0.5550 - top5-acc: 0.9465 - val_loss: 1.1700 - val_acc: 0.5886 - val_top5-acc: 0.9580 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 14s 157ms/step - loss: 1.2494 - acc: 0.5545 - top5-acc: 0.9463 - val_loss: 1.1760 - val_acc: 0.5888 - val_top5-acc: 0.9558 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2453 - acc: 0.5546 - top5-acc: 0.9486 - val_loss: 1.1845 - val_acc: 0.5836 - val_top5-acc: 0.9542 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2475 - acc: 0.5576 - top5-acc: 0.9476 - val_loss: 1.1821 - val_acc: 0.5864 - val_top5-acc: 0.9556 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.2544 - acc: 0.5530 - top5-acc: 0.9474 - val_loss: 1.1882 - val_acc: 0.5790 - val_top5-acc: 0.9550 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2479 - acc: 0.5562 - top5-acc: 0.9460 - val_loss: 1.1910 - val_acc: 0.5716 - val_top5-acc: 0.9552 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2410 - acc: 0.5582 - top5-acc: 0.9469 - val_loss: 1.1761 - val_acc: 0.5846 - val_top5-acc: 0.9570 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.2425 - acc: 0.5574 - top5-acc: 0.9492 - val_loss: 1.1792 - val_acc: 0.5870 - val_top5-acc: 0.9578 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.2481 - acc: 0.5560 - top5-acc: 0.9473 - val_loss: 1.1801 - val_acc: 0.5852 - val_top5-acc: 0.9564 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2441 - acc: 0.5571 - top5-acc: 0.9470 - val_loss: 1.1815 - val_acc: 0.5846 - val_top5-acc: 0.9570 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 14s 160ms/step - loss: 1.2493 - acc: 0.5534 - top5-acc: 0.9473 - val_loss: 1.1842 - val_acc: 0.5798 - val_top5-acc: 0.9560 - lr: 6.2500e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 14s 159ms/step - loss: 1.2451 - acc: 0.5588 - top5-acc: 0.9462 - val_loss: 1.1694 - val_acc: 0.5924 - val_top5-acc: 0.9570 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 22s 69ms/step - loss: 1.1836 - acc: 0.5754 - top5-acc: 0.9532\n",
      "Test accuracy: 57.54%\n",
      "Test top 5 accuracy: 95.32%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.8055 - acc: 0.3731 - top5-acc: 0.8561WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 19s 178ms/step - loss: 1.8055 - acc: 0.3731 - top5-acc: 0.8561 - val_loss: 1.4415 - val_acc: 0.4730 - val_top5-acc: 0.9316 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.4539 - acc: 0.4761 - top5-acc: 0.9239 - val_loss: 1.3494 - val_acc: 0.5154 - val_top5-acc: 0.9424 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.4015 - acc: 0.4964 - top5-acc: 0.9320 - val_loss: 1.3151 - val_acc: 0.5332 - val_top5-acc: 0.9446 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.3599 - acc: 0.5134 - top5-acc: 0.9371 - val_loss: 1.2797 - val_acc: 0.5456 - val_top5-acc: 0.9460 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.3425 - acc: 0.5208 - top5-acc: 0.9377 - val_loss: 1.2681 - val_acc: 0.5526 - val_top5-acc: 0.9462 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.3394 - acc: 0.5196 - top5-acc: 0.9389 - val_loss: 1.3220 - val_acc: 0.5378 - val_top5-acc: 0.9440 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.3297 - acc: 0.5263 - top5-acc: 0.9381 - val_loss: 1.2387 - val_acc: 0.5604 - val_top5-acc: 0.9506 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.3183 - acc: 0.5287 - top5-acc: 0.9403 - val_loss: 1.2457 - val_acc: 0.5550 - val_top5-acc: 0.9520 - lr: 0.0050\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 15s 168ms/step - loss: 1.3158 - acc: 0.5314 - top5-acc: 0.9410 - val_loss: 1.2433 - val_acc: 0.5536 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 14s 165ms/step - loss: 1.3056 - acc: 0.5345 - top5-acc: 0.9429 - val_loss: 1.2104 - val_acc: 0.5728 - val_top5-acc: 0.9538 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 14s 164ms/step - loss: 1.3037 - acc: 0.5347 - top5-acc: 0.9424 - val_loss: 1.2479 - val_acc: 0.5590 - val_top5-acc: 0.9452 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 1.3195 - acc: 0.5268 - top5-acc: 0.9406 - val_loss: 1.2252 - val_acc: 0.5628 - val_top5-acc: 0.9534 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.3104 - acc: 0.5327 - top5-acc: 0.9416 - val_loss: 1.2189 - val_acc: 0.5748 - val_top5-acc: 0.9510 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2942 - acc: 0.5379 - top5-acc: 0.9415 - val_loss: 1.2177 - val_acc: 0.5622 - val_top5-acc: 0.9530 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2911 - acc: 0.5397 - top5-acc: 0.9432 - val_loss: 1.2153 - val_acc: 0.5660 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 1.2677 - acc: 0.5486 - top5-acc: 0.9435 - val_loss: 1.1918 - val_acc: 0.5776 - val_top5-acc: 0.9542 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2601 - acc: 0.5542 - top5-acc: 0.9467 - val_loss: 1.1928 - val_acc: 0.5796 - val_top5-acc: 0.9552 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2604 - acc: 0.5528 - top5-acc: 0.9456 - val_loss: 1.1889 - val_acc: 0.5790 - val_top5-acc: 0.9586 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2615 - acc: 0.5533 - top5-acc: 0.9452 - val_loss: 1.1769 - val_acc: 0.5854 - val_top5-acc: 0.9580 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2591 - acc: 0.5486 - top5-acc: 0.9472 - val_loss: 1.1977 - val_acc: 0.5694 - val_top5-acc: 0.9594 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 1.2601 - acc: 0.5526 - top5-acc: 0.9456 - val_loss: 1.1712 - val_acc: 0.5886 - val_top5-acc: 0.9574 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 1.2593 - acc: 0.5505 - top5-acc: 0.9469 - val_loss: 1.1849 - val_acc: 0.5830 - val_top5-acc: 0.9568 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2577 - acc: 0.5511 - top5-acc: 0.9462 - val_loss: 1.1923 - val_acc: 0.5716 - val_top5-acc: 0.9590 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 15s 165ms/step - loss: 1.2556 - acc: 0.5542 - top5-acc: 0.9468 - val_loss: 1.1900 - val_acc: 0.5772 - val_top5-acc: 0.9582 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2542 - acc: 0.5516 - top5-acc: 0.9456 - val_loss: 1.2021 - val_acc: 0.5748 - val_top5-acc: 0.9554 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2642 - acc: 0.5489 - top5-acc: 0.9452 - val_loss: 1.1894 - val_acc: 0.5722 - val_top5-acc: 0.9584 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2495 - acc: 0.5542 - top5-acc: 0.9486 - val_loss: 1.1686 - val_acc: 0.5872 - val_top5-acc: 0.9586 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2468 - acc: 0.5543 - top5-acc: 0.9473 - val_loss: 1.1858 - val_acc: 0.5716 - val_top5-acc: 0.9586 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2440 - acc: 0.5600 - top5-acc: 0.9481 - val_loss: 1.1870 - val_acc: 0.5768 - val_top5-acc: 0.9564 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2462 - acc: 0.5594 - top5-acc: 0.9477 - val_loss: 1.1791 - val_acc: 0.5874 - val_top5-acc: 0.9572 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2447 - acc: 0.5546 - top5-acc: 0.9476 - val_loss: 1.1762 - val_acc: 0.5872 - val_top5-acc: 0.9570 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2464 - acc: 0.5584 - top5-acc: 0.9474 - val_loss: 1.1667 - val_acc: 0.5884 - val_top5-acc: 0.9590 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2450 - acc: 0.5562 - top5-acc: 0.9464 - val_loss: 1.1683 - val_acc: 0.5848 - val_top5-acc: 0.9588 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2509 - acc: 0.5536 - top5-acc: 0.9469 - val_loss: 1.1761 - val_acc: 0.5850 - val_top5-acc: 0.9564 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2448 - acc: 0.5590 - top5-acc: 0.9464 - val_loss: 1.1749 - val_acc: 0.5832 - val_top5-acc: 0.9584 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2424 - acc: 0.5567 - top5-acc: 0.9480 - val_loss: 1.1764 - val_acc: 0.5860 - val_top5-acc: 0.9592 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2433 - acc: 0.5584 - top5-acc: 0.9491 - val_loss: 1.1781 - val_acc: 0.5812 - val_top5-acc: 0.9594 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2378 - acc: 0.5604 - top5-acc: 0.9486 - val_loss: 1.1647 - val_acc: 0.5934 - val_top5-acc: 0.9592 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2393 - acc: 0.5617 - top5-acc: 0.9478 - val_loss: 1.1636 - val_acc: 0.5922 - val_top5-acc: 0.9596 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2398 - acc: 0.5569 - top5-acc: 0.9481 - val_loss: 1.1667 - val_acc: 0.5908 - val_top5-acc: 0.9592 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2385 - acc: 0.5590 - top5-acc: 0.9474 - val_loss: 1.1658 - val_acc: 0.5884 - val_top5-acc: 0.9600 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 14s 165ms/step - loss: 1.2388 - acc: 0.5584 - top5-acc: 0.9472 - val_loss: 1.1672 - val_acc: 0.5874 - val_top5-acc: 0.9594 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2406 - acc: 0.5591 - top5-acc: 0.9477 - val_loss: 1.1722 - val_acc: 0.5860 - val_top5-acc: 0.9608 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2405 - acc: 0.5582 - top5-acc: 0.9461 - val_loss: 1.1794 - val_acc: 0.5802 - val_top5-acc: 0.9596 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2411 - acc: 0.5598 - top5-acc: 0.9480 - val_loss: 1.1706 - val_acc: 0.5880 - val_top5-acc: 0.9588 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2383 - acc: 0.5605 - top5-acc: 0.9490 - val_loss: 1.1745 - val_acc: 0.5882 - val_top5-acc: 0.9594 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 15s 166ms/step - loss: 1.2359 - acc: 0.5633 - top5-acc: 0.9474 - val_loss: 1.1740 - val_acc: 0.5842 - val_top5-acc: 0.9582 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 15s 167ms/step - loss: 1.2364 - acc: 0.5637 - top5-acc: 0.9462 - val_loss: 1.1698 - val_acc: 0.5900 - val_top5-acc: 0.9588 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2395 - acc: 0.5609 - top5-acc: 0.9498 - val_loss: 1.1710 - val_acc: 0.5870 - val_top5-acc: 0.9598 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 15s 168ms/step - loss: 1.2360 - acc: 0.5638 - top5-acc: 0.9488 - val_loss: 1.1702 - val_acc: 0.5894 - val_top5-acc: 0.9594 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 24s 75ms/step - loss: 1.1845 - acc: 0.5774 - top5-acc: 0.9539\n",
      "Test accuracy: 57.74%\n",
      "Test top 5 accuracy: 95.39%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7230 - acc: 0.3862 - top5-acc: 0.8703WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 19s 185ms/step - loss: 1.7230 - acc: 0.3862 - top5-acc: 0.8703 - val_loss: 1.4080 - val_acc: 0.4894 - val_top5-acc: 0.9350 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.4236 - acc: 0.4913 - top5-acc: 0.9279 - val_loss: 1.3301 - val_acc: 0.5258 - val_top5-acc: 0.9394 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.3780 - acc: 0.5047 - top5-acc: 0.9336 - val_loss: 1.3257 - val_acc: 0.5276 - val_top5-acc: 0.9394 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.3466 - acc: 0.5214 - top5-acc: 0.9369 - val_loss: 1.2821 - val_acc: 0.5450 - val_top5-acc: 0.9470 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 15s 176ms/step - loss: 1.3304 - acc: 0.5247 - top5-acc: 0.9386 - val_loss: 1.2803 - val_acc: 0.5494 - val_top5-acc: 0.9454 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 15s 176ms/step - loss: 1.3268 - acc: 0.5254 - top5-acc: 0.9393 - val_loss: 1.2409 - val_acc: 0.5568 - val_top5-acc: 0.9516 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 15s 176ms/step - loss: 1.3073 - acc: 0.5318 - top5-acc: 0.9402 - val_loss: 1.2324 - val_acc: 0.5656 - val_top5-acc: 0.9492 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 15s 176ms/step - loss: 1.3000 - acc: 0.5368 - top5-acc: 0.9420 - val_loss: 1.2287 - val_acc: 0.5656 - val_top5-acc: 0.9522 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 15s 176ms/step - loss: 1.2971 - acc: 0.5363 - top5-acc: 0.9414 - val_loss: 1.2153 - val_acc: 0.5690 - val_top5-acc: 0.9544 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2880 - acc: 0.5413 - top5-acc: 0.9435 - val_loss: 1.2228 - val_acc: 0.5670 - val_top5-acc: 0.9520 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2893 - acc: 0.5407 - top5-acc: 0.9428 - val_loss: 1.2179 - val_acc: 0.5670 - val_top5-acc: 0.9536 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2866 - acc: 0.5426 - top5-acc: 0.9424 - val_loss: 1.2056 - val_acc: 0.5694 - val_top5-acc: 0.9536 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2870 - acc: 0.5424 - top5-acc: 0.9445 - val_loss: 1.2172 - val_acc: 0.5612 - val_top5-acc: 0.9534 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2799 - acc: 0.5453 - top5-acc: 0.9436 - val_loss: 1.2426 - val_acc: 0.5540 - val_top5-acc: 0.9526 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 15s 173ms/step - loss: 1.2862 - acc: 0.5432 - top5-acc: 0.9417 - val_loss: 1.2059 - val_acc: 0.5734 - val_top5-acc: 0.9508 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 15s 176ms/step - loss: 1.2806 - acc: 0.5438 - top5-acc: 0.9437 - val_loss: 1.2063 - val_acc: 0.5744 - val_top5-acc: 0.9504 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2750 - acc: 0.5448 - top5-acc: 0.9450 - val_loss: 1.2150 - val_acc: 0.5686 - val_top5-acc: 0.9528 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2451 - acc: 0.5560 - top5-acc: 0.9472 - val_loss: 1.1798 - val_acc: 0.5886 - val_top5-acc: 0.9552 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2485 - acc: 0.5564 - top5-acc: 0.9474 - val_loss: 1.1649 - val_acc: 0.5876 - val_top5-acc: 0.9560 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2465 - acc: 0.5550 - top5-acc: 0.9475 - val_loss: 1.1822 - val_acc: 0.5786 - val_top5-acc: 0.9562 - lr: 0.0025\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2428 - acc: 0.5588 - top5-acc: 0.9471 - val_loss: 1.1771 - val_acc: 0.5808 - val_top5-acc: 0.9582 - lr: 0.0025\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2470 - acc: 0.5576 - top5-acc: 0.9465 - val_loss: 1.1849 - val_acc: 0.5798 - val_top5-acc: 0.9584 - lr: 0.0025\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2505 - acc: 0.5547 - top5-acc: 0.9468 - val_loss: 1.1747 - val_acc: 0.5848 - val_top5-acc: 0.9566 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2474 - acc: 0.5560 - top5-acc: 0.9472 - val_loss: 1.1720 - val_acc: 0.5858 - val_top5-acc: 0.9568 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2331 - acc: 0.5605 - top5-acc: 0.9476 - val_loss: 1.1631 - val_acc: 0.5902 - val_top5-acc: 0.9592 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2354 - acc: 0.5592 - top5-acc: 0.9487 - val_loss: 1.1587 - val_acc: 0.5916 - val_top5-acc: 0.9570 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2361 - acc: 0.5600 - top5-acc: 0.9474 - val_loss: 1.1614 - val_acc: 0.5922 - val_top5-acc: 0.9554 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2302 - acc: 0.5636 - top5-acc: 0.9487 - val_loss: 1.1640 - val_acc: 0.5884 - val_top5-acc: 0.9586 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2306 - acc: 0.5627 - top5-acc: 0.9481 - val_loss: 1.1711 - val_acc: 0.5862 - val_top5-acc: 0.9564 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2347 - acc: 0.5579 - top5-acc: 0.9490 - val_loss: 1.1627 - val_acc: 0.5888 - val_top5-acc: 0.9612 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2352 - acc: 0.5598 - top5-acc: 0.9490 - val_loss: 1.1588 - val_acc: 0.5880 - val_top5-acc: 0.9592 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2322 - acc: 0.5630 - top5-acc: 0.9473 - val_loss: 1.1577 - val_acc: 0.5920 - val_top5-acc: 0.9584 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2319 - acc: 0.5624 - top5-acc: 0.9488 - val_loss: 1.1597 - val_acc: 0.5904 - val_top5-acc: 0.9580 - lr: 6.2500e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2266 - acc: 0.5655 - top5-acc: 0.9474 - val_loss: 1.1524 - val_acc: 0.5942 - val_top5-acc: 0.9590 - lr: 6.2500e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2305 - acc: 0.5629 - top5-acc: 0.9497 - val_loss: 1.1645 - val_acc: 0.5884 - val_top5-acc: 0.9588 - lr: 6.2500e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2255 - acc: 0.5629 - top5-acc: 0.9482 - val_loss: 1.1586 - val_acc: 0.5908 - val_top5-acc: 0.9586 - lr: 6.2500e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2270 - acc: 0.5662 - top5-acc: 0.9484 - val_loss: 1.1676 - val_acc: 0.5882 - val_top5-acc: 0.9584 - lr: 6.2500e-04\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2287 - acc: 0.5626 - top5-acc: 0.9493 - val_loss: 1.1586 - val_acc: 0.5930 - val_top5-acc: 0.9580 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2276 - acc: 0.5640 - top5-acc: 0.9486 - val_loss: 1.1543 - val_acc: 0.5972 - val_top5-acc: 0.9578 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 15s 175ms/step - loss: 1.2282 - acc: 0.5618 - top5-acc: 0.9488 - val_loss: 1.1587 - val_acc: 0.5934 - val_top5-acc: 0.9582 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2230 - acc: 0.5670 - top5-acc: 0.9505 - val_loss: 1.1597 - val_acc: 0.5912 - val_top5-acc: 0.9598 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2247 - acc: 0.5647 - top5-acc: 0.9493 - val_loss: 1.1591 - val_acc: 0.5908 - val_top5-acc: 0.9590 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2289 - acc: 0.5630 - top5-acc: 0.9499 - val_loss: 1.1584 - val_acc: 0.5960 - val_top5-acc: 0.9568 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2316 - acc: 0.5620 - top5-acc: 0.9471 - val_loss: 1.1624 - val_acc: 0.5934 - val_top5-acc: 0.9580 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 15s 173ms/step - loss: 1.2248 - acc: 0.5647 - top5-acc: 0.9492 - val_loss: 1.1606 - val_acc: 0.5934 - val_top5-acc: 0.9586 - lr: 1.5625e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 15s 173ms/step - loss: 1.2291 - acc: 0.5629 - top5-acc: 0.9482 - val_loss: 1.1606 - val_acc: 0.5928 - val_top5-acc: 0.9588 - lr: 1.5625e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 15s 173ms/step - loss: 1.2316 - acc: 0.5678 - top5-acc: 0.9484 - val_loss: 1.1625 - val_acc: 0.5942 - val_top5-acc: 0.9588 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2255 - acc: 0.5677 - top5-acc: 0.9494 - val_loss: 1.1665 - val_acc: 0.5908 - val_top5-acc: 0.9564 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 15s 173ms/step - loss: 1.2326 - acc: 0.5653 - top5-acc: 0.9483 - val_loss: 1.1630 - val_acc: 0.5922 - val_top5-acc: 0.9578 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 15s 174ms/step - loss: 1.2322 - acc: 0.5659 - top5-acc: 0.9476 - val_loss: 1.1652 - val_acc: 0.5934 - val_top5-acc: 0.9584 - lr: 7.8125e-05\n",
      "313/313 [==============================] - 23s 75ms/step - loss: 1.1766 - acc: 0.5835 - top5-acc: 0.9550\n",
      "Test accuracy: 58.35%\n",
      "Test top 5 accuracy: 95.5%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.6446 - acc: 0.4120 - top5-acc: 0.8842WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 20s 193ms/step - loss: 1.6446 - acc: 0.4120 - top5-acc: 0.8842 - val_loss: 1.3361 - val_acc: 0.5278 - val_top5-acc: 0.9388 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.3900 - acc: 0.5014 - top5-acc: 0.9308 - val_loss: 1.3030 - val_acc: 0.5316 - val_top5-acc: 0.9440 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.3421 - acc: 0.5210 - top5-acc: 0.9365 - val_loss: 1.2902 - val_acc: 0.5358 - val_top5-acc: 0.9450 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 16s 183ms/step - loss: 1.3182 - acc: 0.5290 - top5-acc: 0.9388 - val_loss: 1.2731 - val_acc: 0.5486 - val_top5-acc: 0.9466 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 16s 182ms/step - loss: 1.3026 - acc: 0.5360 - top5-acc: 0.9403 - val_loss: 1.2341 - val_acc: 0.5634 - val_top5-acc: 0.9514 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 16s 182ms/step - loss: 1.2894 - acc: 0.5403 - top5-acc: 0.9420 - val_loss: 1.1946 - val_acc: 0.5816 - val_top5-acc: 0.9530 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 16s 182ms/step - loss: 1.2853 - acc: 0.5409 - top5-acc: 0.9418 - val_loss: 1.1940 - val_acc: 0.5748 - val_top5-acc: 0.9556 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2803 - acc: 0.5430 - top5-acc: 0.9421 - val_loss: 1.2024 - val_acc: 0.5794 - val_top5-acc: 0.9544 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2625 - acc: 0.5505 - top5-acc: 0.9445 - val_loss: 1.1870 - val_acc: 0.5854 - val_top5-acc: 0.9550 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2576 - acc: 0.5521 - top5-acc: 0.9451 - val_loss: 1.1896 - val_acc: 0.5818 - val_top5-acc: 0.9520 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 16s 182ms/step - loss: 1.2562 - acc: 0.5533 - top5-acc: 0.9454 - val_loss: 1.1965 - val_acc: 0.5740 - val_top5-acc: 0.9584 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2543 - acc: 0.5519 - top5-acc: 0.9462 - val_loss: 1.1750 - val_acc: 0.5864 - val_top5-acc: 0.9544 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2575 - acc: 0.5508 - top5-acc: 0.9468 - val_loss: 1.1860 - val_acc: 0.5810 - val_top5-acc: 0.9516 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2516 - acc: 0.5542 - top5-acc: 0.9468 - val_loss: 1.1789 - val_acc: 0.5824 - val_top5-acc: 0.9592 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2608 - acc: 0.5517 - top5-acc: 0.9456 - val_loss: 1.1677 - val_acc: 0.5822 - val_top5-acc: 0.9586 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 16s 180ms/step - loss: 1.2472 - acc: 0.5547 - top5-acc: 0.9460 - val_loss: 1.1729 - val_acc: 0.5846 - val_top5-acc: 0.9558 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 16s 180ms/step - loss: 1.2385 - acc: 0.5597 - top5-acc: 0.9471 - val_loss: 1.1538 - val_acc: 0.5938 - val_top5-acc: 0.9556 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 16s 180ms/step - loss: 1.2474 - acc: 0.5568 - top5-acc: 0.9463 - val_loss: 1.1889 - val_acc: 0.5854 - val_top5-acc: 0.9532 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2444 - acc: 0.5562 - top5-acc: 0.9453 - val_loss: 1.1864 - val_acc: 0.5834 - val_top5-acc: 0.9536 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2517 - acc: 0.5547 - top5-acc: 0.9463 - val_loss: 1.1687 - val_acc: 0.5806 - val_top5-acc: 0.9596 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2471 - acc: 0.5554 - top5-acc: 0.9466 - val_loss: 1.1816 - val_acc: 0.5852 - val_top5-acc: 0.9546 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2474 - acc: 0.5570 - top5-acc: 0.9447 - val_loss: 1.1736 - val_acc: 0.5818 - val_top5-acc: 0.9586 - lr: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "88/88 [==============================] - 16s 180ms/step - loss: 1.2236 - acc: 0.5644 - top5-acc: 0.9488 - val_loss: 1.1516 - val_acc: 0.5946 - val_top5-acc: 0.9598 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2210 - acc: 0.5660 - top5-acc: 0.9493 - val_loss: 1.1507 - val_acc: 0.5966 - val_top5-acc: 0.9594 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2228 - acc: 0.5647 - top5-acc: 0.9480 - val_loss: 1.1425 - val_acc: 0.5952 - val_top5-acc: 0.9600 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 16s 182ms/step - loss: 1.2226 - acc: 0.5650 - top5-acc: 0.9490 - val_loss: 1.1518 - val_acc: 0.5968 - val_top5-acc: 0.9590 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2222 - acc: 0.5630 - top5-acc: 0.9485 - val_loss: 1.1383 - val_acc: 0.5962 - val_top5-acc: 0.9580 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 16s 180ms/step - loss: 1.2206 - acc: 0.5649 - top5-acc: 0.9487 - val_loss: 1.1665 - val_acc: 0.5884 - val_top5-acc: 0.9560 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 16s 180ms/step - loss: 1.2172 - acc: 0.5662 - top5-acc: 0.9496 - val_loss: 1.1606 - val_acc: 0.5924 - val_top5-acc: 0.9582 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2174 - acc: 0.5682 - top5-acc: 0.9498 - val_loss: 1.1488 - val_acc: 0.5950 - val_top5-acc: 0.9586 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2224 - acc: 0.5655 - top5-acc: 0.9477 - val_loss: 1.1562 - val_acc: 0.5878 - val_top5-acc: 0.9566 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2262 - acc: 0.5652 - top5-acc: 0.9476 - val_loss: 1.1724 - val_acc: 0.5870 - val_top5-acc: 0.9552 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2071 - acc: 0.5726 - top5-acc: 0.9504 - val_loss: 1.1432 - val_acc: 0.6016 - val_top5-acc: 0.9590 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2094 - acc: 0.5715 - top5-acc: 0.9491 - val_loss: 1.1344 - val_acc: 0.5968 - val_top5-acc: 0.9586 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2095 - acc: 0.5709 - top5-acc: 0.9493 - val_loss: 1.1408 - val_acc: 0.5982 - val_top5-acc: 0.9590 - lr: 0.0012\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2055 - acc: 0.5720 - top5-acc: 0.9500 - val_loss: 1.1340 - val_acc: 0.5990 - val_top5-acc: 0.9602 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2078 - acc: 0.5697 - top5-acc: 0.9497 - val_loss: 1.1327 - val_acc: 0.6022 - val_top5-acc: 0.9584 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2104 - acc: 0.5702 - top5-acc: 0.9502 - val_loss: 1.1416 - val_acc: 0.5982 - val_top5-acc: 0.9602 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2068 - acc: 0.5728 - top5-acc: 0.9498 - val_loss: 1.1319 - val_acc: 0.5948 - val_top5-acc: 0.9590 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2106 - acc: 0.5695 - top5-acc: 0.9504 - val_loss: 1.1345 - val_acc: 0.5980 - val_top5-acc: 0.9580 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 16s 181ms/step - loss: 1.2094 - acc: 0.5682 - top5-acc: 0.9510 - val_loss: 1.1284 - val_acc: 0.5992 - val_top5-acc: 0.9604 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 16s 182ms/step - loss: 1.2132 - acc: 0.5701 - top5-acc: 0.9490 - val_loss: 1.1442 - val_acc: 0.5972 - val_top5-acc: 0.9592 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2115 - acc: 0.5713 - top5-acc: 0.9481 - val_loss: 1.1353 - val_acc: 0.6020 - val_top5-acc: 0.9610 - lr: 0.0012\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2145 - acc: 0.5668 - top5-acc: 0.9496 - val_loss: 1.1419 - val_acc: 0.5948 - val_top5-acc: 0.9588 - lr: 0.0012\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2134 - acc: 0.5703 - top5-acc: 0.9495 - val_loss: 1.1395 - val_acc: 0.5986 - val_top5-acc: 0.9592 - lr: 0.0012\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2130 - acc: 0.5683 - top5-acc: 0.9498 - val_loss: 1.1349 - val_acc: 0.6044 - val_top5-acc: 0.9602 - lr: 0.0012\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2047 - acc: 0.5708 - top5-acc: 0.9509 - val_loss: 1.1337 - val_acc: 0.5998 - val_top5-acc: 0.9606 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2076 - acc: 0.5705 - top5-acc: 0.9484 - val_loss: 1.1344 - val_acc: 0.6000 - val_top5-acc: 0.9616 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2059 - acc: 0.5723 - top5-acc: 0.9498 - val_loss: 1.1384 - val_acc: 0.5948 - val_top5-acc: 0.9622 - lr: 6.2500e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 16s 186ms/step - loss: 1.2079 - acc: 0.5726 - top5-acc: 0.9482 - val_loss: 1.1465 - val_acc: 0.5996 - val_top5-acc: 0.9580 - lr: 6.2500e-04\n",
      "313/313 [==============================] - 27s 86ms/step - loss: 1.1654 - acc: 0.5835 - top5-acc: 0.9558\n",
      "Test accuracy: 58.35%\n",
      "Test top 5 accuracy: 95.58%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.7094 - acc: 0.4172 - top5-acc: 0.8785WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 21s 206ms/step - loss: 1.7094 - acc: 0.4172 - top5-acc: 0.8785 - val_loss: 1.3225 - val_acc: 0.5266 - val_top5-acc: 0.9458 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.3271 - acc: 0.5236 - top5-acc: 0.9387 - val_loss: 1.2366 - val_acc: 0.5550 - val_top5-acc: 0.9518 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.2767 - acc: 0.5407 - top5-acc: 0.9454 - val_loss: 1.2566 - val_acc: 0.5456 - val_top5-acc: 0.9548 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.2502 - acc: 0.5502 - top5-acc: 0.9493 - val_loss: 1.1898 - val_acc: 0.5714 - val_top5-acc: 0.9570 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.2451 - acc: 0.5544 - top5-acc: 0.9476 - val_loss: 1.1691 - val_acc: 0.5872 - val_top5-acc: 0.9586 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.2285 - acc: 0.5605 - top5-acc: 0.9490 - val_loss: 1.1544 - val_acc: 0.5866 - val_top5-acc: 0.9600 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.2158 - acc: 0.5669 - top5-acc: 0.9507 - val_loss: 1.1396 - val_acc: 0.5892 - val_top5-acc: 0.9602 - lr: 0.0050\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 17s 193ms/step - loss: 1.2144 - acc: 0.5652 - top5-acc: 0.9515 - val_loss: 1.1328 - val_acc: 0.6070 - val_top5-acc: 0.9592 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.2080 - acc: 0.5676 - top5-acc: 0.9519 - val_loss: 1.1683 - val_acc: 0.5890 - val_top5-acc: 0.9566 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.2067 - acc: 0.5680 - top5-acc: 0.9513 - val_loss: 1.1312 - val_acc: 0.6024 - val_top5-acc: 0.9604 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.2027 - acc: 0.5712 - top5-acc: 0.9504 - val_loss: 1.1187 - val_acc: 0.6060 - val_top5-acc: 0.9636 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.2028 - acc: 0.5702 - top5-acc: 0.9517 - val_loss: 1.1499 - val_acc: 0.5862 - val_top5-acc: 0.9600 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.1952 - acc: 0.5724 - top5-acc: 0.9527 - val_loss: 1.1532 - val_acc: 0.5832 - val_top5-acc: 0.9572 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.1985 - acc: 0.5738 - top5-acc: 0.9521 - val_loss: 1.1529 - val_acc: 0.5940 - val_top5-acc: 0.9574 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1942 - acc: 0.5738 - top5-acc: 0.9526 - val_loss: 1.1233 - val_acc: 0.6068 - val_top5-acc: 0.9588 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1847 - acc: 0.5785 - top5-acc: 0.9530 - val_loss: 1.1059 - val_acc: 0.6044 - val_top5-acc: 0.9638 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.1945 - acc: 0.5759 - top5-acc: 0.9521 - val_loss: 1.1318 - val_acc: 0.6036 - val_top5-acc: 0.9594 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1839 - acc: 0.5778 - top5-acc: 0.9535 - val_loss: 1.1266 - val_acc: 0.6052 - val_top5-acc: 0.9624 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1850 - acc: 0.5780 - top5-acc: 0.9534 - val_loss: 1.1049 - val_acc: 0.6088 - val_top5-acc: 0.9634 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.1982 - acc: 0.5736 - top5-acc: 0.9511 - val_loss: 1.1791 - val_acc: 0.5800 - val_top5-acc: 0.9548 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 17s 193ms/step - loss: 1.1902 - acc: 0.5756 - top5-acc: 0.9543 - val_loss: 1.1276 - val_acc: 0.6018 - val_top5-acc: 0.9614 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1843 - acc: 0.5771 - top5-acc: 0.9544 - val_loss: 1.1231 - val_acc: 0.6058 - val_top5-acc: 0.9598 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1914 - acc: 0.5728 - top5-acc: 0.9530 - val_loss: 1.1636 - val_acc: 0.5830 - val_top5-acc: 0.9594 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1851 - acc: 0.5781 - top5-acc: 0.9536 - val_loss: 1.1298 - val_acc: 0.6054 - val_top5-acc: 0.9588 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1603 - acc: 0.5861 - top5-acc: 0.9547 - val_loss: 1.0960 - val_acc: 0.6110 - val_top5-acc: 0.9624 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1591 - acc: 0.5879 - top5-acc: 0.9553 - val_loss: 1.0847 - val_acc: 0.6214 - val_top5-acc: 0.9636 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1557 - acc: 0.5871 - top5-acc: 0.9555 - val_loss: 1.1193 - val_acc: 0.6080 - val_top5-acc: 0.9606 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 17s 195ms/step - loss: 1.1656 - acc: 0.5837 - top5-acc: 0.9547 - val_loss: 1.1033 - val_acc: 0.6140 - val_top5-acc: 0.9612 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1617 - acc: 0.5867 - top5-acc: 0.9546 - val_loss: 1.1190 - val_acc: 0.6052 - val_top5-acc: 0.9598 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1586 - acc: 0.5867 - top5-acc: 0.9556 - val_loss: 1.1084 - val_acc: 0.6098 - val_top5-acc: 0.9598 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1610 - acc: 0.5855 - top5-acc: 0.9559 - val_loss: 1.0808 - val_acc: 0.6194 - val_top5-acc: 0.9632 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1569 - acc: 0.5885 - top5-acc: 0.9565 - val_loss: 1.1028 - val_acc: 0.6138 - val_top5-acc: 0.9604 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1682 - acc: 0.5824 - top5-acc: 0.9547 - val_loss: 1.1005 - val_acc: 0.6124 - val_top5-acc: 0.9630 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1585 - acc: 0.5892 - top5-acc: 0.9562 - val_loss: 1.0957 - val_acc: 0.6136 - val_top5-acc: 0.9652 - lr: 0.0025\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1646 - acc: 0.5836 - top5-acc: 0.9544 - val_loss: 1.1004 - val_acc: 0.6134 - val_top5-acc: 0.9638 - lr: 0.0025\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1653 - acc: 0.5854 - top5-acc: 0.9540 - val_loss: 1.0893 - val_acc: 0.6132 - val_top5-acc: 0.9628 - lr: 0.0025\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1442 - acc: 0.5943 - top5-acc: 0.9563 - val_loss: 1.0757 - val_acc: 0.6228 - val_top5-acc: 0.9650 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1469 - acc: 0.5904 - top5-acc: 0.9572 - val_loss: 1.0803 - val_acc: 0.6176 - val_top5-acc: 0.9644 - lr: 0.0012\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1526 - acc: 0.5891 - top5-acc: 0.9563 - val_loss: 1.0826 - val_acc: 0.6200 - val_top5-acc: 0.9644 - lr: 0.0012\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1476 - acc: 0.5908 - top5-acc: 0.9562 - val_loss: 1.0841 - val_acc: 0.6152 - val_top5-acc: 0.9656 - lr: 0.0012\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1445 - acc: 0.5943 - top5-acc: 0.9561 - val_loss: 1.0779 - val_acc: 0.6234 - val_top5-acc: 0.9644 - lr: 0.0012\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1425 - acc: 0.5933 - top5-acc: 0.9581 - val_loss: 1.0784 - val_acc: 0.6246 - val_top5-acc: 0.9648 - lr: 0.0012\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1436 - acc: 0.5921 - top5-acc: 0.9560 - val_loss: 1.0684 - val_acc: 0.6254 - val_top5-acc: 0.9650 - lr: 6.2500e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1385 - acc: 0.5950 - top5-acc: 0.9560 - val_loss: 1.0764 - val_acc: 0.6246 - val_top5-acc: 0.9640 - lr: 6.2500e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1415 - acc: 0.5930 - top5-acc: 0.9578 - val_loss: 1.0826 - val_acc: 0.6196 - val_top5-acc: 0.9630 - lr: 6.2500e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1440 - acc: 0.5942 - top5-acc: 0.9558 - val_loss: 1.0854 - val_acc: 0.6246 - val_top5-acc: 0.9652 - lr: 6.2500e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1427 - acc: 0.5942 - top5-acc: 0.9569 - val_loss: 1.0759 - val_acc: 0.6216 - val_top5-acc: 0.9658 - lr: 6.2500e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1419 - acc: 0.5937 - top5-acc: 0.9570 - val_loss: 1.0834 - val_acc: 0.6232 - val_top5-acc: 0.9662 - lr: 6.2500e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1376 - acc: 0.5967 - top5-acc: 0.9571 - val_loss: 1.0817 - val_acc: 0.6234 - val_top5-acc: 0.9636 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 17s 194ms/step - loss: 1.1413 - acc: 0.5928 - top5-acc: 0.9563 - val_loss: 1.0782 - val_acc: 0.6228 - val_top5-acc: 0.9648 - lr: 3.1250e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 28s 91ms/step - loss: 1.1144 - acc: 0.6051 - top5-acc: 0.9594\n",
      "Test accuracy: 60.51%\n",
      "Test top 5 accuracy: 95.94%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.4319 - acc: 0.4969 - top5-acc: 0.9193WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 22s 214ms/step - loss: 1.4319 - acc: 0.4969 - top5-acc: 0.9193 - val_loss: 1.1647 - val_acc: 0.5848 - val_top5-acc: 0.9580 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1967 - acc: 0.5751 - top5-acc: 0.9522 - val_loss: 1.1233 - val_acc: 0.6024 - val_top5-acc: 0.9612 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1664 - acc: 0.5827 - top5-acc: 0.9550 - val_loss: 1.0783 - val_acc: 0.6164 - val_top5-acc: 0.9628 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.1432 - acc: 0.5928 - top5-acc: 0.9577 - val_loss: 1.0931 - val_acc: 0.6040 - val_top5-acc: 0.9640 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1374 - acc: 0.5974 - top5-acc: 0.9567 - val_loss: 1.0613 - val_acc: 0.6216 - val_top5-acc: 0.9650 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1359 - acc: 0.5973 - top5-acc: 0.9580 - val_loss: 1.0563 - val_acc: 0.6166 - val_top5-acc: 0.9642 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.1322 - acc: 0.5969 - top5-acc: 0.9569 - val_loss: 1.0924 - val_acc: 0.5994 - val_top5-acc: 0.9618 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1264 - acc: 0.5995 - top5-acc: 0.9576 - val_loss: 1.0436 - val_acc: 0.6264 - val_top5-acc: 0.9656 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1278 - acc: 0.5962 - top5-acc: 0.9576 - val_loss: 1.0450 - val_acc: 0.6190 - val_top5-acc: 0.9640 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1159 - acc: 0.6031 - top5-acc: 0.9595 - val_loss: 1.0435 - val_acc: 0.6334 - val_top5-acc: 0.9656 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.1215 - acc: 0.6009 - top5-acc: 0.9583 - val_loss: 1.0923 - val_acc: 0.6108 - val_top5-acc: 0.9662 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.1221 - acc: 0.6024 - top5-acc: 0.9588 - val_loss: 1.0770 - val_acc: 0.6088 - val_top5-acc: 0.9638 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.1163 - acc: 0.6056 - top5-acc: 0.9595 - val_loss: 1.0751 - val_acc: 0.6160 - val_top5-acc: 0.9638 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0958 - acc: 0.6131 - top5-acc: 0.9610 - val_loss: 1.0291 - val_acc: 0.6328 - val_top5-acc: 0.9642 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0941 - acc: 0.6119 - top5-acc: 0.9609 - val_loss: 1.0329 - val_acc: 0.6322 - val_top5-acc: 0.9660 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0965 - acc: 0.6118 - top5-acc: 0.9609 - val_loss: 1.0525 - val_acc: 0.6224 - val_top5-acc: 0.9648 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0991 - acc: 0.6099 - top5-acc: 0.9594 - val_loss: 1.0444 - val_acc: 0.6282 - val_top5-acc: 0.9656 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.0909 - acc: 0.6130 - top5-acc: 0.9614 - val_loss: 1.0333 - val_acc: 0.6318 - val_top5-acc: 0.9658 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0993 - acc: 0.6097 - top5-acc: 0.9606 - val_loss: 1.0449 - val_acc: 0.6326 - val_top5-acc: 0.9652 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0813 - acc: 0.6172 - top5-acc: 0.9612 - val_loss: 1.0422 - val_acc: 0.6290 - val_top5-acc: 0.9648 - lr: 0.0012\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0838 - acc: 0.6149 - top5-acc: 0.9621 - val_loss: 1.0312 - val_acc: 0.6296 - val_top5-acc: 0.9688 - lr: 0.0012\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0813 - acc: 0.6181 - top5-acc: 0.9614 - val_loss: 1.0257 - val_acc: 0.6352 - val_top5-acc: 0.9668 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0828 - acc: 0.6168 - top5-acc: 0.9610 - val_loss: 1.0332 - val_acc: 0.6336 - val_top5-acc: 0.9646 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0774 - acc: 0.6173 - top5-acc: 0.9624 - val_loss: 1.0328 - val_acc: 0.6312 - val_top5-acc: 0.9642 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0830 - acc: 0.6166 - top5-acc: 0.9614 - val_loss: 1.0178 - val_acc: 0.6314 - val_top5-acc: 0.9670 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0843 - acc: 0.6154 - top5-acc: 0.9608 - val_loss: 1.0271 - val_acc: 0.6378 - val_top5-acc: 0.9680 - lr: 0.0012\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0765 - acc: 0.6186 - top5-acc: 0.9620 - val_loss: 1.0238 - val_acc: 0.6304 - val_top5-acc: 0.9664 - lr: 0.0012\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0819 - acc: 0.6161 - top5-acc: 0.9613 - val_loss: 1.0157 - val_acc: 0.6320 - val_top5-acc: 0.9660 - lr: 0.0012\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.0851 - acc: 0.6157 - top5-acc: 0.9612 - val_loss: 1.0328 - val_acc: 0.6312 - val_top5-acc: 0.9660 - lr: 0.0012\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0805 - acc: 0.6184 - top5-acc: 0.9617 - val_loss: 1.0197 - val_acc: 0.6340 - val_top5-acc: 0.9664 - lr: 0.0012\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0810 - acc: 0.6162 - top5-acc: 0.9636 - val_loss: 1.0182 - val_acc: 0.6334 - val_top5-acc: 0.9652 - lr: 0.0012\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0840 - acc: 0.6154 - top5-acc: 0.9611 - val_loss: 1.0124 - val_acc: 0.6396 - val_top5-acc: 0.9656 - lr: 0.0012\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0844 - acc: 0.6149 - top5-acc: 0.9613 - val_loss: 1.0182 - val_acc: 0.6364 - val_top5-acc: 0.9652 - lr: 0.0012\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0793 - acc: 0.6140 - top5-acc: 0.9611 - val_loss: 1.0264 - val_acc: 0.6312 - val_top5-acc: 0.9676 - lr: 0.0012\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.0818 - acc: 0.6188 - top5-acc: 0.9615 - val_loss: 1.0185 - val_acc: 0.6334 - val_top5-acc: 0.9666 - lr: 0.0012\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 18s 201ms/step - loss: 1.0817 - acc: 0.6159 - top5-acc: 0.9623 - val_loss: 1.0224 - val_acc: 0.6360 - val_top5-acc: 0.9664 - lr: 0.0012\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0742 - acc: 0.6219 - top5-acc: 0.9616 - val_loss: 1.0226 - val_acc: 0.6348 - val_top5-acc: 0.9660 - lr: 0.0012\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.0764 - acc: 0.6200 - top5-acc: 0.9623 - val_loss: 1.0131 - val_acc: 0.6392 - val_top5-acc: 0.9658 - lr: 6.2500e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0756 - acc: 0.6188 - top5-acc: 0.9620 - val_loss: 1.0199 - val_acc: 0.6400 - val_top5-acc: 0.9664 - lr: 6.2500e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0762 - acc: 0.6184 - top5-acc: 0.9627 - val_loss: 1.0209 - val_acc: 0.6328 - val_top5-acc: 0.9666 - lr: 6.2500e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0735 - acc: 0.6186 - top5-acc: 0.9626 - val_loss: 1.0229 - val_acc: 0.6324 - val_top5-acc: 0.9660 - lr: 6.2500e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0726 - acc: 0.6204 - top5-acc: 0.9621 - val_loss: 1.0165 - val_acc: 0.6330 - val_top5-acc: 0.9666 - lr: 6.2500e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 18s 202ms/step - loss: 1.0757 - acc: 0.6212 - top5-acc: 0.9617 - val_loss: 1.0212 - val_acc: 0.6322 - val_top5-acc: 0.9680 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.0735 - acc: 0.6192 - top5-acc: 0.9617 - val_loss: 1.0161 - val_acc: 0.6374 - val_top5-acc: 0.9670 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 18s 201ms/step - loss: 1.0708 - acc: 0.6192 - top5-acc: 0.9623 - val_loss: 1.0153 - val_acc: 0.6332 - val_top5-acc: 0.9662 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0718 - acc: 0.6201 - top5-acc: 0.9627 - val_loss: 1.0094 - val_acc: 0.6356 - val_top5-acc: 0.9678 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0698 - acc: 0.6222 - top5-acc: 0.9628 - val_loss: 1.0205 - val_acc: 0.6324 - val_top5-acc: 0.9660 - lr: 3.1250e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 18s 204ms/step - loss: 1.0733 - acc: 0.6222 - top5-acc: 0.9612 - val_loss: 1.0131 - val_acc: 0.6328 - val_top5-acc: 0.9664 - lr: 3.1250e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0717 - acc: 0.6175 - top5-acc: 0.9638 - val_loss: 1.0142 - val_acc: 0.6354 - val_top5-acc: 0.9660 - lr: 3.1250e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 18s 203ms/step - loss: 1.0711 - acc: 0.6186 - top5-acc: 0.9624 - val_loss: 1.0155 - val_acc: 0.6334 - val_top5-acc: 0.9662 - lr: 3.1250e-04\n",
      "313/313 [==============================] - 31s 98ms/step - loss: 1.0583 - acc: 0.6243 - top5-acc: 0.9660\n",
      "Test accuracy: 62.43%\n",
      "Test top 5 accuracy: 96.6%\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - ETA: 0s - loss: 1.1805 - acc: 0.5933 - top5-acc: 0.9467WARNING:tensorflow:Model was constructed with shape (32, 32, 3) for input KerasTensor(type_spec=TensorSpec(shape=(32, 32, 3), dtype=tf.uint8, name='normalization_input'), name='normalization_input', description=\"created by layer 'normalization_input'\"), but it was called on an input with incompatible shape (None, 32, 32, 3).\n",
      "88/88 [==============================] - 27s 267ms/step - loss: 1.1805 - acc: 0.5933 - top5-acc: 0.9467 - val_loss: 0.9913 - val_acc: 0.6604 - val_top5-acc: 0.9692 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9908 - acc: 0.6510 - top5-acc: 0.9696 - val_loss: 0.9659 - val_acc: 0.6594 - val_top5-acc: 0.9726 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9743 - acc: 0.6559 - top5-acc: 0.9692 - val_loss: 0.9803 - val_acc: 0.6564 - val_top5-acc: 0.9718 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9654 - acc: 0.6599 - top5-acc: 0.9706 - val_loss: 0.9419 - val_acc: 0.6722 - val_top5-acc: 0.9726 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9647 - acc: 0.6608 - top5-acc: 0.9713 - val_loss: 0.9423 - val_acc: 0.6732 - val_top5-acc: 0.9720 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9614 - acc: 0.6609 - top5-acc: 0.9721 - val_loss: 0.9422 - val_acc: 0.6728 - val_top5-acc: 0.9706 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9598 - acc: 0.6601 - top5-acc: 0.9724 - val_loss: 0.9463 - val_acc: 0.6746 - val_top5-acc: 0.9714 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9581 - acc: 0.6612 - top5-acc: 0.9730 - val_loss: 0.9430 - val_acc: 0.6688 - val_top5-acc: 0.9736 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9596 - acc: 0.6623 - top5-acc: 0.9715 - val_loss: 0.9472 - val_acc: 0.6662 - val_top5-acc: 0.9712 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9450 - acc: 0.6656 - top5-acc: 0.9724 - val_loss: 0.9295 - val_acc: 0.6788 - val_top5-acc: 0.9730 - lr: 0.0025\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9344 - acc: 0.6695 - top5-acc: 0.9732 - val_loss: 0.9424 - val_acc: 0.6690 - val_top5-acc: 0.9732 - lr: 0.0025\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9356 - acc: 0.6686 - top5-acc: 0.9727 - val_loss: 0.9359 - val_acc: 0.6700 - val_top5-acc: 0.9744 - lr: 0.0025\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9388 - acc: 0.6665 - top5-acc: 0.9730 - val_loss: 0.9254 - val_acc: 0.6746 - val_top5-acc: 0.9722 - lr: 0.0025\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9361 - acc: 0.6708 - top5-acc: 0.9732 - val_loss: 0.9298 - val_acc: 0.6686 - val_top5-acc: 0.9712 - lr: 0.0025\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9388 - acc: 0.6679 - top5-acc: 0.9730 - val_loss: 0.9165 - val_acc: 0.6772 - val_top5-acc: 0.9726 - lr: 0.0025\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9392 - acc: 0.6683 - top5-acc: 0.9722 - val_loss: 0.9232 - val_acc: 0.6786 - val_top5-acc: 0.9736 - lr: 0.0025\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9355 - acc: 0.6703 - top5-acc: 0.9732 - val_loss: 0.9346 - val_acc: 0.6740 - val_top5-acc: 0.9730 - lr: 0.0025\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9421 - acc: 0.6669 - top5-acc: 0.9724 - val_loss: 0.9232 - val_acc: 0.6798 - val_top5-acc: 0.9738 - lr: 0.0025\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9366 - acc: 0.6689 - top5-acc: 0.9739 - val_loss: 0.9300 - val_acc: 0.6732 - val_top5-acc: 0.9738 - lr: 0.0025\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9403 - acc: 0.6660 - top5-acc: 0.9730 - val_loss: 0.9242 - val_acc: 0.6784 - val_top5-acc: 0.9720 - lr: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9283 - acc: 0.6720 - top5-acc: 0.9735 - val_loss: 0.9256 - val_acc: 0.6768 - val_top5-acc: 0.9736 - lr: 0.0012\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9311 - acc: 0.6714 - top5-acc: 0.9730 - val_loss: 0.9207 - val_acc: 0.6720 - val_top5-acc: 0.9726 - lr: 0.0012\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9301 - acc: 0.6738 - top5-acc: 0.9729 - val_loss: 0.9178 - val_acc: 0.6782 - val_top5-acc: 0.9722 - lr: 0.0012\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9276 - acc: 0.6734 - top5-acc: 0.9733 - val_loss: 0.9229 - val_acc: 0.6720 - val_top5-acc: 0.9742 - lr: 0.0012\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9266 - acc: 0.6724 - top5-acc: 0.9734 - val_loss: 0.9193 - val_acc: 0.6772 - val_top5-acc: 0.9736 - lr: 0.0012\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9254 - acc: 0.6718 - top5-acc: 0.9739 - val_loss: 0.9128 - val_acc: 0.6800 - val_top5-acc: 0.9736 - lr: 6.2500e-04\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9243 - acc: 0.6754 - top5-acc: 0.9727 - val_loss: 0.9115 - val_acc: 0.6810 - val_top5-acc: 0.9736 - lr: 6.2500e-04\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9178 - acc: 0.6770 - top5-acc: 0.9744 - val_loss: 0.9139 - val_acc: 0.6774 - val_top5-acc: 0.9738 - lr: 6.2500e-04\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 18s 210ms/step - loss: 0.9232 - acc: 0.6753 - top5-acc: 0.9734 - val_loss: 0.9120 - val_acc: 0.6788 - val_top5-acc: 0.9746 - lr: 6.2500e-04\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9237 - acc: 0.6738 - top5-acc: 0.9735 - val_loss: 0.9127 - val_acc: 0.6760 - val_top5-acc: 0.9736 - lr: 6.2500e-04\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9212 - acc: 0.6742 - top5-acc: 0.9739 - val_loss: 0.9147 - val_acc: 0.6756 - val_top5-acc: 0.9736 - lr: 6.2500e-04\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9243 - acc: 0.6746 - top5-acc: 0.9737 - val_loss: 0.9172 - val_acc: 0.6760 - val_top5-acc: 0.9736 - lr: 6.2500e-04\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9195 - acc: 0.6784 - top5-acc: 0.9734 - val_loss: 0.9092 - val_acc: 0.6764 - val_top5-acc: 0.9744 - lr: 3.1250e-04\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9183 - acc: 0.6765 - top5-acc: 0.9737 - val_loss: 0.9108 - val_acc: 0.6794 - val_top5-acc: 0.9734 - lr: 3.1250e-04\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9179 - acc: 0.6762 - top5-acc: 0.9740 - val_loss: 0.9118 - val_acc: 0.6778 - val_top5-acc: 0.9738 - lr: 3.1250e-04\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9211 - acc: 0.6754 - top5-acc: 0.9726 - val_loss: 0.9107 - val_acc: 0.6768 - val_top5-acc: 0.9740 - lr: 3.1250e-04\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9229 - acc: 0.6742 - top5-acc: 0.9738 - val_loss: 0.9082 - val_acc: 0.6766 - val_top5-acc: 0.9736 - lr: 3.1250e-04\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9171 - acc: 0.6756 - top5-acc: 0.9748 - val_loss: 0.9116 - val_acc: 0.6766 - val_top5-acc: 0.9744 - lr: 3.1250e-04\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9190 - acc: 0.6759 - top5-acc: 0.9732 - val_loss: 0.9145 - val_acc: 0.6762 - val_top5-acc: 0.9734 - lr: 3.1250e-04\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9204 - acc: 0.6747 - top5-acc: 0.9732 - val_loss: 0.9131 - val_acc: 0.6770 - val_top5-acc: 0.9736 - lr: 3.1250e-04\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9199 - acc: 0.6754 - top5-acc: 0.9739 - val_loss: 0.9074 - val_acc: 0.6798 - val_top5-acc: 0.9732 - lr: 3.1250e-04\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 18s 209ms/step - loss: 0.9197 - acc: 0.6755 - top5-acc: 0.9734 - val_loss: 0.9116 - val_acc: 0.6770 - val_top5-acc: 0.9734 - lr: 3.1250e-04\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9176 - acc: 0.6789 - top5-acc: 0.9732 - val_loss: 0.9118 - val_acc: 0.6780 - val_top5-acc: 0.9738 - lr: 3.1250e-04\n",
      "Epoch 44/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9242 - acc: 0.6738 - top5-acc: 0.9736 - val_loss: 0.9088 - val_acc: 0.6792 - val_top5-acc: 0.9738 - lr: 3.1250e-04\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9193 - acc: 0.6772 - top5-acc: 0.9737 - val_loss: 0.9128 - val_acc: 0.6756 - val_top5-acc: 0.9734 - lr: 3.1250e-04\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9217 - acc: 0.6744 - top5-acc: 0.9738 - val_loss: 0.9140 - val_acc: 0.6766 - val_top5-acc: 0.9738 - lr: 3.1250e-04\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9204 - acc: 0.6758 - top5-acc: 0.9741 - val_loss: 0.9104 - val_acc: 0.6780 - val_top5-acc: 0.9732 - lr: 1.5625e-04\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 19s 211ms/step - loss: 0.9214 - acc: 0.6772 - top5-acc: 0.9731 - val_loss: 0.9099 - val_acc: 0.6768 - val_top5-acc: 0.9738 - lr: 1.5625e-04\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9197 - acc: 0.6770 - top5-acc: 0.9734 - val_loss: 0.9081 - val_acc: 0.6776 - val_top5-acc: 0.9738 - lr: 1.5625e-04\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 19s 212ms/step - loss: 0.9185 - acc: 0.6768 - top5-acc: 0.9733 - val_loss: 0.9107 - val_acc: 0.6772 - val_top5-acc: 0.9740 - lr: 1.5625e-04\n",
      "313/313 [==============================] - 32s 102ms/step - loss: 0.9356 - acc: 0.6712 - top5-acc: 0.9735\n",
      "Test accuracy: 67.12%\n",
      "Test top 5 accuracy: 97.35%\n"
     ]
    }
   ],
   "source": [
    "tested_acc_evolution = evol_accuracy(all_models,listnumblocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ignore the folowwing lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculates a heatmap according to the selection of a CKA_Kernel (preferred) or CKA_Linear\n",
    "# def Heatmap_2(result1,result2,type,sigma):\n",
    "#     dim1 = len(result1)\n",
    "#     dim2 = len(result2)\n",
    "#     k = (dim1 - 1)\n",
    "#     heatmap_CKA = np.zeros((dim1,dim2))\n",
    "#     for i in range(0,dim1):\n",
    "#         tr = (dim2 - 1)\n",
    "#         for j in range(0,dim2):\n",
    "#             if type == 'kernel':\n",
    "#                 heatmap_CKA[k][tr] = cka(gram_rbf(result1[i],sigma),gram_rbf(result2[j],sigma))\n",
    "#             elif type == 'linear':\n",
    "#                 heatmap_CKA[k][tr] = cka(gram_linear(result1[i]),gram_linear(result2[j])) \n",
    "#             else:\n",
    "#                 print('There is no such category, try again')\n",
    "#                 break\n",
    "\n",
    "#             tr -= 1\n",
    "#         k -= 1\n",
    "#     #print('CKA' + type + 'calculated')\n",
    "#     return heatmap_CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_Heatmap_mul(heatmap,type,bl):\n",
    "#     #Number of thats that you want to appear in the plot\n",
    "#     tri = 4\n",
    "#     if type == 'kernel' or type == 'linear':\n",
    "#         dim1 = heatmap.shape[1]\n",
    "#         dim2 = heatmap.shape[0]\n",
    "#         axis_labelsx = list()\n",
    "#         axis_labelsy = list()\n",
    "#         for i in range(0,dim1):\n",
    "#             axis_labels_inter = str('%i'%(i+1))\n",
    "#             axis_labelsx.append(axis_labels_inter)\n",
    "    \n",
    "#         for i in range(0,dim2):\n",
    "#             axis_labels_inter = str('%i'%(i+1))\n",
    "#             axis_labelsy.append(axis_labels_inter)\n",
    "        \n",
    "#         _, ax = plt.subplots(figsize=(7,3))\n",
    "#         ax = sns.heatmap(heatmap, xticklabels=axis_labelsx[::-1], yticklabels=axis_labelsy[::-1], ax = ax, annot=bl)\n",
    "#         #sns.heatmap(heatmap, xticklabels=2, yticklabels=2, ax = ax, annot=bl, cbar=True)   \n",
    "#         ax.invert_xaxis()\n",
    "        \n",
    "#         # ax.axhline(y = 0, color='k',linewidth = 4)\n",
    "#         # ax.axhline(y = heatmap.shape[1], color = 'k', linewidth = 4)\n",
    "#         # ax.axvline(x = 0, color ='k',linewidth = 4)\n",
    "#         # ax.axvline(x = heatmap.shape[0], color = 'k', linewidth = 4)\n",
    "\n",
    "#         ax.set_title(\"CKA-\"+ type)   \n",
    "#         ax.set_xlabel(\"Layer\")\n",
    "#         ax.set_ylabel(\"Layer\")\n",
    "#         plt.yticks(rotation=0)\n",
    "#         plt.locator_params(axis='x',nbins=tri)\n",
    "#         plt.locator_params(axis='y',nbins=tri)\n",
    "#         plt.savefig('CKA_'+ type +'.png', dpi=300)\n",
    "        \n",
    "#     else:\n",
    "#         print('There is no such category, try again')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val1 = 8\n",
    "# val2 = 12\n",
    "# path = 'Results_Article/1A/mlpmixer_'+ str(val1) +'ly_384Dc'\n",
    "# with open(path + '/activations_'+ str(val1) +'ly_384Dc.pkl','rb') as file:\n",
    "#     tested_activations1 = pickle.load(file)\n",
    "#     path = 'Results_Article/1A/mlpmixer_'+ str(val2) +'ly_384Dc'\n",
    "# with open(path + '/activations_'+ str(val2) +'ly_384Dc.pkl','rb') as file:\n",
    "#     tested_activations2 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing = Heatmap_2(tested_activations1, tested_activations2, 'kernel',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize_Heatmap_mul(testing,'kernel',False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mlp_image_classification",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
