{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zSzgroG_Suq"
   },
   "source": [
    "# Study of Image classification with modern MLP Mixer model and CKA\n",
    "\n",
    "**Author:** [Arturo Flores](https://www.linkedin.com/in/afloresalv/)<br>\n",
    "**Based on (MLP-MIXER):**  https://keras.io/examples/vision/mlp_image_classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U087DdDw_Suy"
   },
   "source": [
    "# Setup for the MLP-Mixer Architecture\n",
    "\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AnTyoluw_Suz"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda3\\envs\\AI\\lib\\site-packages\\tensorflow_addons\\utils\\ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.5.0 and strictly below 2.8.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.8.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt \n",
    "from scipy.stats import norm\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import datetime\n",
    "import pickle\n",
    "# Files imported from the sleected GitHub https://cka-similarity.github.io/\n",
    "from CKA_Google import *\n",
    "import seaborn as sns \n",
    "import random\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 : Across Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8DAOrIHu_Su2"
   },
   "source": [
    "## Configure the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1iMiVS7o_Su3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 224 X 224 = 50176\n",
      "Patch size: 32 X 32 = 1024 \n",
      "Patches per image: 49\n",
      "Elements per patch (3 channels): 3072\n"
     ]
    }
   ],
   "source": [
    "weight_decay = 0.0001\n",
    "batch_size = 512 \n",
    "num_epochs = 50\n",
    "dropout_rate = 0.2\n",
    "learning_rate = 0.005\n",
    "\n",
    "## Selected Architecture: B/32\n",
    "\n",
    "image_size = 224  # We'll resize input images to this size. Square\n",
    "patch_size = 32  # Size of the patches to be extracted from the input images. Square\n",
    "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
    "embedding_dim = 384  # Fixed Embedding Dimension\n",
    "num_blocks = 12\n",
    "\n",
    "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
    "print(f\"Patches per image: {num_patches}\")\n",
    "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "date = now.strftime(\"%Y-%m-%d_%H-%M\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUuu2OAS_Su0"
   },
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
      "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Dataset for training \n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
    "#plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08mpnEZH_Su5"
   },
   "source": [
    "## Build a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ra-bXojQ_Su6"
   },
   "outputs": [],
   "source": [
    "def build_classifier(blocks, embedding_dim, positional_encoding=False):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Augment data. \n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches. \n",
    "    patches = Patches(patch_size, num_patches)(augmented)\n",
    "    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n",
    "    x = layers.Dense(units=embedding_dim)(patches)\n",
    "    if positional_encoding:\n",
    "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
    "        position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=embedding_dim\n",
    "        )(positions)\n",
    "        x = x + position_embedding\n",
    "    # Process x using the module blocks. ## (sequential_82)\n",
    "    x = blocks(x)\n",
    "    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor. \n",
    "    representation = layers.GlobalAveragePooling1D()(x)\n",
    "    # Apply dropout.\n",
    "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
    "    # Compute logits outputs.\n",
    "    logits = layers.Dense(num_classes)(representation) \n",
    "    # Create the Keras model.\n",
    "    return keras.Model(inputs=inputs, outputs=logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cpQFU8H__Su8"
   },
   "source": [
    "## Define an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9E1zD2BY_Su8"
   },
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    # Create Adam optimizer with weight decay. Regularization that penalizes the increase of weight - with a facto alpha - to correct the overfitting\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay,\n",
    "    )\n",
    "    # Compile the model.\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        #Negative Log Likelihood = Categorical Cross Entropy\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
    "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
    "        ],\n",
    "    )\n",
    "    # Create a learning rate scheduler callback.\n",
    "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=5\n",
    "    )\n",
    "    # Create an early stopping regularization callback. \n",
    "    # It ends at a point that corresponds to a minimum of the L2-regularized objective\n",
    "    #early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    #    monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
    "    #)\n",
    "    # Fit the model.\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[reduce_lr],\n",
    "    )\n",
    "\n",
    "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
    "\n",
    "    # Return history to plot learning curves.\n",
    "    return history, accuracy, top_5_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxeE0cmM_Su9"
   },
   "source": [
    "## Use data augmentation\n",
    "Their state is not set during training; it must be set before training, either by initializing them from a precomputed constant, or by \"adapting\" them on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zh6hFPWX_Su-"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Normalization(),\n",
    "        layers.Resizing(image_size, image_size),\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G77cUgiu_Su-"
   },
   "source": [
    "## Implement patch extraction as a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RYKNktXe_Su_"
   },
   "outputs": [],
   "source": [
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size, num_patches):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = num_patches\n",
    "\n",
    "    def call(self, images):\n",
    "        #Extract the shape dimension in the position 0 = columns\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            #Without overlapping, stride horizontally and vertically\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            #Rate: Dilation factor [1 1* 1* 1] controls the spacing between the kernel points.\n",
    "            rates=[1, 1, 1, 1],\n",
    "            #Patches contained in the images are considered, no zero padding\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        #shape[-1], number of colummns, as well as shape[0]\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
    "        return patches\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Patches, self).get_config().copy()\n",
    "        config.update ({\n",
    "            'patch_size' : self.patch_size ,\n",
    "            'num_patches' : self.num_patches\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l7yehcSS_Su_"
   },
   "source": [
    "## The MLP-Mixer model\n",
    "\n",
    "The MLP-Mixer is an architecture based exclusively on\n",
    "multi-layer perceptrons (MLPs), that contains two types of MLP layers:\n",
    "\n",
    "1. One applied independently to image patches, which mixes the per-location features.\n",
    "2. The other applied across patches (along channels), which mixes spatial information.\n",
    "\n",
    "This is similar to a [depthwise separable convolution based model](https://arxiv.org/pdf/1610.02357.pdf)\n",
    "such as the Xception model, but with two chained dense transforms, no max pooling, and layer normalization\n",
    "instead of batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvwg4e2n_SvA"
   },
   "source": [
    "### Implement the MLP-Mixer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dT6wVEki_SvA"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLPMixerLayer(layers.Layer):\n",
    "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
    "        super(MLPMixerLayer, self).__init__(*args, **kwargs)\n",
    "\n",
    "        self.mlp1 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dense(units=num_patches),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.mlp2 = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(units=num_patches),\n",
    "                tfa.layers.GELU(),\n",
    "                layers.Dense(units=embedding_dim),\n",
    "                layers.Dropout(rate=dropout_rate),\n",
    "            ]\n",
    "        )\n",
    "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply layer normalization.\n",
    "        x = self.normalize(inputs)\n",
    "        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n",
    "        x_channels = tf.linalg.matrix_transpose(x)\n",
    "        # Apply mlp1 on each channel independently.\n",
    "        mlp1_outputs = self.mlp1(x_channels)\n",
    "        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n",
    "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
    "        # Add skip connection.\n",
    "        x = mlp1_outputs + inputs\n",
    "        # Apply layer normalization.\n",
    "        x_patches = self.normalize(x)\n",
    "        # Apply mlp2 on each patch independtenly.\n",
    "        mlp2_outputs = self.mlp2(x_patches)\n",
    "        # Add skip connection.\n",
    "        x = x + mlp2_outputs\n",
    "        return x\n",
    "\n",
    "    def get_config(self): \n",
    "        config = super(MLPMixerLayer, self).get_config().copy()\n",
    "        config.update ({\n",
    "            'num_patches' : num_patches,\n",
    "            'embedding_dim' : embedding_dim,\n",
    "            'dropout_rate' : dropout_rate,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zUiufq92_SvA"
   },
   "source": [
    "## Build, train, and evaluate the MLP-Mixer model\n",
    "\n",
    "Note that training the model with the current settings on a V100 GPUs\n",
    "takes around 8 seconds per epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report: Learning Curve\n",
    "def curves(history):\n",
    "    ymax1 = min(history[\"loss\"])\n",
    "    xmax1 = history[\"loss\"].index(ymax1)\n",
    "    ymax2 = min(history[\"val_loss\"])\n",
    "    xmax2 = history[\"val_loss\"].index(ymax2)\n",
    "    plt.title(\"Cross Entropy Loss\")\n",
    "    plt.plot(history[\"loss\"], color = 'blue', label = 'Training')\n",
    "    plt.plot(history[\"val_loss\"], color = 'orange', label = 'Testing')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.annotate('Max:' + str(round(ymax1,2)) , xy = (xmax1, ymax1), xytext = (xmax1*0.93, 1.07*ymax1), \n",
    "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
    "    plt.annotate('Max:' + str(round(ymax2,2)) , xy = (xmax2, ymax2), xytext = (xmax2*0.93, 1.07*ymax2), \n",
    "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
    "    plt.xlim([0,num_epochs])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    # Graph accuracy\n",
    "    ymax3 = max(history[\"acc\"])\n",
    "    xmax3 = history[\"acc\"].index(ymax3)\n",
    "    ymax4 = max(history[\"val_acc\"])\n",
    "    xmax4 = history[\"val_acc\"].index(ymax4)\n",
    "    ymax5 = max(history[\"top5-acc\"])\n",
    "    xmax5 = history[\"top5-acc\"].index(ymax5)\n",
    "    ymax6 = max(history[\"val_top5-acc\"])\n",
    "    xmax6 = history[\"val_top5-acc\"].index(ymax6)\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.title('Classification accuracy')\n",
    "    plt.plot(history['acc'], color = 'blue', label = 'Training')\n",
    "    plt.plot(history['val_acc'], color = 'orange', label = 'Testing')\n",
    "    plt.annotate('Max:' + str(round(ymax3,2)) , xy = (xmax3, ymax3), xytext = (xmax3*0.93, 1.2*ymax3), \n",
    "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
    "    plt.annotate('Max:' + str(round(ymax4,2)) , xy = (xmax4, ymax4), xytext = (xmax4*0.93, 0.7*ymax4), \n",
    "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.title('Classification top5-acc')\n",
    "    plt.plot(history['top5-acc'], color = 'blue', label = 'Training')\n",
    "    plt.plot(history['val_top5-acc'], color = 'orange', label = 'Testing')\n",
    "    plt.annotate('Max:' + str(round(ymax5,2)) , xy = (xmax5, ymax5), xytext = (xmax5*0.93, 1.2*ymax5), \n",
    "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
    "    plt.annotate('Max:' + str(round(ymax6,2)) , xy = (xmax6, ymax6), xytext = (xmax6*0.87, 1.2*ymax6), \n",
    "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
    "    plt.xlim([0,num_epochs])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.suptitle(\"Learning Curves\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain activations + Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Layers + Patches + One dense layer\n",
    "def Preprocessing(num_example):\n",
    "    augmented = data_augmentation(x_train[num_example])\n",
    "    b = Patches(patch_size, num_patches)(augmented)\n",
    "    a = layers.Dense(units=embedding_dim)(b)\n",
    "    inp = tf.reshape(a,[1,embedding_dim,num_patches])\n",
    "    return inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a random vector with indexes of a random batch selection and also regularizes the selected batch\n",
    "def Batch_Preprocessing(batch_size):\n",
    "    #Vector with the number of Sample of the Xtrain\n",
    "    a  = list(range(0,x_train.shape[0]))\n",
    "    b = random.sample(a,batch_size)\n",
    "    batch_regularization = list()\n",
    "    for i in range(0,batch_size):\n",
    "        inter_result = Preprocessing(b[i])\n",
    "        batch_regularization.append(inter_result)\n",
    "    return batch_regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_out(result,layer_number,example):\n",
    "    fig, (ax1, ax2)= plt.subplots(1,2)\n",
    "    ax1.imshow(x_train[example])\n",
    "    ax1.set_title('Original_Figure, Class: #' + str(y_train[example][0]))\n",
    "    ax2.imshow(result[layer_number])\n",
    "    ax2.set_title('Activations of MLP block of the Mixer #: '+ '\"' + str(layer_number) + '\"')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Mixer_Layer_Outputs(model_input, model_output,example):\n",
    "    #The input is fixed to the beginning of the mlp blocks\n",
    "    intermediate_model=tf.keras.models.Model(inputs=model_input.input,outputs=model_output.output)\n",
    "    #This reshape is necessary for the input of the model\n",
    "    example = tf.reshape(example,[1,num_patches,embedding_dim])\n",
    "    #Inference\n",
    "    intermediate_prediction =intermediate_model.predict(example)\n",
    "    #This reshape is standardize the output\n",
    "    layactivation = intermediate_prediction.reshape((embedding_dim,num_patches))\n",
    "    return layactivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computes the outputs of each MLP-mixer Layer\n",
    "def Mixer_Activations(model, example):\n",
    "    total_activations = list()\n",
    "    for i in range(num_blocks):\n",
    "        model_input = model.layers[4].layers[0]\n",
    "        model_output = model.layers[4].layers[i]\n",
    "        int_total_activations = Mixer_Layer_Outputs(model_input, model_output, example)\n",
    "        total_activations.append(int_total_activations)\n",
    "    return  total_activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average of layer's activation\n",
    "def Prom_Mixer_Activations_Blocks(model,batch_regularization):\n",
    "    sum = list()\n",
    "    for i in range(0,num_blocks):\n",
    "        sum_raw = np.zeros((embedding_dim,num_patches))\n",
    "        sum.append(sum_raw)\n",
    "    for i in range(0,batch_size):\n",
    "        mixer_raw = Mixer_Activations(model,batch_regularization[i])\n",
    "        for i in range(0,num_blocks):\n",
    "            sum[i] = np.add(mixer_raw[i],sum[i])\n",
    "    prom_mixer_activations = [ (number / batch_size)  for number in sum]\n",
    "    return prom_mixer_activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates a heatmap according to the selection of a CKA_Kernel (preferred) or CKA_Linear\n",
    "def Heatmap(result,type,sigma):\n",
    "    dim = len(result)\n",
    "    k = (dim - 1)\n",
    "    heatmap_CKA = np.zeros((dim,dim))\n",
    "    for i in range(0,dim):\n",
    "        tr = (dim - 1)\n",
    "        for j in range(0,dim):\n",
    "            if type == 'kernel':\n",
    "                heatmap_CKA[k][tr] = cka(gram_rbf(result[i],sigma),gram_rbf(result[j],sigma))\n",
    "            elif type == 'linear':\n",
    "                heatmap_CKA[k][tr] = cka(gram_linear(result[i]),gram_linear(result[j])) \n",
    "            else:\n",
    "                print('There is no such category, try again')\n",
    "                break\n",
    "\n",
    "            tr -= 1\n",
    "        k -= 1\n",
    "    #print('CKA' + type + 'calculated')\n",
    "    return heatmap_CKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average of heatmaps (obsolet)\n",
    "def Prom_Mixer_Heatmaps(batch_result,type):\n",
    "    mat_heatmaps = list()\n",
    "    prom_mixer_heatmap_raw = np.zeros((num_blocks,num_blocks))\n",
    "    for i in range(0,batch_size):\n",
    "        mixer_activations_raw = Mixer_Activations(batch_result[i])\n",
    "        heatmap_raw = Heatmap(mixer_activations_raw, type)\n",
    "        mat_heatmaps.append(heatmap_raw)\n",
    "        prom_mixer_heatmap_raw = np.add(heatmap_raw,prom_mixer_heatmap_raw)\n",
    "    prom_mixer_heatmap =  prom_mixer_heatmap_raw/batch_size  \n",
    "    return prom_mixer_heatmap,mat_heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_Heatmap(heatmap,type,bl):\n",
    "    #Number of thats that you want to appear in the plot\n",
    "    tri = 4\n",
    "    if type == 'kernel' or type == 'linear':\n",
    "        dim = len(heatmap)\n",
    "        axis_labels = list()\n",
    "        for i in range(0,dim):\n",
    "            axis_labels_inter = str('%i'%(i+1))\n",
    "            axis_labels.append(axis_labels_inter)\n",
    "        _, ax = plt.subplots(figsize=(3,3))\n",
    "        ax = sns.heatmap(heatmap, xticklabels=axis_labels[::-1], yticklabels=axis_labels[::-1], ax = ax, annot=bl)\n",
    "        #sns.heatmap(heatmap, xticklabels=2, yticklabels=2, ax = ax, annot=bl, cbar=True)   \n",
    "        ax.invert_xaxis()\n",
    "        ax.axhline(y = 0, color='k',linewidth = 4)\n",
    "        ax.axhline(y = heatmap.shape[1], color = 'k', linewidth = 4)\n",
    "        ax.axvline(x = 0, color ='k',linewidth = 4)\n",
    "        ax.axvline(x = heatmap.shape[0], color = 'k', linewidth = 4)\n",
    "\n",
    "        ax.set_title(\"CKA-\"+ type)   \n",
    "        ax.set_xlabel(\"Layer\")\n",
    "        ax.set_ylabel(\"Layer\")\n",
    "        plt.yticks(rotation=0)\n",
    "        plt.locator_params(axis='x',nbins=tri)\n",
    "        plt.locator_params(axis='y',nbins=tri)\n",
    "        plt.savefig('CKA_'+ type +'.png', dpi=300)\n",
    "        \n",
    "    else:\n",
    "        print('There is no such category, try again')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 : Across datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained with CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(2):\n",
    "    mlpmixer_blocks = keras.Sequential(\n",
    "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
    "    )\n",
    "    mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model\n",
    "    history,accuracy,top_5_accuracy = run_experiment(mlpmixer_classifier)\n",
    "    #Saving Results\n",
    "    #pwd = 'Results_Article/3A/mlpmixer_' + str(date) + '_CF10_' + str(k+1)\n",
    "    pwd = 'Results_Article/3A/mlpmixer_CF10_' + str(k+1)\n",
    "    mlpmixer_classifier.save(pwd)\n",
    "    np.save( pwd + '/history.npy',history.history)\n",
    "    with open(pwd + '/accuracy.pkl','wb') as file:\n",
    "        pickle.dump(accuracy,file)\n",
    "    with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
    "        pickle.dump(top_5_accuracy,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trained with CIFAR 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset for training \n",
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 30s 246ms/step - loss: 5.9549 - acc: 0.0449 - top5-acc: 0.1633 - val_loss: 4.2852 - val_acc: 0.0838 - val_top5-acc: 0.2530 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 3.7323 - acc: 0.1265 - top5-acc: 0.3540 - val_loss: 3.6955 - val_acc: 0.1658 - val_top5-acc: 0.4130 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 3.4536 - acc: 0.1731 - top5-acc: 0.4380 - val_loss: 3.3434 - val_acc: 0.2104 - val_top5-acc: 0.4864 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 3.2946 - acc: 0.2037 - top5-acc: 0.4863 - val_loss: 3.2993 - val_acc: 0.2238 - val_top5-acc: 0.5006 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 3.1404 - acc: 0.2314 - top5-acc: 0.5237 - val_loss: 3.1267 - val_acc: 0.2480 - val_top5-acc: 0.5400 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 3.0393 - acc: 0.2514 - top5-acc: 0.5505 - val_loss: 2.9957 - val_acc: 0.2750 - val_top5-acc: 0.5712 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.9231 - acc: 0.2731 - top5-acc: 0.5757 - val_loss: 2.9300 - val_acc: 0.2866 - val_top5-acc: 0.5782 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.8628 - acc: 0.2847 - top5-acc: 0.5926 - val_loss: 2.7857 - val_acc: 0.3114 - val_top5-acc: 0.6116 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 2.7959 - acc: 0.3016 - top5-acc: 0.6072 - val_loss: 2.7675 - val_acc: 0.3110 - val_top5-acc: 0.6220 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.7211 - acc: 0.3141 - top5-acc: 0.6252 - val_loss: 2.7343 - val_acc: 0.3272 - val_top5-acc: 0.6254 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.6662 - acc: 0.3241 - top5-acc: 0.6406 - val_loss: 2.6346 - val_acc: 0.3410 - val_top5-acc: 0.6486 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.6222 - acc: 0.3356 - top5-acc: 0.6485 - val_loss: 2.6095 - val_acc: 0.3418 - val_top5-acc: 0.6546 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.5867 - acc: 0.3430 - top5-acc: 0.6542 - val_loss: 2.5997 - val_acc: 0.3460 - val_top5-acc: 0.6622 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.5491 - acc: 0.3521 - top5-acc: 0.6626 - val_loss: 2.5707 - val_acc: 0.3560 - val_top5-acc: 0.6688 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 2.4828 - acc: 0.3652 - top5-acc: 0.6785 - val_loss: 2.5136 - val_acc: 0.3728 - val_top5-acc: 0.6738 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.4537 - acc: 0.3715 - top5-acc: 0.6853 - val_loss: 2.5332 - val_acc: 0.3588 - val_top5-acc: 0.6696 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 2.4133 - acc: 0.3804 - top5-acc: 0.6938 - val_loss: 2.4975 - val_acc: 0.3752 - val_top5-acc: 0.6860 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.4194 - acc: 0.3797 - top5-acc: 0.6935 - val_loss: 2.3784 - val_acc: 0.3934 - val_top5-acc: 0.7042 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.4186 - acc: 0.3797 - top5-acc: 0.6970 - val_loss: 2.3481 - val_acc: 0.4074 - val_top5-acc: 0.7182 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.3543 - acc: 0.3897 - top5-acc: 0.7066 - val_loss: 2.3777 - val_acc: 0.4056 - val_top5-acc: 0.7018 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.3174 - acc: 0.3987 - top5-acc: 0.7154 - val_loss: 2.4667 - val_acc: 0.3942 - val_top5-acc: 0.7012 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 2.3466 - acc: 0.3993 - top5-acc: 0.7108 - val_loss: 2.5206 - val_acc: 0.3846 - val_top5-acc: 0.6922 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 7.1884 - acc: 0.2268 - top5-acc: 0.4844 - val_loss: 3.3004 - val_acc: 0.2892 - val_top5-acc: 0.6054 - lr: 0.0050\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.4327 - acc: 0.3864 - top5-acc: 0.6986 - val_loss: 2.3076 - val_acc: 0.4126 - val_top5-acc: 0.7240 - lr: 0.0050\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.1611 - acc: 0.4333 - top5-acc: 0.7439 - val_loss: 2.2488 - val_acc: 0.4318 - val_top5-acc: 0.7332 - lr: 0.0050\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.0844 - acc: 0.4495 - top5-acc: 0.7567 - val_loss: 2.2129 - val_acc: 0.4410 - val_top5-acc: 0.7430 - lr: 0.0050\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.0374 - acc: 0.4629 - top5-acc: 0.7671 - val_loss: 2.2133 - val_acc: 0.4378 - val_top5-acc: 0.7406 - lr: 0.0050\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 2.0106 - acc: 0.4649 - top5-acc: 0.7726 - val_loss: 2.2302 - val_acc: 0.4330 - val_top5-acc: 0.7388 - lr: 0.0050\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.9915 - acc: 0.4686 - top5-acc: 0.7748 - val_loss: 2.2031 - val_acc: 0.4394 - val_top5-acc: 0.7508 - lr: 0.0050\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.9827 - acc: 0.4701 - top5-acc: 0.7789 - val_loss: 2.1750 - val_acc: 0.4480 - val_top5-acc: 0.7416 - lr: 0.0050\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.9661 - acc: 0.4743 - top5-acc: 0.7818 - val_loss: 2.1746 - val_acc: 0.4478 - val_top5-acc: 0.7496 - lr: 0.0050\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.9430 - acc: 0.4797 - top5-acc: 0.7857 - val_loss: 2.1919 - val_acc: 0.4406 - val_top5-acc: 0.7452 - lr: 0.0050\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.9289 - acc: 0.4805 - top5-acc: 0.7880 - val_loss: 2.1991 - val_acc: 0.4468 - val_top5-acc: 0.7502 - lr: 0.0050\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.9222 - acc: 0.4834 - top5-acc: 0.7895 - val_loss: 2.1801 - val_acc: 0.4450 - val_top5-acc: 0.7508 - lr: 0.0050\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.9085 - acc: 0.4859 - top5-acc: 0.7908 - val_loss: 2.1602 - val_acc: 0.4488 - val_top5-acc: 0.7540 - lr: 0.0050\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.8916 - acc: 0.4909 - top5-acc: 0.7927 - val_loss: 2.2080 - val_acc: 0.4506 - val_top5-acc: 0.7464 - lr: 0.0050\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.8915 - acc: 0.4881 - top5-acc: 0.7949 - val_loss: 2.1739 - val_acc: 0.4582 - val_top5-acc: 0.7514 - lr: 0.0050\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.8951 - acc: 0.4888 - top5-acc: 0.7958 - val_loss: 2.1560 - val_acc: 0.4492 - val_top5-acc: 0.7580 - lr: 0.0050\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 1.8791 - acc: 0.4924 - top5-acc: 0.7993 - val_loss: 2.1442 - val_acc: 0.4538 - val_top5-acc: 0.7566 - lr: 0.0050\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 1.8781 - acc: 0.4920 - top5-acc: 0.7987 - val_loss: 2.1865 - val_acc: 0.4436 - val_top5-acc: 0.7528 - lr: 0.0050\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.8804 - acc: 0.4936 - top5-acc: 0.8002 - val_loss: 2.1744 - val_acc: 0.4544 - val_top5-acc: 0.7510 - lr: 0.0050\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.8637 - acc: 0.4966 - top5-acc: 0.8024 - val_loss: 2.1724 - val_acc: 0.4574 - val_top5-acc: 0.7612 - lr: 0.0050\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.8551 - acc: 0.4965 - top5-acc: 0.8031 - val_loss: 2.1367 - val_acc: 0.4598 - val_top5-acc: 0.7628 - lr: 0.0050\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 20s 233ms/step - loss: 1.8532 - acc: 0.4996 - top5-acc: 0.8031 - val_loss: 2.1572 - val_acc: 0.4564 - val_top5-acc: 0.7604 - lr: 0.0050\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.8320 - acc: 0.5024 - top5-acc: 0.8088 - val_loss: 2.2362 - val_acc: 0.4374 - val_top5-acc: 0.7448 - lr: 0.0050\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.8670 - acc: 0.4964 - top5-acc: 0.8049 - val_loss: 2.1778 - val_acc: 0.4462 - val_top5-acc: 0.7608 - lr: 0.0050\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.8298 - acc: 0.5050 - top5-acc: 0.8088 - val_loss: 2.1879 - val_acc: 0.4530 - val_top5-acc: 0.7596 - lr: 0.0050\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.8112 - acc: 0.5093 - top5-acc: 0.8122 - val_loss: 2.1490 - val_acc: 0.4660 - val_top5-acc: 0.7634 - lr: 0.0050\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 1.5983 - acc: 0.5562 - top5-acc: 0.8457 - val_loss: 2.0746 - val_acc: 0.4800 - val_top5-acc: 0.7750 - lr: 0.0025\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.5504 - acc: 0.5706 - top5-acc: 0.8535 - val_loss: 2.0322 - val_acc: 0.4876 - val_top5-acc: 0.7780 - lr: 0.0025\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 1.9821 - acc: 0.5021 - top5-acc: 0.7815\n",
      "Test accuracy: 50.21%\n",
      "Test top 5 accuracy: 78.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as layer_normalization_24_layer_call_fn, layer_normalization_24_layer_call_and_return_conditional_losses, layer_normalization_25_layer_call_fn, layer_normalization_25_layer_call_and_return_conditional_losses, layer_normalization_26_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results_Article/3A/mlpmixer_CF100_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results_Article/3A/mlpmixer_CF100_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "88/88 [==============================] - 30s 245ms/step - loss: 5.9199 - acc: 0.0468 - top5-acc: 0.1671 - val_loss: 4.1968 - val_acc: 0.0962 - val_top5-acc: 0.2720 - lr: 0.0050\n",
      "Epoch 2/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 3.8033 - acc: 0.1177 - top5-acc: 0.3373 - val_loss: 3.8455 - val_acc: 0.1546 - val_top5-acc: 0.3812 - lr: 0.0050\n",
      "Epoch 3/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 3.4949 - acc: 0.1661 - top5-acc: 0.4259 - val_loss: 3.3983 - val_acc: 0.1970 - val_top5-acc: 0.4694 - lr: 0.0050\n",
      "Epoch 4/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 3.3274 - acc: 0.1960 - top5-acc: 0.4721 - val_loss: 3.1773 - val_acc: 0.2250 - val_top5-acc: 0.5188 - lr: 0.0050\n",
      "Epoch 5/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 3.1749 - acc: 0.2259 - top5-acc: 0.5163 - val_loss: 3.1870 - val_acc: 0.2386 - val_top5-acc: 0.5322 - lr: 0.0050\n",
      "Epoch 6/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 3.0251 - acc: 0.2528 - top5-acc: 0.5520 - val_loss: 2.9310 - val_acc: 0.2774 - val_top5-acc: 0.5770 - lr: 0.0050\n",
      "Epoch 7/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.9277 - acc: 0.2722 - top5-acc: 0.5766 - val_loss: 2.9440 - val_acc: 0.2804 - val_top5-acc: 0.5834 - lr: 0.0050\n",
      "Epoch 8/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.8506 - acc: 0.2892 - top5-acc: 0.5946 - val_loss: 2.7712 - val_acc: 0.3172 - val_top5-acc: 0.6226 - lr: 0.0050\n",
      "Epoch 9/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.7620 - acc: 0.3077 - top5-acc: 0.6165 - val_loss: 2.6840 - val_acc: 0.3300 - val_top5-acc: 0.6262 - lr: 0.0050\n",
      "Epoch 10/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.7211 - acc: 0.3145 - top5-acc: 0.6230 - val_loss: 2.7655 - val_acc: 0.3138 - val_top5-acc: 0.6320 - lr: 0.0050\n",
      "Epoch 11/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.6627 - acc: 0.3277 - top5-acc: 0.6385 - val_loss: 2.6330 - val_acc: 0.3390 - val_top5-acc: 0.6500 - lr: 0.0050\n",
      "Epoch 12/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.6299 - acc: 0.3331 - top5-acc: 0.6475 - val_loss: 2.6166 - val_acc: 0.3472 - val_top5-acc: 0.6546 - lr: 0.0050\n",
      "Epoch 13/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.5835 - acc: 0.3445 - top5-acc: 0.6552 - val_loss: 2.5612 - val_acc: 0.3544 - val_top5-acc: 0.6670 - lr: 0.0050\n",
      "Epoch 14/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.5482 - acc: 0.3505 - top5-acc: 0.6661 - val_loss: 2.5159 - val_acc: 0.3618 - val_top5-acc: 0.6762 - lr: 0.0050\n",
      "Epoch 15/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.5139 - acc: 0.3577 - top5-acc: 0.6706 - val_loss: 2.5472 - val_acc: 0.3540 - val_top5-acc: 0.6724 - lr: 0.0050\n",
      "Epoch 16/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.4971 - acc: 0.3627 - top5-acc: 0.6777 - val_loss: 2.5715 - val_acc: 0.3570 - val_top5-acc: 0.6768 - lr: 0.0050\n",
      "Epoch 17/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.4261 - acc: 0.3761 - top5-acc: 0.6914 - val_loss: 2.4366 - val_acc: 0.3774 - val_top5-acc: 0.7006 - lr: 0.0050\n",
      "Epoch 18/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 13.3189 - acc: 0.2817 - top5-acc: 0.5387 - val_loss: 25.9403 - val_acc: 0.0462 - val_top5-acc: 0.1560 - lr: 0.0050\n",
      "Epoch 19/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 9.0909 - acc: 0.1524 - top5-acc: 0.3685 - val_loss: 3.0671 - val_acc: 0.2648 - val_top5-acc: 0.5554 - lr: 0.0050\n",
      "Epoch 20/50\n",
      "88/88 [==============================] - 20s 231ms/step - loss: 2.8983 - acc: 0.2834 - top5-acc: 0.5858 - val_loss: 2.7410 - val_acc: 0.3200 - val_top5-acc: 0.6340 - lr: 0.0050\n",
      "Epoch 21/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.6704 - acc: 0.3254 - top5-acc: 0.6381 - val_loss: 2.6160 - val_acc: 0.3402 - val_top5-acc: 0.6580 - lr: 0.0050\n",
      "Epoch 22/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.5296 - acc: 0.3572 - top5-acc: 0.6689 - val_loss: 2.5551 - val_acc: 0.3594 - val_top5-acc: 0.6760 - lr: 0.0050\n",
      "Epoch 23/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.4031 - acc: 0.3813 - top5-acc: 0.6933 - val_loss: 2.4485 - val_acc: 0.3822 - val_top5-acc: 0.6968 - lr: 0.0025\n",
      "Epoch 24/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.3464 - acc: 0.3927 - top5-acc: 0.7072 - val_loss: 2.3920 - val_acc: 0.3914 - val_top5-acc: 0.7044 - lr: 0.0025\n",
      "Epoch 25/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.3058 - acc: 0.4002 - top5-acc: 0.7142 - val_loss: 2.3691 - val_acc: 0.3974 - val_top5-acc: 0.7044 - lr: 0.0025\n",
      "Epoch 26/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.2597 - acc: 0.4117 - top5-acc: 0.7244 - val_loss: 2.3404 - val_acc: 0.3994 - val_top5-acc: 0.7164 - lr: 0.0025\n",
      "Epoch 27/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.2293 - acc: 0.4169 - top5-acc: 0.7290 - val_loss: 2.3159 - val_acc: 0.4090 - val_top5-acc: 0.7184 - lr: 0.0025\n",
      "Epoch 28/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.1967 - acc: 0.4244 - top5-acc: 0.7366 - val_loss: 2.3067 - val_acc: 0.4112 - val_top5-acc: 0.7200 - lr: 0.0025\n",
      "Epoch 29/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.1649 - acc: 0.4311 - top5-acc: 0.7437 - val_loss: 2.2883 - val_acc: 0.4152 - val_top5-acc: 0.7270 - lr: 0.0025\n",
      "Epoch 30/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.1419 - acc: 0.4348 - top5-acc: 0.7498 - val_loss: 2.2560 - val_acc: 0.4230 - val_top5-acc: 0.7270 - lr: 0.0025\n",
      "Epoch 31/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.1186 - acc: 0.4424 - top5-acc: 0.7521 - val_loss: 2.2558 - val_acc: 0.4182 - val_top5-acc: 0.7288 - lr: 0.0025\n",
      "Epoch 32/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.0894 - acc: 0.4465 - top5-acc: 0.7576 - val_loss: 2.2164 - val_acc: 0.4320 - val_top5-acc: 0.7362 - lr: 0.0025\n",
      "Epoch 33/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.0694 - acc: 0.4533 - top5-acc: 0.7614 - val_loss: 2.2105 - val_acc: 0.4314 - val_top5-acc: 0.7392 - lr: 0.0025\n",
      "Epoch 34/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 2.0525 - acc: 0.4564 - top5-acc: 0.7654 - val_loss: 2.2056 - val_acc: 0.4350 - val_top5-acc: 0.7440 - lr: 0.0025\n",
      "Epoch 35/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 2.0350 - acc: 0.4576 - top5-acc: 0.7704 - val_loss: 2.1851 - val_acc: 0.4330 - val_top5-acc: 0.7408 - lr: 0.0025\n",
      "Epoch 36/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 2.0145 - acc: 0.4628 - top5-acc: 0.7710 - val_loss: 2.1971 - val_acc: 0.4290 - val_top5-acc: 0.7392 - lr: 0.0025\n",
      "Epoch 37/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 2.0006 - acc: 0.4668 - top5-acc: 0.7720 - val_loss: 2.1543 - val_acc: 0.4440 - val_top5-acc: 0.7480 - lr: 0.0025\n",
      "Epoch 38/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.9743 - acc: 0.4720 - top5-acc: 0.7796 - val_loss: 2.1729 - val_acc: 0.4414 - val_top5-acc: 0.7506 - lr: 0.0025\n",
      "Epoch 39/50\n",
      "88/88 [==============================] - 20s 233ms/step - loss: 1.9777 - acc: 0.4732 - top5-acc: 0.7802 - val_loss: 2.1569 - val_acc: 0.4438 - val_top5-acc: 0.7556 - lr: 0.0025\n",
      "Epoch 40/50\n",
      "88/88 [==============================] - 21s 234ms/step - loss: 1.9495 - acc: 0.4798 - top5-acc: 0.7842 - val_loss: 2.1378 - val_acc: 0.4460 - val_top5-acc: 0.7508 - lr: 0.0025\n",
      "Epoch 41/50\n",
      "88/88 [==============================] - 21s 233ms/step - loss: 1.9401 - acc: 0.4794 - top5-acc: 0.7854 - val_loss: 2.1269 - val_acc: 0.4512 - val_top5-acc: 0.7482 - lr: 0.0025\n",
      "Epoch 42/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.9167 - acc: 0.4840 - top5-acc: 0.7910 - val_loss: 2.1487 - val_acc: 0.4522 - val_top5-acc: 0.7460 - lr: 0.0025\n",
      "Epoch 43/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.9158 - acc: 0.4865 - top5-acc: 0.7892 - val_loss: 2.1334 - val_acc: 0.4562 - val_top5-acc: 0.7520 - lr: 0.0025\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 20s 232ms/step - loss: 1.8917 - acc: 0.4923 - top5-acc: 0.7962 - val_loss: 2.1546 - val_acc: 0.4496 - val_top5-acc: 0.7542 - lr: 0.0025\n",
      "Epoch 45/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.8985 - acc: 0.4845 - top5-acc: 0.7950 - val_loss: 2.1273 - val_acc: 0.4492 - val_top5-acc: 0.7540 - lr: 0.0025\n",
      "Epoch 46/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.8888 - acc: 0.4920 - top5-acc: 0.7947 - val_loss: 2.1287 - val_acc: 0.4514 - val_top5-acc: 0.7536 - lr: 0.0025\n",
      "Epoch 47/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.7778 - acc: 0.5180 - top5-acc: 0.8149 - val_loss: 2.0581 - val_acc: 0.4704 - val_top5-acc: 0.7698 - lr: 0.0012\n",
      "Epoch 48/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.7528 - acc: 0.5224 - top5-acc: 0.8193 - val_loss: 2.0621 - val_acc: 0.4722 - val_top5-acc: 0.7672 - lr: 0.0012\n",
      "Epoch 49/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.7419 - acc: 0.5242 - top5-acc: 0.8198 - val_loss: 2.0626 - val_acc: 0.4752 - val_top5-acc: 0.7630 - lr: 0.0012\n",
      "Epoch 50/50\n",
      "88/88 [==============================] - 20s 232ms/step - loss: 1.7291 - acc: 0.5286 - top5-acc: 0.8215 - val_loss: 2.0697 - val_acc: 0.4748 - val_top5-acc: 0.7656 - lr: 0.0012\n",
      "313/313 [==============================] - 15s 47ms/step - loss: 1.9954 - acc: 0.4830 - top5-acc: 0.7766\n",
      "Test accuracy: 48.3%\n",
      "Test top 5 accuracy: 77.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as layer_normalization_36_layer_call_fn, layer_normalization_36_layer_call_and_return_conditional_losses, layer_normalization_37_layer_call_fn, layer_normalization_37_layer_call_and_return_conditional_losses, layer_normalization_38_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results_Article/3A/mlpmixer_CF100_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results_Article/3A/mlpmixer_CF100_2\\assets\n"
     ]
    }
   ],
   "source": [
    "for k in range(2):\n",
    "    mlpmixer_blocks = keras.Sequential(\n",
    "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
    "    )\n",
    "    mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model\n",
    "    history,accuracy,top_5_accuracy = run_experiment(mlpmixer_classifier)\n",
    "    #Saving Results\n",
    "    pwd = 'Results_Article/3A/mlpmixer_CF100_' + str(k+1)\n",
    "    mlpmixer_classifier.save(pwd)\n",
    "    np.save( pwd + '/history.npy',history.history)\n",
    "    with open(pwd + '/accuracy.pkl','wb') as file:\n",
    "        pickle.dump(accuracy,file)\n",
    "    with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
    "        pickle.dump(top_5_accuracy,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Found untraced functions such as layer_normalization_48_layer_call_fn, layer_normalization_48_layer_call_and_return_conditional_losses, layer_normalization_49_layer_call_fn, layer_normalization_49_layer_call_and_return_conditional_losses, layer_normalization_50_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results_Article/3A/mlpmixer_Untrained\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Results_Article/3A/mlpmixer_Untrained\\assets\n"
     ]
    }
   ],
   "source": [
    "mlpmixer_blocks = keras.Sequential(\n",
    "[MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
    ")\n",
    "mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model\n",
    "pwd = 'Results_Article/3A/mlpmixer_Untrained'\n",
    "mlpmixer_classifier.save(pwd)\n",
    "#np.save( pwd + '/history_' + str(date) +'.npy',history.history)\n",
    "#with open(pwd + '/accuracy.pkl','wb') as file:\n",
    "#    pickle.dump(accuracy,file)\n",
    "#with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
    "#    pickle.dump(top_5_accuracy,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the path below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program_Files\\Anaconda3\\envs\\AI\\lib\\site-packages\\keras\\saving\\saved_model\\load.py:115: RuntimeWarning: Unexpected end-group tag: Not all data was converted\n",
      "  metadata.ParseFromString(file_content)\n"
     ]
    }
   ],
   "source": [
    "path = 'Results_Article/3A/mlpmixer_'\n",
    "global_models = list()\n",
    "#Call the folder\n",
    "C10_mlpmixer_1 = tf.keras.models.load_model(path + 'CF10_1')\n",
    "global_models.append(C10_mlpmixer_1)\n",
    "C10_mlpmixer_2 = tf.keras.models.load_model(path + 'CF10_2')\n",
    "global_models.append(C10_mlpmixer_2)\n",
    "C100_mlpmixer_1 = tf.keras.models.load_model(path + 'CF100_1')\n",
    "global_models.append(C100_mlpmixer_1)\n",
    "C100_mlpmixer_2 = tf.keras.models.load_model(path + 'CF100_2')\n",
    "global_models.append(C100_mlpmixer_2)\n",
    "Unt_mlpmixer = tf.keras.models.load_model(path + 'Untrained')\n",
    "global_models.append(Unt_mlpmixer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.saved_model.load.Loader._recreate_base_user_object.<locals>._UserObject"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(C10_mlpmixer_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intialization before testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def across_datasets(global_models,batch_prepro,type,sigma):\n",
    "    total_activations = list()\n",
    "    plot_raw = list()\n",
    "    plot_total = list()\n",
    "    for k in range(len(global_models)):\n",
    "        tested_model = global_models[k] \n",
    "        ave_mixer_activations = Prom_Mixer_Activations_Blocks(tested_model,batch_prepro)\n",
    "        total_activations.append(ave_mixer_activations)\n",
    "        \n",
    "    for pairs in set:\n",
    "        comp_1 = total_activations[pairs[0]]\n",
    "        comp_2 = total_activations[pairs[1]]\n",
    "        plot_raw = list()\n",
    "        for i in range(num_blocks):\n",
    "            if type == 'rbf':\n",
    "                inter_row = cka(gram_rbf(comp_1[i],sigma),gram_rbf(comp_2[i],sigma))\n",
    "            elif type == 'linear':\n",
    "                inter_row = cka(gram_linear(comp_1[i]),gram_linear(comp_2[i]))\n",
    "            plot_raw.append(inter_row)\n",
    "        plot_total.append(plot_raw)\n",
    "    return plot_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The experiment on the paper is with the linear type!\n",
    "#######################################################\n",
    "\n",
    "sigma = None\n",
    "type = 'linear'\n",
    "\n",
    "#Pairs of models that are going to be compared according to the order in the matrix\n",
    "set = [[0,1],[2,3],[0,2],[0,4],[2,4]]\n",
    "label_set = ['CIFAR-10 Net vs. CIFAR-10 Net',\n",
    "            'CIFAR-100 Net vs. CIFAR-100 Net',\n",
    "            'CIFAR-10 Net vs. CIFAR-100 Net ',\n",
    "            'CIFAR-10 Net vs. Untrained',\n",
    "            'CIFAR-100 Net vs. Untrained']\n",
    "num_models_set = len(set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on CIFAR 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for testing\n",
    "\n",
    "num_classes = 10\n",
    "input_shape = (32, 32, 3)\n",
    "(x_train, y_train), _ = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Once to Avoid Randomness after setting the testing dataset\n",
    "batch_prepro = Batch_Preprocessing(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001962643F040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001962643F040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001962643F5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001962643F5E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "# The experiment on the paper is with the linear type\n",
    "plot_total_1 = across_datasets(global_models,batch_prepro,type,sigma)\n",
    "with open('Results_Article/3A/plot_total_C10.pkl','wb') as file:\n",
    "    pickle.dump(plot_total_1,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on CIFAR 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for testing\n",
    "\n",
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "(x_train, y_train), _ = keras.datasets.cifar100.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Once to Avoid Randomness after setting the testing dataset\n",
    "batch_prepro = Batch_Preprocessing(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The experiment on the paper is with the linear type\n",
    "plot_total_2 = across_datasets(global_models,batch_prepro,type,sigma)\n",
    "with open('Results_Article/3A/plot_total_C100.pkl','wb') as file:\n",
    "    pickle.dump(plot_total_2,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tested on MNIST: (Appendix 6A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for testing\n",
    "\n",
    "#num_classes = 10\n",
    "#input_shape = (28, 28)\n",
    "#(x_train, y_train), _ = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Once to Avoid Randomness after setting the testing dataset\n",
    "#batch_prepro = Batch_Preprocessing(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_total_3 = across_datasets(global_models,batch_prepro,type,sigma)\n",
    "#with open('Results_Article/6A/plot_total_MNIST.pkl','wb') as file:\n",
    "#    pickle.dump(plot_total_3,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENT 3: VERIFICATIONS (OPTIONAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'Results_Article/3A'\n",
    "with open(path + '/plot_total_C100.pkl','rb') as file:\n",
    "        tested_plot = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = '_tested_C100'\n",
    "######################################################\n",
    "x = list(range(1,num_blocks+1))\n",
    "for j in range(num_models_set):\n",
    "    plt.plot(x,tested_plot[j], label = label_set[j])\n",
    "plt.xlabel('Layer')\n",
    "plt.ylabel('CKA ('+ type +')')\n",
    "plt.locator_params(axis='x', nbins=num_blocks)\n",
    "plt.title('Similarity on CIFAR-100')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('Results_Article/3A/Similarity_'+ type + name +'.png') \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mlp_image_classification",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
