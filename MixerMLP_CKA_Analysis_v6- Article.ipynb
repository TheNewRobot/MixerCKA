{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zSzgroG_Suq"
      },
      "source": [
        "# Study of Image classification with modern MLP Mixer model and CKA\n",
        "\n",
        "**Author:** [Arturo Flores](https://www.linkedin.com/in/afloresalv/)<br>\n",
        "**Based on (MLP-MIXER):**  https://keras.io/examples/vision/mlp_image_classification/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmtajQ2N_Suw"
      },
      "source": [
        "## Introduction\n",
        "#####################\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This example implements three modern attention-free, multi-layer perceptron (MLP) based models for image\n",
        "classification, demonstrated on the CIFAR-100 dataset:\n",
        "\n",
        "1. The [MLP-Mixer](https://arxiv.org/abs/2105.01601) model, by Ilya Tolstikhin et al., based on two types of MLPs.\n",
        "\n",
        "The purpose of the example is not to compare between these models, as they might perform differently on\n",
        "different datasets with well-tuned hyperparameters. Rather, it is to show simple implementations of their\n",
        "main building blocks.\n",
        "\n",
        "This example requires TensorFlow 2.4 or higher, as well as\n",
        "[TensorFlow Addons](https://www.tensorflow.org/addons/overview),\n",
        "which can be installed using the following command:\n",
        "\n",
        "```shell\n",
        "pip install -U tensorflow-addons\n",
        "update tensorflow core to 2.7.0\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U087DdDw_Suy"
      },
      "source": [
        "# Setup for the MLP-Mixer Architecture\n",
        "\n",
        "################################################################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AnTyoluw_Suz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "import datetime\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUuu2OAS_Su0"
      },
      "source": [
        "## Prepare the data\n",
        "C1FAR 100 = 100 classes, each 600 images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_1Ql-fV_Su1"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "#plt.imshow(x_train[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DAOrIHu_Su2"
      },
      "source": [
        "## Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1iMiVS7o_Su3"
      },
      "outputs": [],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128 # The paper also fine tunes this to 512\n",
        "num_epochs = 50\n",
        "dropout_rate = 0.2\n",
        "image_size = 64  # We'll resize input images to this size. Square\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images. Square\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
        "embedding_dim = 256  # Number of hidden units.\n",
        "num_blocks = 4  # Number of Mixer Layers\n",
        "num_example = 13\n",
        "\n",
        "print(f\"Image size: {image_size} X {image_size} = {image_size ** 2}\")\n",
        "print(f\"Patch size: {patch_size} X {patch_size} = {patch_size ** 2} \")\n",
        "print(f\"Patches per image: {num_patches}\")\n",
        "print(f\"Elements per patch (3 channels): {(patch_size ** 2) * 3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08mpnEZH_Su5"
      },
      "source": [
        "## Build a classification model\n",
        "\n",
        "We implement a method that builds a classifier given the processing blocks. \\\n",
        "Positional Encoding = https://kazemnejad.com/blog/transformer_architecture_positional_encoding/  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ra-bXojQ_Su6"
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_classifier(blocks, embedding_dim, positional_encoding=False):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "    # Augment data. \n",
        "    augmented = data_augmentation(inputs)\n",
        "    # Create patches. \n",
        "    patches = Patches(patch_size, num_patches)(augmented)\n",
        "    # Encode patches to generate a [batch_size, num_patches, embedding_dim] tensor.\n",
        "    x = layers.Dense(units=embedding_dim)(patches)\n",
        "    if positional_encoding:\n",
        "        positions = tf.range(start=0, limit=num_patches, delta=1)\n",
        "        position_embedding = layers.Embedding(\n",
        "            input_dim=num_patches, output_dim=embedding_dim\n",
        "        )(positions)\n",
        "        x = x + position_embedding\n",
        "    # Process x using the module blocks. ## (sequential_82)\n",
        "    x = blocks(x)\n",
        "    # Apply global average pooling to generate a [batch_size, embedding_dim] representation tensor. \n",
        "    representation = layers.GlobalAveragePooling1D()(x)\n",
        "    # Apply dropout.\n",
        "    representation = layers.Dropout(rate=dropout_rate)(representation)\n",
        "    # Compute logits outputs.\n",
        "    logits = layers.Dense(num_classes)(representation) \n",
        "    # Create the Keras model.\n",
        "    return keras.Model(inputs=inputs, outputs=logits)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpQFU8H__Su8"
      },
      "source": [
        "## Define an experiment\n",
        "\n",
        "We implement a utility function to compile, train, and evaluate a given model. \\\n",
        "Adam Algorithm with Weight Decay: https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/AdamW \\\n",
        "Losses: https://keras.io/api/losses/ \\\n",
        "Reduce learning rate: https://keras.io/api/callbacks/reduce_lr_on_plateau/ \\\n",
        "Logits: https://www.youtube.com/watch?v=icQaFxKa_J0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E1zD2BY_Su8"
      },
      "outputs": [],
      "source": [
        "\n",
        "def run_experiment(model):\n",
        "    # Create Adam optimizer with weight decay. Regularization that penalizes the increase of weight - with a facto alpha - to correct the overfitting\n",
        "    optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay,\n",
        "    )\n",
        "    # Compile the model.\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        #Negative Log Likelihood = Categorical Cross Entropy\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[\n",
        "            keras.metrics.SparseCategoricalAccuracy(name=\"acc\"),\n",
        "            keras.metrics.SparseTopKCategoricalAccuracy(5, name=\"top5-acc\"),\n",
        "        ],\n",
        "    )\n",
        "    # Create a learning rate scheduler callback.\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "        monitor=\"val_loss\", factor=0.5, patience=5\n",
        "    )\n",
        "    # Create an early stopping regularization callback. \n",
        "    # It ends at a point that corresponds to a minimum of the L2-regularized objective\n",
        "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", patience=10, restore_best_weights=True\n",
        "    )\n",
        "    # Fit the model.\n",
        "    history = model.fit(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=num_epochs,\n",
        "        validation_split=0.1,\n",
        "        callbacks=[early_stopping, reduce_lr],\n",
        "    )\n",
        "\n",
        "    _, accuracy, top_5_accuracy = model.evaluate(x_test, y_test)\n",
        "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
        "    print(f\"Test top 5 accuracy: {round(top_5_accuracy * 100, 2)}%\")\n",
        "\n",
        "    # Return history to plot learning curves.\n",
        "    return history, accuracy, top_5_accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxeE0cmM_Su9"
      },
      "source": [
        "## Use data augmentation\n",
        "Their state is not set during training; it must be set before training, either by initializing them from a precomputed constant, or by \"adapting\" them on data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zh6hFPWX_Su-"
      },
      "outputs": [],
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.Normalization(),\n",
        "        layers.Resizing(image_size, image_size),\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomZoom(\n",
        "            height_factor=0.2, width_factor=0.2\n",
        "        ),\n",
        "    ],\n",
        "    name=\"data_augmentation\",\n",
        ")\n",
        "# Compute the mean and the variance of the training data for normalization.\n",
        "data_augmentation.layers[0].adapt(x_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G77cUgiu_Su-"
      },
      "source": [
        "## Implement patch extraction as a layer\n",
        "Atributes and heritage: https://pythones.net/funcion-super-en-python-bien-explicada-ejemplos-oop/ \\\n",
        "Extract Patches: https://www.tensorflow.org/api_docs/python/tf/image/extract_patches \\\n",
        "Reshape: https://www.tensorflow.org/api_docs/python/tf/reshape \\\n",
        "If one component of shape is the special value -1, the size of that dimension is computed so that the total size remains constant. \\\n",
        "Preprocessing data: https://www.tensorflow.org/guide/keras/preprocessing_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYKNktXe_Su_"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Patches(layers.Layer):\n",
        "    def __init__(self, patch_size, num_patches):\n",
        "        super(Patches, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = num_patches\n",
        "\n",
        "    def call(self, images):\n",
        "        #Extract the shape dimension in the position 0 = columns\n",
        "        batch_size = tf.shape(images)[0]\n",
        "        patches = tf.image.extract_patches(\n",
        "            images=images,\n",
        "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
        "            #Without overlapping, stride horizontally and vertically\n",
        "            strides=[1, self.patch_size, self.patch_size, 1],\n",
        "            #Rate: Dilation factor [1 1* 1* 1] controls the spacing between the kernel points.\n",
        "            rates=[1, 1, 1, 1],\n",
        "            #Patches contained in the images are considered, no zero padding\n",
        "            padding=\"VALID\",\n",
        "        )\n",
        "        #shape[-1], number of colummns, as well as shape[0]\n",
        "        patch_dims = patches.shape[-1]\n",
        "        patches = tf.reshape(patches, [batch_size, self.num_patches, patch_dims])\n",
        "        return patches\n",
        "\n",
        "    def get_config(self):\n",
        "        config = super(Patches, self).get_config().copy()\n",
        "        config.update ({\n",
        "            'patch_size' : self.patch_size ,\n",
        "            'num_patches' : self.num_patches\n",
        "        })\n",
        "        return config\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7yehcSS_Su_"
      },
      "source": [
        "## The MLP-Mixer model\n",
        "\n",
        "The MLP-Mixer is an architecture based exclusively on\n",
        "multi-layer perceptrons (MLPs), that contains two types of MLP layers:\n",
        "\n",
        "1. One applied independently to image patches, which mixes the per-location features.\n",
        "2. The other applied across patches (along channels), which mixes spatial information.\n",
        "\n",
        "This is similar to a [depthwise separable convolution based model](https://arxiv.org/pdf/1610.02357.pdf)\n",
        "such as the Xception model, but with two chained dense transforms, no max pooling, and layer normalization\n",
        "instead of batch normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvwg4e2n_SvA"
      },
      "source": [
        "### Implement the MLP-Mixer module"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dT6wVEki_SvA"
      },
      "outputs": [],
      "source": [
        "\n",
        "class MLPMixerLayer(layers.Layer):\n",
        "    def __init__(self, num_patches, embedding_dim, dropout_rate, *args, **kwargs):\n",
        "        super(MLPMixerLayer, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.mlp1 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=num_patches),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.mlp2 = keras.Sequential(\n",
        "            [\n",
        "                layers.Dense(units=num_patches),\n",
        "                tfa.layers.GELU(),\n",
        "                layers.Dense(units=embedding_dim),\n",
        "                layers.Dropout(rate=dropout_rate),\n",
        "            ]\n",
        "        )\n",
        "        self.normalize = layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        # Apply layer normalization.\n",
        "        x = self.normalize(inputs)\n",
        "        # Transpose inputs from [num_batches, num_patches, hidden_units] to [num_batches, hidden_units, num_patches].\n",
        "        x_channels = tf.linalg.matrix_transpose(x)\n",
        "        # Apply mlp1 on each channel independently.\n",
        "        mlp1_outputs = self.mlp1(x_channels)\n",
        "        # Transpose mlp1_outputs from [num_batches, hidden_dim, num_patches] to [num_batches, num_patches, hidden_units].\n",
        "        mlp1_outputs = tf.linalg.matrix_transpose(mlp1_outputs)\n",
        "        # Add skip connection.\n",
        "        x = mlp1_outputs + inputs\n",
        "        # Apply layer normalization.\n",
        "        x_patches = self.normalize(x)\n",
        "        # Apply mlp2 on each patch independtenly.\n",
        "        mlp2_outputs = self.mlp2(x_patches)\n",
        "        # Add skip connection.\n",
        "        x = x + mlp2_outputs\n",
        "        return x\n",
        "\n",
        "    def get_config(self): \n",
        "        config = super(MLPMixerLayer, self).get_config().copy()\n",
        "        config.update ({\n",
        "            'num_patches' : num_patches,\n",
        "            'embedding_dim' : embedding_dim,\n",
        "            'dropout_rate' : dropout_rate,\n",
        "        })\n",
        "        return config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUiufq92_SvA"
      },
      "source": [
        "## Build, train, and evaluate the MLP-Mixer model\n",
        "\n",
        "Note that training the model with the current settings on a V100 GPUs\n",
        "takes around 8 seconds per epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Report: Learning Curve\n",
        "def curves(history):\n",
        "    ymax1 = min(history[\"loss\"])\n",
        "    xmax1 = history[\"loss\"].index(ymax1)\n",
        "    ymax2 = min(history[\"val_loss\"])\n",
        "    xmax2 = history[\"val_loss\"].index(ymax2)\n",
        "    plt.title(\"Cross Entropy Loss\")\n",
        "    plt.plot(history[\"loss\"], color = 'blue', label = 'Training')\n",
        "    plt.plot(history[\"val_loss\"], color = 'orange', label = 'Testing')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.annotate('Max:' + str(round(ymax1,2)) , xy = (xmax1, ymax1), xytext = (xmax1*0.93, 1.07*ymax1), \n",
        "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
        "    plt.annotate('Max:' + str(round(ymax2,2)) , xy = (xmax2, ymax2), xytext = (xmax2*0.93, 1.07*ymax2), \n",
        "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
        "    plt.xlim([0,num_epochs])\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    # Graph accuracy\n",
        "    ymax3 = max(history[\"acc\"])\n",
        "    xmax3 = history[\"acc\"].index(ymax3)\n",
        "    ymax4 = max(history[\"val_acc\"])\n",
        "    xmax4 = history[\"val_acc\"].index(ymax4)\n",
        "    ymax5 = max(history[\"top5-acc\"])\n",
        "    xmax5 = history[\"top5-acc\"].index(ymax5)\n",
        "    ymax6 = max(history[\"val_top5-acc\"])\n",
        "    xmax6 = history[\"val_top5-acc\"].index(ymax6)\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.title('Classification accuracy')\n",
        "    plt.plot(history['acc'], color = 'blue', label = 'Training')\n",
        "    plt.plot(history['val_acc'], color = 'orange', label = 'Testing')\n",
        "    plt.annotate('Max:' + str(round(ymax3,2)) , xy = (xmax3, ymax3), xytext = (xmax3*0.93, 1.2*ymax3), \n",
        "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
        "    plt.annotate('Max:' + str(round(ymax4,2)) , xy = (xmax4, ymax4), xytext = (xmax4*0.93, 0.7*ymax4), \n",
        "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
        "    plt.subplot(2,1,2)\n",
        "    plt.title('Classification top5-acc')\n",
        "    plt.plot(history['top5-acc'], color = 'blue', label = 'Training')\n",
        "    plt.plot(history['val_top5-acc'], color = 'orange', label = 'Testing')\n",
        "    plt.annotate('Max:' + str(round(ymax5,2)) , xy = (xmax5, ymax5), xytext = (xmax5*0.93, 1.2*ymax5), \n",
        "                    arrowprops=dict(facecolor='blue', headwidth= 6, headlength =9))\n",
        "    plt.annotate('Max:' + str(round(ymax6,2)) , xy = (xmax6, ymax6), xytext = (xmax6*0.87, 1.2*ymax6), \n",
        "                    arrowprops=dict(facecolor='goldenrod', headwidth= 6, headlength =9))\n",
        "    plt.xlim([0,num_epochs])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.suptitle(\"Learning Curves\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Obtain activations + Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preprocessing Layers + Patches + One dense layer\n",
        "def Preprocessing(num_example):\n",
        "    augmented = data_augmentation(x_train[num_example])\n",
        "    b = Patches(patch_size, num_patches)(augmented)\n",
        "    a = layers.Dense(units=embedding_dim)(b)\n",
        "    inp = tf.reshape(a,[1,embedding_dim,num_patches])\n",
        "    return inp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creates a random vector with indexes of a random batch selection and also regularizes the selected batch\n",
        "def Batch_Preprocessing(batch_size):\n",
        "    #Vector with the number of Sample of the Xtrain\n",
        "    a  = list(range(0,x_train.shape[0]))\n",
        "    b = random.sample(a,batch_size)\n",
        "    batch_regularization = list()\n",
        "    for i in range(0,batch_size):\n",
        "        inter_result = Preprocessing(b[i])\n",
        "        batch_regularization.append(inter_result)\n",
        "    return batch_regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_out(result,layer_number,example):\n",
        "    fig, (ax1, ax2)= plt.subplots(1,2)\n",
        "    ax1.imshow(x_train[example])\n",
        "    ax1.set_title('Original_Figure, Class: #' + str(y_train[example][0]))\n",
        "    ax2.imshow(result[layer_number])\n",
        "    ax2.set_title('Activations of MLP block of the Mixer #: '+ '\"' + str(layer_number) + '\"')\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Mixer_Layer_Outputs(model_input, model_output,example):\n",
        "    #The input is fixed to the beginning of the mlp blocks\n",
        "    intermediate_model=tf.keras.models.Model(inputs=model_input.input,outputs=model_output.output)\n",
        "    #This reshape is necessary for the input of the model\n",
        "    example = tf.reshape(example,[1,num_patches,embedding_dim])\n",
        "    #Inference\n",
        "    intermediate_prediction =intermediate_model.predict(example)\n",
        "    #This reshape is standardize the output\n",
        "    layactivation = intermediate_prediction.reshape((embedding_dim,num_patches))\n",
        "    return layactivation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Computes the outputs of each MLP-mixer Layer\n",
        "def Mixer_Activations(model, example):\n",
        "    total_activations = list()\n",
        "    for i in range(num_blocks):\n",
        "        model_input = model.layers[4].layers[0]\n",
        "        model_output = model.layers[4].layers[i]\n",
        "        int_total_activations = Mixer_Layer_Outputs(model_input, model_output, example)\n",
        "        total_activations.append(int_total_activations)\n",
        "    return  total_activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Average of layer's activation\n",
        "def Prom_Mixer_Activations_Blocks(model,batch_regularization):\n",
        "    sum = list()\n",
        "    for i in range(0,num_blocks):\n",
        "        sum_raw = np.zeros((embedding_dim,num_patches))\n",
        "        sum.append(sum_raw)\n",
        "    for i in range(0,batch_size):\n",
        "        mixer_raw = Mixer_Activations(model,batch_regularization[i])\n",
        "        for i in range(0,num_blocks):\n",
        "            sum[i] = np.add(mixer_raw[i],sum[i])\n",
        "    prom_mixer_activations = [ (number / batch_size)  for number in sum]\n",
        "    return prom_mixer_activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CKA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Files imported from the sleected GitHub https://cka-similarity.github.io/\n",
        "from CKA_Google import *\n",
        "import seaborn as sns \n",
        "import random\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculates a heatmap according to the selection of a CKA_Kernel (preferred) or CKA_Linear\n",
        "def Heatmap(result,type,sigma):\n",
        "    dim = len(result)\n",
        "    k = (dim - 1)\n",
        "    heatmap_CKA = np.zeros((dim,dim))\n",
        "    for i in range(0,dim):\n",
        "        tr = (dim - 1)\n",
        "        for j in range(0,dim):\n",
        "            if type == 'kernel':\n",
        "                heatmap_CKA[k][tr] = cka(gram_rbf(result[i],sigma),gram_rbf(result[j],sigma))\n",
        "            elif type == 'linear':\n",
        "                heatmap_CKA[k][tr] = cka(gram_linear(result[i]),gram_linear(result[j])) \n",
        "            else:\n",
        "                print('There is no such category, try again')\n",
        "                break\n",
        "\n",
        "            tr -= 1\n",
        "        k -= 1\n",
        "    #print('CKA' + type + 'calculated')\n",
        "    return heatmap_CKA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Average of heatmaps (obsolet)\n",
        "def Prom_Mixer_Heatmaps(batch_result,type):\n",
        "    mat_heatmaps = list()\n",
        "    prom_mixer_heatmap_raw = np.zeros((num_blocks,num_blocks))\n",
        "    for i in range(0,batch_size):\n",
        "        mixer_activations_raw = Mixer_Activations(batch_result[i])\n",
        "        heatmap_raw = Heatmap(mixer_activations_raw, type)\n",
        "        mat_heatmaps.append(heatmap_raw)\n",
        "        prom_mixer_heatmap_raw = np.add(heatmap_raw,prom_mixer_heatmap_raw)\n",
        "    prom_mixer_heatmap =  prom_mixer_heatmap_raw/batch_size  \n",
        "    return prom_mixer_heatmap,mat_heatmaps\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_Heatmap(heatmap,type,bl):\n",
        "    #Number of thats that you want to appear in the plot\n",
        "    tri = 4\n",
        "    if type == 'kernel' or type == 'linear':\n",
        "        dim = len(heatmap)\n",
        "        axis_labels = list()\n",
        "        for i in range(0,dim):\n",
        "            axis_labels_inter = str('%i'%(i+1))\n",
        "            axis_labels.append(axis_labels_inter)\n",
        "        _, ax = plt.subplots(figsize=(6,6))\n",
        "        ax = sns.heatmap(heatmap, xticklabels=axis_labels[::-1], yticklabels=axis_labels[::-1], ax = ax, annot=bl)\n",
        "        #sns.heatmap(heatmap, xticklabels=2, yticklabels=2, ax = ax, annot=bl, cbar=True)   \n",
        "        ax.invert_xaxis()\n",
        "        ax.axhline(y = 0, color='k',linewidth = 4)\n",
        "        ax.axhline(y = heatmap.shape[1], color = 'k', linewidth = 4)\n",
        "        ax.axvline(x = 0, color ='k',linewidth = 4)\n",
        "        ax.axvline(x = heatmap.shape[0], color = 'k', linewidth = 4)\n",
        "\n",
        "        ax.set_title(\"CKA-\"+ type)   \n",
        "        ax.set_xlabel(\"Layer\")\n",
        "        ax.set_ylabel(\"Layer\")\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.locator_params(axis='x',nbins=tri)\n",
        "        plt.locator_params(axis='y',nbins=tri)\n",
        "        plt.savefig('CKA_'+ type +'.png', dpi=300)\n",
        "        \n",
        "    else:\n",
        "        print('There is no such category, try again')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stadistics of the Activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "from matplotlib.ticker import FormatStrFormatter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Second Argument displays the mean, and the standard deviation \n",
        "#Distribution_Act_Layers(bt_result,False)\n",
        "def Distribution_Act_Layers(result,flag):\n",
        "    legends = list()\n",
        "    fig, ax = plt.subplots()\n",
        "    for i in range(num_blocks):\n",
        "        x = result[i].flatten(order='C')\n",
        "        mu, std = norm.fit(x)\n",
        "        x = np.linspace(x.min(), x.max(), 200)\n",
        "        p = norm.pdf(x, mu, std)\n",
        "        ax.plot(x, p*100, linewidth=2)\n",
        "        if flag:\n",
        "            legends_i = str('L' + str(i+1) + r'$, \\mu=$' + str(round(mu,2)) + r'$, \\sigma=$' + str(round(std,2)))\n",
        "        else:\n",
        "            legends_i = str('L' + str(i+1))\n",
        "        legends.append(legends_i)\n",
        "    ax.set_title('Distribution of Activations for each Layer')\n",
        "    ax.legend(legends, fontsize ='x-small', fancybox = True)\n",
        "    ax.set_xlabel('Value')\n",
        "    ax.set_ylabel('Relative Frequency (%)')\n",
        "    ax.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 1 : Understand Network Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1A: Different Depths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128 \n",
        "num_epochs = 3\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.005\n",
        "\n",
        "## Selected Architecture: B/32\n",
        "\n",
        "image_size = 64  # We'll resize input images to this size. Square\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images. Square\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
        "embedding_dim = [256]  # Fixed Embedding Dimension\n",
        "num_blocks = [4,6,8]\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "date = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
        "\n",
        "#num_blocks = [8,12,24,32]  # Number of Mixer Layers that we want to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Create different mlpmixers according to an array of widths or depths\n",
        "def mlpmixer_iterations(num_patches,experiment,embedding_dim,num_blocks):\n",
        "    it_blocks = len(num_blocks)\n",
        "    it_widths = len(embedding_dim)\n",
        "    for j in range(it_widths):\n",
        "        for i in range(it_blocks):\n",
        "            mlpmixer_blocks = keras.Sequential(\n",
        "            [MLPMixerLayer(num_patches, embedding_dim[j], dropout_rate) for _ in range(num_blocks[i])] # creates the number of block without a \n",
        "            )\n",
        "            mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim[j]) # Returns the model\n",
        "            history,accuracy, top_5_accuracy = run_experiment(mlpmixer_classifier)\n",
        "            #Saving Results\n",
        "            pwd = 'Results_Article/'+ str(experiment) +'/mlpmixer_'+ str(num_blocks[i]) + 'ly_' + str(embedding_dim[j]) + 'Dc_' + str(date)\n",
        "            mlpmixer_classifier.save(pwd)\n",
        "            np.save( pwd + '/history_' + str(date) +'.npy',history.history)\n",
        "            with open(pwd + '/accuracy.pkl','wb') as file:\n",
        "                pickle.dump(accuracy,file)\n",
        "            with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
        "                pickle.dump(top_5_accuracy,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset for training \n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")\n",
        "#plt.imshow(x_train[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlpmixer_iterations(num_patches,'1A', embedding_dim,num_blocks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verification (optional for 1A and 2A)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the model for the verification\n",
        "Change paths in this cell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'Results_Article/1A/mlpmixer_4ly_256Dc_2022-02-21_15-07'\n",
        "#Call the folder\n",
        "tested_model = tf.keras.models.load_model(path)\n",
        "#Call the file\n",
        "tested_history=np.load( path + '/history_2022-02-21_15-07.npy',allow_pickle='TRUE').item()\n",
        "with open(path + '/accuracy.pkl','rb') as file:\n",
        "    tested_accuracy = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "curves(tested_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set manually the values of your loaded model\n",
        "embedding_dim = 256\n",
        "num_blocks = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Random Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run separtely once to avoid randomness\n",
        "num_example = 39\n",
        "example_prepro = Preprocessing(num_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Select a MixerBlock and visualize the activation\n",
        "n_MixerLayer = 2\n",
        "\n",
        "bt_result = Mixer_Activations(tested_model,example_prepro)\n",
        "visualize_out(bt_result,n_MixerLayer,num_example)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Heatmap of activations of the random sample\n",
        "sigma = 1\n",
        "bt_heatmap_CKA_ran = Heatmap(bt_result,'kernel',sigma)\n",
        "visualize_Heatmap(bt_heatmap_CKA_ran,'kernel',False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run separtely once to avoid randomness \n",
        "batch_prepro = Batch_Preprocessing(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Heatmap of Average of layer's activation\n",
        "sigma = 1\n",
        "A1_ave_mixer_activations = Prom_Mixer_Activations_Blocks(tested_model,batch_prepro)\n",
        "A1_global_heatmap = Heatmap(A1_ave_mixer_activations,'kernel',sigma)\n",
        "visualize_Heatmap(A1_global_heatmap,'kernel',False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 2: Different Widths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128 \n",
        "num_epochs = 3\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.005\n",
        "\n",
        "## Selected Architecture: B/32\n",
        "\n",
        "image_size = 64  # We'll resize input images to this size. Square\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images. Square\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
        "num_blocks = [12]  # Fixed Number of Mixer Layers \n",
        "embedding_dim = [256] \n",
        "\n",
        "#embedding_dim = [256,384,512,640]  # Values that we want to test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset for training \n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlpmixer_iterations(num_patches,'2A',embedding_dim,num_blocks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 3: Across Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128 \n",
        "num_epochs = 3\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.005\n",
        "\n",
        "\n",
        "## Selected Architecture: B/32\n",
        "\n",
        "image_size = 64  # We'll resize input images to this size. Square\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images. Square\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
        "embedding_dim = 256  # Fixed Embedding Dimension\n",
        "num_blocks = 4\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "date = now.strftime(\"%Y-%m-%d_%H-%M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset for training \n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trained with CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in range(2):\n",
        "    mlpmixer_blocks = keras.Sequential(\n",
        "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
        "    )\n",
        "    mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model\n",
        "    history,accuracy,top_5_accuracy = run_experiment(mlpmixer_classifier)\n",
        "    #Saving Results\n",
        "    pwd = 'Results_Article/3A/mlpmixer_' + str(date) + '_CF10_' + str(k+1)\n",
        "    mlpmixer_classifier.save(pwd)\n",
        "    np.save( pwd + '/history_' + str(date) +'.npy',history.history)\n",
        "    with open(pwd + '/accuracy.pkl','wb') as file:\n",
        "        pickle.dump(accuracy,file)\n",
        "    with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
        "        pickle.dump(top_5_accuracy,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset for training \n",
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Trained with CIFAR 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in range(2):\n",
        "    mlpmixer_blocks = keras.Sequential(\n",
        "    [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
        "    )\n",
        "    mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model\n",
        "    history,accuracy,top_5_accuracy = run_experiment(mlpmixer_classifier)\n",
        "    #Saving Results\n",
        "    pwd = 'Results_Article/3A/mlpmixer_' + str(date) + '_CF100_' + str(k+1)\n",
        "    mlpmixer_classifier.save(pwd)\n",
        "    np.save( pwd + '/history_' + str(date) +'.npy',history.history)\n",
        "    with open(pwd + '/accuracy.pkl','wb') as file:\n",
        "        pickle.dump(accuracy,file)\n",
        "    with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
        "        pickle.dump(top_5_accuracy,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Untrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlpmixer_blocks = keras.Sequential(\n",
        "[MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
        ")\n",
        "mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model\n",
        "pwd = 'Results_Article/3A/mlpmixer_' + str(date) + '_Untrained'\n",
        "mlpmixer_classifier.save(pwd)\n",
        "#np.save( pwd + '/history_' + str(date) +'.npy',history.history)\n",
        "#with open(pwd + '/accuracy.pkl','wb') as file:\n",
        "#    pickle.dump(accuracy,file)\n",
        "#with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
        "#    pickle.dump(top_5_accuracy,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the path below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'Results_Article/3A/mlpmixer_2022-02-21_15-20_'\n",
        "global_models = list()\n",
        "#Call the folder\n",
        "C10_mlpmixer_1 = tf.keras.models.load_model(path + 'CF10_1')\n",
        "global_models.append(C10_mlpmixer_1)\n",
        "C10_mlpmixer_2 = tf.keras.models.load_model(path + 'CF10_2')\n",
        "global_models.append(C10_mlpmixer_2)\n",
        "C100_mlpmixer_1 = tf.keras.models.load_model(path + 'CF100_1')\n",
        "global_models.append(C100_mlpmixer_1)\n",
        "C100_mlpmixer_2 = tf.keras.models.load_model(path + 'CF100_2')\n",
        "global_models.append(C100_mlpmixer_2)\n",
        "Unt_mlpmixer = tf.keras.models.load_model(path + 'Untrained')\n",
        "global_models.append(Unt_mlpmixer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run Once to Avoid Randomness\n",
        "batch_prepro = Batch_Preprocessing(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Intialization before testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def across_datasets(global_models,batch_prepro,type,sigma):\n",
        "    total_activations = list()\n",
        "    plot_raw = list()\n",
        "    plot_total = list()\n",
        "    for k in range(len(global_models)):\n",
        "        tested_model = global_models[k] \n",
        "        ave_mixer_activations = Prom_Mixer_Activations_Blocks(tested_model,batch_prepro)\n",
        "        total_activations.append(ave_mixer_activations)\n",
        "        \n",
        "    for pairs in set:\n",
        "        comp_1 = total_activations[pairs[0]]\n",
        "        comp_2 = total_activations[pairs[1]]\n",
        "        plot_raw = list()\n",
        "        for i in range(num_blocks):\n",
        "            if type == 'rbf':\n",
        "                inter_row = cka(gram_rbf(comp_1[i],sigma),gram_rbf(comp_2[i],sigma))\n",
        "            elif type == 'linear':\n",
        "                inter_row = cka(gram_linear(comp_1[i]),gram_linear(comp_2[i]))\n",
        "            plot_raw.append(inter_row)\n",
        "        plot_total.append(plot_raw)\n",
        "    return plot_total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sigma = 1\n",
        "type = 'linear'\n",
        "\n",
        "#Pairs of models that are going to be compared according to the order in the matriz\n",
        "set = [[0,1],[2,3],[0,2],[0,4],[2,4]]\n",
        "label_set = ['CIFAR-10 Net vs. CIFAR-10 Net',\n",
        "            'CIFAR-100 Net vs. CIFAR-100 Net',\n",
        "            'CIFAR-10 Net vs. CIFAR-100 Net ',\n",
        "            'CIFAR-10 Net vs. Untrained',\n",
        "            'CIFAR-100 Net vs. Untrained']\n",
        "num_models_set = len(set)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tested on CIFAR 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset for testing\n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), _ = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The experiment on the paper is with the linear type\n",
        "plot_total_1 = across_datasets(global_models,batch_prepro,type,sigma=None)\n",
        "with open('Results_Article/3A/plot_total_C10.pkl','wb') as file:\n",
        "    pickle.dump(plot_total_1,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tested on CIFAR 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset for testing\n",
        "\n",
        "num_classes = 100\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), _ = keras.datasets.cifar100.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# The experiment on the paper is with the linear type\n",
        "plot_total_2 = across_datasets(global_models,batch_prepro,type,sigma=None)\n",
        "with open('Results_Article/3A/plot_total_C100.pkl','wb') as file:\n",
        "    pickle.dump(plot_total_2,file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tested on MNIST: (Appendix 6A)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset for testing\n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (28, 28)\n",
        "(x_train, y_train), _ = keras.datasets.mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_total_3 = across_datasets(global_models,batch_prepro,type,sigma=None)\n",
        "with open('Results_Article/6A/plot_total_MNIST.pkl','wb') as file:\n",
        "    pickle.dump(plot_total_3,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Verification (Optional for 3A)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tested_plot = plot_total_1\n",
        "name = '_tested_C10'\n",
        "######################################################\n",
        "x = list(range(1,num_blocks+1))\n",
        "for j in range(num_models_set):\n",
        "    plt.plot(x,tested_plot[j], label = label_set[j])\n",
        "plt.xlabel('Layer')\n",
        "plt.ylabel('CKA ('+ type +')')\n",
        "plt.locator_params(axis='x', nbins=num_blocks)\n",
        "plt.title('Similarity on CIFAR-10')\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.savefig('Results_Article/3A/Similarity_'+ type + name +'.png') \n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 4: Sanity Check"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mlpmixer_generator(num_models):\n",
        "    now = datetime.datetime.now()\n",
        "    date = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
        "    for i in range(num_models):\n",
        "        mlpmixer_blocks = keras.Sequential(\n",
        "        [MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
        "        )\n",
        "        mlpmixer_classifier = build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model\n",
        "        history,accuracy, top_5_accuracy = run_experiment(mlpmixer_classifier)\n",
        "        #Saving Results\n",
        "        pwd = 'Results_Article/4A_SC/mlpmixer_B-32_'  + str(date) + '_' + str(i+1)\n",
        "        mlpmixer_classifier.save(pwd)\n",
        "        np.save( pwd + '/history_' + str(date) +'.npy',history.history)\n",
        "        with open(pwd + '/accuracy.pkl','wb') as file:\n",
        "            pickle.dump(accuracy,file)\n",
        "        with open(pwd + '/top5-accuracy.pkl','wb') as file:\n",
        "            pickle.dump(top_5_accuracy,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Available types = 'rbf' or 'linear'\n",
        "def sanity_check(total_activations,num_models,num_blocks,type,sigma):\n",
        "    row = []\n",
        "    total_events = 0\n",
        "    positive_events = 0\n",
        "    for i in range(num_models-1):\n",
        "        comp_1 = total_activations[i]\n",
        "        for j in range(i+1,num_models):\n",
        "            comp_2 = total_activations[j]\n",
        "            for m in range(num_blocks):\n",
        "                for n in range(num_blocks):\n",
        "                    if type == 'rbf':\n",
        "                        inter_row = cka(gram_rbf(comp_1[m],sigma),gram_rbf(comp_2[n],sigma))\n",
        "                    elif type == 'linear':\n",
        "                        inter_row = cka(gram_linear(comp_1[m]),gram_linear(comp_2[n]))\n",
        "                    row.append(inter_row)\n",
        "                b = [i for i, x in enumerate(row) if x == max(row)]\n",
        "                if len(b) == 1:\n",
        "                    if b[0] == m:\n",
        "                        #print(row)\n",
        "                        #print('Hello, Layer %i'%(m))\n",
        "                        positive_events += 1\n",
        "                    else:\n",
        "                        pass\n",
        "                else:\n",
        "                    pass\n",
        "                total_events +=1\n",
        "                row=[]\n",
        "    return positive_events, total_events"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Configure the hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128 \n",
        "num_epochs = 3\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.005\n",
        "\n",
        "## Selected Architecture: B/32\n",
        "\n",
        "image_size = 64  # We'll resize input images to this size. Square\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images. Square\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
        "embedding_dim = 256  # Fixed Embedding Dimension\n",
        "num_blocks = 4\n",
        "\n",
        "\n",
        "num_models = 4\n",
        "#num_models = 10 selected\n",
        "rbf_index = [0.2,0.4,0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset for training \n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), _ = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlpmixer_generator(num_models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change the path below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'Results_Article/4A_SC/mlpmixer_B-32_2022-02-21_15-47_'\n",
        "total_models = list()\n",
        "for k in range(num_models):  \n",
        "    current_model = tf.keras.models.load_model(path + str(k+1))\n",
        "    total_models.append(current_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run this cell once to avoid randomness\n",
        "batch_prepro = Batch_Preprocessing(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "total_activations = list()\n",
        "for k in range(num_models):\n",
        "    tested_model = total_models[k] \n",
        "    ave_mixer_activations = Prom_Mixer_Activations_Blocks(tested_model,batch_prepro)\n",
        "    total_activations.append(ave_mixer_activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pwd='Results_Article/4A_SC'\n",
        "for sigma in rbf_index:\n",
        "    positive_events, total_events = sanity_check(total_activations, num_models, num_blocks,'rbf',sigma)\n",
        "    SC_accuracy = (positive_events/total_events) \n",
        "    print(f\"The Sanity check with a CKA RFF: {sigma} has an accuracy of {round(SC_accuracy * 100, 2)}%\")\n",
        "    #Multiplying by 100 to ensure proper saving of the file\n",
        "    with open(pwd + '/SCaccuracy_RBF'+ str(round(sigma*100))  +'.pkl','wb') as file:\n",
        "        pickle.dump(SC_accuracy,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positive_events, total_events = sanity_check(total_activations, num_models, num_blocks,'linear',sigma=None)\n",
        "SC_accuracy = (positive_events/total_events) \n",
        "print(f\"The Sanity check with a CKA linear has an accuracy of {round(SC_accuracy * 100, 2)}%\")\n",
        "with open(pwd + '/SCaccuracy_linear.pkl','wb') as file:\n",
        "        pickle.dump(SC_accuracy,file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Appendix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5: Internal Behavior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128 \n",
        "num_epochs = 3\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.005\n",
        "\n",
        "## Selected Architecture: B/32\n",
        "\n",
        "image_size = 64  # We'll resize input images to this size. Square\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images. Square\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
        "embedding_dim = 256  # Fixed Embedding Dimension\n",
        "num_blocks = 4\n",
        "\n",
        "sigma = 1\n",
        "type = 'kernel' # 'kernel' or 'linear'\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "date = now.strftime(\"%Y-%m-%d_%H-%M\")\n",
        "path = 'Results_Article/5Appendix/mlpmixer_' + str(date) + '_independent'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset for training \n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "(x_train, y_train), _ = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Mixer_Layer_Outputs2(model,example,shape):\n",
        "    intermediate_model=tf.keras.models.Model(inputs=model.input,outputs=model.output)\n",
        "    #This reshape is necessary for the input of the model\n",
        "    example = tf.reshape(example,[1,shape[0],shape[1]])\n",
        "    #Inference\n",
        "    intermediate_prediction =intermediate_model.predict(example)\n",
        "    #This reshape is standardize the output\n",
        "    layactivation = intermediate_prediction.reshape((embedding_dim,num_patches))\n",
        "    return layactivation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Computes the outputs of each MLP-mixer Layer\n",
        "def Mixer_Activations_2(model,example):\n",
        "    total_activations = list()\n",
        "    for i in range(num_blocks):\n",
        "        #Shape of the input for the mlp1\n",
        "        shape=(embedding_dim,num_patches)\n",
        "        modelf = model.layers[4].layers[i].mlp1\n",
        "        int_total_activations = Mixer_Layer_Outputs2(modelf,example,shape)\n",
        "        #Shape of the input for the mlp2\n",
        "        total_activations.append(int_total_activations)\n",
        "        shape=(num_patches,embedding_dim)\n",
        "        modelf = model.layers[4].layers[i].mlp2\n",
        "        int_total_activations = Mixer_Layer_Outputs2(modelf,example,shape)\n",
        "        total_activations.append(int_total_activations)\n",
        "    return total_activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Prom_Mixer_Activations_Blocks_2(model,batch_regularization):\n",
        "    sum = list()\n",
        "    for i in range(0,2*num_blocks):\n",
        "        sum_raw = np.zeros((embedding_dim,num_patches))\n",
        "        sum.append(sum_raw)\n",
        "    for i in range(0,batch_size):\n",
        "        mixer_raw = Mixer_Activations_2(model,batch_regularization[i])\n",
        "        for i in range(0,2*num_blocks):\n",
        "            sum[i] = np.add(mixer_raw[i],sum[i])\n",
        "    prom_mixer_activations = [ (number / batch_size)  for number in sum]\n",
        "    return prom_mixer_activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mlpmixer_blocks = keras.Sequential(\n",
        "[MLPMixerLayer(num_patches, embedding_dim, dropout_rate) for _ in range(num_blocks)] # creates the number of block without a \n",
        ")\n",
        "mlpmixer_independent= build_classifier(mlpmixer_blocks,embedding_dim) # Returns the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Run once to avoid randomness\n",
        "batch_prepro = Batch_Preprocessing(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#After training, this cell is going to be same as the after-training heatmap\n",
        "A5_bt_ave_mixer_activations = Prom_Mixer_Activations_Blocks_2(mlpmixer_independent,batch_prepro)\n",
        "A5_bt_global_heatmap = Heatmap(A5_bt_ave_mixer_activations,type,sigma)\n",
        "visualize_Heatmap(A5_bt_global_heatmap,type,False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = run_experiment(mlpmixer_independent)\n",
        "mlpmixer_independent.save(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#After training heatmap\n",
        "A5_at_ave_mixer_activations = Prom_Mixer_Activations_Blocks_2(mlpmixer_independent,batch_prepro)\n",
        "A5_at_global_heatmap = Heatmap(A5_at_ave_mixer_activations,type,sigma)\n",
        "visualize_Heatmap(A5_at_global_heatmap,type,False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path + '/heatmap_bt.pkl','wb') as file:\n",
        "    pickle.dump(A5_bt_global_heatmap,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path + '/heatmap_at.pkl','wb') as file:\n",
        "    pickle.dump(A5_at_global_heatmap,file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(path + '/heatmap_at.pkl','rb') as file:\n",
        "    tested_heatmap = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1B (Under Construction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "weight_decay = 0.0001\n",
        "batch_size = 128 \n",
        "num_epochs = 3\n",
        "dropout_rate = 0.2\n",
        "learning_rate = 0.005\n",
        "\n",
        "## Selected Architecture: B/32\n",
        "\n",
        "image_size = 64  # We'll resize input images to this size. Square\n",
        "patch_size = 8  # Size of the patches to be extracted from the input images. Square\n",
        "num_patches = (image_size // patch_size) ** 2  # Size of the data array, or sequence length (S)\n",
        "#The same as 1A experiment\n",
        "embedding_dim = [256]  # Fixed Embedding Dimension\n",
        "num_blocks = [4,6,8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Dataset for training \n",
        "\n",
        "num_classes = 10\n",
        "input_shape = (32, 32, 3)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_models = list()\n",
        "for layer in num_blocks:\n",
        "    #Call the folder\n",
        "    pwd1 = 'Results_Article/1A/mlpmixer_'+ str(layer) + 'ly_' + str(embedding_dim[0]) + 'Dc_2022-02-21_17-26' \n",
        "    layers_models = tf.keras.models.load_model(pwd1, compile=False)\n",
        "    all_models.append(layers_models)       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.add(Dense(10, activation= 'softmax'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "mlp_image_classification",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
